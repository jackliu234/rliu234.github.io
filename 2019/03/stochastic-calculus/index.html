<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>Notes on Stochastic Calculus Â· Rongjia Liu</title><meta name="description" content="Notes on Stochastic Calculus - Rongjia Liu"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/arctic.css"><link rel="search" type="application/opensearchdescription+xml" href="http://jackliu234.com/atom.xml" title="Rongjia Liu"><script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/search/" target="_self" class="nav-list-link">SEARCH</a></li><!-- li.nav-list-item--><!--    a.nav-list-link(class="search" href=url_for("search") target="_self") <i class="fa fa-search" aria-hidden="true"></i>--></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Notes on Stochastic Calculus</h1><div class="post-info">Mar 10, 2019<span id="busuanzi_container_page_pv">| Page Views:</span><span id="busuanzi_value_page_pv"></span><!--    if item.tags--><!--        span | &nbsp;--><!--        for tag in item.tags.toArray()--><!--            a(href=url_for(tag.path))=  '#' + tag.name--><!-- if item.from && (is_home() || is_post())--><!--    a.post-from(href=item.from target="_blank" title=item.from)!= __('translated')-->
</div><div class="post-content"><a id="more"></a>
<h1 id="Discrete-Time-Martingales"><a href="#Discrete-Time-Martingales" class="headerlink" title="Discrete Time Martingales"></a>Discrete Time Martingales</h1><h2 id="Conditional-expectation"><a href="#Conditional-expectation" class="headerlink" title="Conditional expectation"></a>Conditional expectation</h2><p><strong><em>Definition</em></strong> A <strong>Borel</strong> set is any set in a topological space that can be formed from open sets through the operations of:</p>
<ul>
<li>complement</li>
<li>countable union</li>
<li>countable intersection</li>
</ul>
<p><strong><em>Definition</em></strong> Let <script type="math/tex">Y</script> be a random vector and <script type="math/tex">X</script> be a integrable random variable with <script type="math/tex">\mathbb{E}|X|<\infty</script>. The <strong>conditional expectation</strong> of <script type="math/tex">X</script> given <script type="math/tex">Y</script> is the unique measureable function <script type="math/tex">f(Y)</script> such that for every Borel set <script type="math/tex">\mathcal{B}</script>:</p>
<script type="math/tex; mode=display">\mathbb{E}X \textbf{1}_{Y \in \mathcal{B}} = \mathbb{E}f(Y) \textbf{1}_{Y \in \mathcal{B}}</script><p>We denote <script type="math/tex">f(Y)</script> as <script type="math/tex">\mathbb{E}(X|Y)</script></p>
<p><strong><em>Example 1</em></strong> Suppose random variable <script type="math/tex">X</script> and <script type="math/tex">Y</script> are discrete.</p>
<script type="math/tex; mode=display">\begin{align}
\mathbb{E}(X|Y) &= \sum_x x\;\dfrac{\mathbb{P}(X = x, Y = y)}{\sum_{x'} \mathbb{P}(X = x', Y = y)} \\
&= \sum_x x\;\mathbb{P}(X = x|Y = y) \\
\end{align}</script><p><strong><em>Example 2</em></strong> Suppose random variable <script type="math/tex">X</script> and <script type="math/tex">Y</script> are continuous, with joint probability density function <script type="math/tex">f_{X, Y}(x. y)</script> and marginal density <script type="math/tex">f_X(x)</script> and <script type="math/tex">f_Y(y)</script>.</p>
<script type="math/tex; mode=display">\begin{align}
\mathbb{E}(X|Y) &= \int x\;\dfrac{f_{X, Y}(x. y)}{f_Y(y)}dx \\
&= \int x\;f_{X|Y}(x)dx \\
\end{align}</script><p>Here are some basic properties of conditional expectation:</p>
<ul>
<li>Linearity: <script type="math/tex">\mathbb{E}[aX + bY|\mathcal{F}] = a\mathbb{E}[X|\mathcal{F}] +  b\mathbb{E}[Y|\mathcal{F}]</script></li>
<li>Constant: if <script type="math/tex">X = a</script>, then <script type="math/tex">\mathbb{E}[X|\mathcal{F}] = a</script></li>
<li>Independence: if <script type="math/tex">X</script> is independent of <script type="math/tex">\mathcal{F}</script>, then <script type="math/tex">\mathbb{E}[X|\mathcal{F}] = \mathbb{E}X</script></li>
<li>Tower Property: if <script type="math/tex">\mathcal{G} \subset \mathcal{F}</script> then <script type="math/tex">\mathbb{E}[ \mathbb{E}[X | \mathcal{F}]|\mathcal{G}] = \mathbb{E}[X | \mathcal{G}]</script></li>
<li>Factorization Property: if Z is <script type="math/tex">\mathcal{F}</script>-measurable then <script type="math/tex">\mathbb{E}[ZX|\mathcal{F}] = Z\mathbb{E}[X|\mathcal{F}]</script></li>
<li>Monotonicity: if <script type="math/tex">X \leq Y</script>, then <script type="math/tex">\mathbb{E}[X|\mathcal{F}] \leq \mathbb{E}[Y|\mathcal{F}]</script> a.s.</li>
</ul>
<h2 id="L-2-Theory"><a href="#L-2-Theory" class="headerlink" title="L^2 Theory"></a><script type="math/tex">L^2</script> Theory</h2><p><strong><em>Definition</em></strong> A <script type="math/tex">\boldsymbol{\sigma}</script><strong>-algebra</strong> is a collection <script type="math/tex">\Sigma</script> of subsets of a Borel set <script type="math/tex">\mathcal{B}</script>, that is closed under:</p>
<ul>
<li>complement, e.g. if <script type="math/tex">A \in \Sigma</script>, then <script type="math/tex">\mathcal{B}\backslash A \in \Sigma</script></li>
<li>countable unions, e.g. if <script type="math/tex">A_n \in \Sigma</script>, then <script type="math/tex">\cup A_n \in \Sigma</script></li>
</ul>
<p><strong><em>Definition</em></strong> <strong><script type="math/tex">L^2(\Omega, \mathcal{F}, \mathbb{P})</script></strong> is the set of all <script type="math/tex">\mathcal{F}</script>-measurable square-integrable random variable <script type="math/tex">X</script>, with finite 2nd moment <script type="math/tex">\mathbb{E}X^2</script>.</p>
<p><strong><em>Definition</em></strong> A real <strong>Hilbert space</strong> is a real vector space <script type="math/tex">\mathcal{H}</script> with an inner product <script type="math/tex"><,></script>, such that <script type="math/tex">\mathcal{H}</script> is a complete metric space w.r.t. to the metric <script type="math/tex">d</script>, where:</p>
<script type="math/tex; mode=display">d(x, y) = <x-y, x-y></script><p>Hilbert space examples: <script type="math/tex">\mathbb{R}^n</script>, with inner product <script type="math/tex"><\textbf{x}, \textbf{y}> = \sum x_iy_i</script>. Or, <script type="math/tex">L^2(\Omega, \mathcal{F}, \mathbb{P})</script>, with inner product <script type="math/tex"><\textbf{X}_1, \textbf{X}_2> = \mathbb{E}[X_1X_2]</script>. The reason we are interested at <script type="math/tex">L^2</script> rather than <script type="math/tex">L^p</script> for other <script type="math/tex">p</script> is that the innner product <script type="math/tex">\mathbb{E}[X_1X_2]</script> give rise of orthogonality.</p>
<p><strong><em>Proposition</em></strong> If <script type="math/tex">X \in L^2(\Omega, \mathcal{F}, \mathbb{P})</script>, then for any <script type="math/tex">\sigma</script>-algebra <script type="math/tex">\mathcal{G} \in \mathcal{F}</script>, the conditional expectation <script type="math/tex">\mathbb{E}[X|\mathcal{G}]</script> is the <strong><em>orthogonal projection</em></strong> of X onto <script type="math/tex">L^2(\Omega, \mathcal{G}, \mathbb{P})</script>, such that:</p>
<script type="math/tex; mode=display">\mathbb{E}[X|\mathcal{G}]=X \text{ if } X\in L^2(\Omega, \mathcal{G}, \mathbb{P})</script><script type="math/tex; mode=display">\mathbb{E}[X|\mathcal{G}]=0 \text{ if } X\notin L^2(\Omega, \mathcal{G}, \mathbb{P})</script><p>Also, <script type="math/tex">\mathbb{E}[X|\mathcal{G}]</script> can be interpreted as a <script type="math/tex">\mathcal{G}</script>-measurable random variable that minimizes the mean square error <script type="math/tex">\mathbb{E}[(X - \mathbb{E}[X|\mathcal{G}])^2]</script>.</p>
<h2 id="Martingales"><a href="#Martingales" class="headerlink" title="Martingales"></a>Martingales</h2><p><strong><em>Definition</em></strong> A <strong>filtration</strong> is an increasing sequence of <script type="math/tex">\sigma</script>-algebra <script type="math/tex">\mathcal{F}_n \subset \mathcal{F}</script>, where <script type="math/tex">\mathcal{F}</script> is the <script type="math/tex">\sigma</script>-algebra of all events.</p>
<p><strong><em>Definition</em></strong> A <strong>martingale</strong> is a sequence of <script type="math/tex">\mathcal{F}</script> measurable integrable random variable <script type="math/tex">X_{n}</script> such that:</p>
<script type="math/tex; mode=display">\mathbb{E}[X_{n+1}|\mathcal{F}_{n}] = X_{n}</script><p>The tower property implies that <script type="math/tex">\mathbb{E}X_n = X_0</script>.</p>
<p><strong><em>Example 1</em></strong> Given I.I.D. random variable <script type="math/tex">X_n \subset L^2</script> with <script type="math/tex">\mathbb{E}X_n = 0</script> and variance <script type="math/tex">\sigma^2</script>.</p>
<ul>
<li>Sequence <script type="math/tex">S_n = \sum_{i=1}^n X_i</script>, and</li>
<li>Sequence<script type="math/tex">T_n = (\sum_{i=1}^n X_i)^2 - n\sigma^2</script></li>
</ul>
<p>are both martingales.</p>
<p><strong><em>Example 2</em></strong> Let <script type="math/tex">X</script> be any <script type="math/tex">L^1</script> random variable and <script type="math/tex">\mathcal{F}_n</script> be any filtration. Then the sequence <script type="math/tex">X_n := \mathbb{E}[X|\mathcal{F}_n]</script> is a <strong>closed martingales</strong>.</p>
<p>Note that the <a href="https://jackliu234.com/2019-02-15/">St. Petersburg martingale</a> <script type="math/tex">X_n</script> is not closed, where <script type="math/tex">X_0 \in \mathbb{R}</script> and <script type="math/tex">P(X_{n}=2X_{n-1}) = 1/2</script> and <script type="math/tex">P(X_{n}=0) = 1/2</script>. This is because <script type="math/tex">X \notin L^{1}</script>.</p>
<p><strong><em>Example 3</em></strong> Given I.I.D. random variable <script type="math/tex">X_n</script> with moment generating function <script type="math/tex">M_{X} = \mathbb{E}e^{\theta X}</script>. Then the <strong>exponential martingales</strong> <script type="math/tex">Z_{n}</script> is a positive martingale with definition:</p>
<script type="math/tex; mode=display">Z_{n} = \dfrac{e^{\theta \sum_n X_{i}}}{[M_{X}]^{n}}</script><h2 id="Doobâs-Indentity"><a href="#Doobâs-Indentity" class="headerlink" title="Doobâs Indentity"></a>Doobâs Indentity</h2><p><strong><em>Definition</em></strong> A sequence <script type="math/tex">Z_n</script> of random variables is <strong>predictable</strong> with respect to filtration <script type="math/tex">\mathcal{F}_n</script> if <script type="math/tex">Z_n</script> is measurable with respect to <script type="math/tex">\mathcal{F}_{n-1}</script></p>
<p><strong><em>Definition</em></strong> A sequence <script type="math/tex">Z_n</script> of random variables is <strong>adapted</strong> to filtration <script type="math/tex">\mathcal{F}_n</script> if <script type="math/tex">Z_n</script> is measurable with respect to <script type="math/tex">\mathcal{F}_{n}</script></p>
<p><strong><em>Proposition</em></strong> If <script type="math/tex">X_n</script> is a martingale with <script type="math/tex">X_0 = 0</script> and <script type="math/tex">Z_n</script> is a predictable sequence of bounded random variables, then the <strong>martingale transform</strong> <script type="math/tex">\{Z \cdot X\}_n</script> is a martingale:</p>
<script type="math/tex; mode=display">\{Z \cdot X\}_n = \sum_{i=1}^n Z_i(X_i - X_{i-1})</script><p><strong><em>Definition</em></strong> A <strong>stopping time</strong> with respect to filtration <script type="math/tex">\mathcal{F}</script> is a random variable <script type="math/tex">T \in \mathbb{N} \cup \{\infty\}</script> such that <script type="math/tex">\{T = n\} \in \mathcal{F}_{n} \;\forall\; n \geq 0</script></p>
<p><strong><em>Lemma</em></strong> Let <script type="math/tex">T</script> be a stopping time, then the sequence <script type="math/tex">Z_n := \textbf{1}_{T \geq n}</script> is predictable.</p>
<p><strong><em>Theorem</em></strong> Let <script type="math/tex">X_{n}</script> be a martingale and <script type="math/tex">T</script> be a stopping time. For all <script type="math/tex">m \in \mathbb{N}</script>, the <strong>Doobâs Identity</strong> states that <script type="math/tex">\mathbb{E}X_{T\wedge m} = \mathbb{E}X_{0}</script>. Note that if <script type="math/tex">|X_{T\wedge m}|</script> is bounded for all <script type="math/tex">m</script>, DCT shows that <script type="math/tex">\mathbb{E}X_{T} = \mathbb{E}X_{0}</script>.</p>
<p>Proof. <script type="math/tex">X_{T\wedge n}</script> is a martingale:</p>
<script type="math/tex; mode=display">\begin{align}
X_{T\wedge n} &= \sum_{i=1}^n (X_i - X_{i-1})\textbf{1}_{T \geq n} \\
&= \sum_{i=1}^n (X_i - X_{i-1})Z_i
\end{align}</script><p><strong><em>Theorem</em></strong> Let <script type="math/tex">f_n</script> be a sequence functions on measure space <script type="math/tex">(\mathcal{S}, \Sigma, \mu)</script> that converge point-wise to a function f. For <script type="math/tex">\lim_{n \rightarrow \infty} \int_{\mathcal{S}} f_{n}d\mu = \int_{\mathcal{S}} f d\mu</script>,</p>
<ul>
<li><p>The <strong>Dominated Convergence Theroem</strong> (DCT) requires <script type="math/tex">f_{n}</script> to be dominated by an integrable function <script type="math/tex">g</script>: <script type="math/tex">|f_{n}(x)| \leq g(x)</script></p>
</li>
<li><p>The <strong>Monotone Convergence Theroem</strong> (MCT) requires <script type="math/tex">f_{n}</script> to be monotone (increasing or decreasing): <script type="math/tex">f_{1} \leq f_{2} \leq f_{3} ...</script> or <script type="math/tex">f_{1} \geq f_{2} \geq f_{3} ...</script></p>
</li>
</ul>
<p><strong><em>Example 1</em></strong> Let <script type="math/tex">S_{n} = \sum X_{i}</script> be a simple random walk with <script type="math/tex">X_{i} = \pm 1</script>. Let stopping time <script type="math/tex">T := min[n: S_{n} = +A \;or -B]</script>, where <script type="math/tex">A, B>0</script>.</p>
<p>We know that <script type="math/tex">S_{n}</script> is a martingale and <script type="math/tex">S_{T\wedge n} < max(A, B)</script>. Apply Doobsâs Identity and DCT we have:</p>
<script type="math/tex; mode=display">\mathbb{E}S_{T} = 0</script><p>We know that <script type="math/tex">S_{n}^2 - n</script> is a martingale. Apply Doobsâs Identity we have <script type="math/tex">\mathbb{E}S_{T\wedge n}^2 = \mathbb{E}(T\wedge n)</script>. Since <script type="math/tex">S_{T\wedge n}^2</script> is bounded by <script type="math/tex">max(A^2, B^2)</script> and <script type="math/tex">T\wedge n</script> is monotone, apply DCT on the RHS and MCT on LHS we get:</p>
<script type="math/tex; mode=display">\mathbb{E}S^2_{T} = \mathbb{E}T</script><p>Combine both results we can get some interesting result for the <strong>Gamblerâs Ruin</strong> problem:</p>
<script type="math/tex; mode=display">\mathbb{P}[S_{T} = A] = B/(A + B) \\
\mathbb{P}[S_{T} = B] = A/(A + B) \\
\mathbb{E}T = AB</script><p><strong><em>Example 2</em></strong> Let <script type="math/tex">S_{n}</script> be a simple random walk. Let stopping time <script type="math/tex">T := min\{n: S_{n} = +A\}</script>, where <script type="math/tex">A>0</script>. Note that now DCT fails as <script type="math/tex">S_{T\wedge n}</script> is not bounded. Hence <script type="math/tex">\mathbb{E}S_{T} \neq 0</script>.</p>
<p>In fact, <script type="math/tex">\mathbb{E}S_{T} = 1</script> because <script type="math/tex">S_{T} \equiv 1</script>:</p>
<script type="math/tex; mode=display">\mathbb{P}[T < \infty] = \lim_{B \rightarrow \infty} B/(A + B) = 1</script><h2 id="Doobâs-Maximal-Inequality"><a href="#Doobâs-Maximal-Inequality" class="headerlink" title="Doobâs Maximal Inequality"></a>Doobâs Maximal Inequality</h2><p><strong><em>Definition</em></strong> An adapted sequence of random variable <script type="math/tex">X_n</script> is a:</p>
<ul>
<li>sub-martingale if <script type="math/tex">\mathbb{E}[X_n | \mathcal{F}_{n-1}] \geq X_{n-1}</script></li>
<li>super-martingale if <script type="math/tex">\mathbb{E}[X_n | \mathcal{F}_{n-1}] \leq X_{n-1}</script></li>
</ul>
<p><strong><em>Proposition</em></strong> If <script type="math/tex">\varphi :\mathbb{R} \rightarrow \mathbb{R}</script> is a convex function and <script type="math/tex">X_n</script> is a martingale, then:</p>
<ul>
<li>The <strong>Jensenâs Inequality</strong> holds: <script type="math/tex">\varphi(\mathbb{E}X) \leq \mathbb{E}\varphi(X)</script></li>
<li>the sequence <script type="math/tex">\varphi(X_n)</script> is a sub-martingale.</li>
</ul>
<p><strong><em>Proposition</em></strong> If <script type="math/tex">X_n</script> is a martingale with <script type="math/tex">X_0 = 0</script> and <script type="math/tex">Z_n</script> is a predictable sequence of boundedm <strong>non-negative</strong> random variables, then the martingale transform <script type="math/tex">\{Z \cdot X\}_n</script> is a <strong>sub-martingale</strong>:</p>
<script type="math/tex; mode=display">\{Z \cdot X\}_n = \sum_{i=1}^n Z_i(X_i - X_{i-1})</script><p><strong><em>Proposition</em></strong> If <script type="math/tex">X_n</script> is a martingale with <script type="math/tex">X_0 = 0</script> and <script type="math/tex">Z_n</script> is a predictable sequence of random variables such that <script type="math/tex">Z_n \in [0, 1]</script>, then <script type="math/tex">\mathbb{E}\{Z \cdot X\}_n \leq \mathbb{E}X_n</script></p>
<p><strong><em>Corollary</em></strong> If <script type="math/tex">X_n</script> is a non-negative sub-martingale with initial term <script type="math/tex">X_0 = 0</script>, then <strong>Doobâs Maximal Inequality</strong> claims that for any <script type="math/tex">\alpha \in \mathbb{R}</script>:</p>
<script type="math/tex; mode=display">\mathbb{P}[max_{k \leq n} X_k \geq \alpha] \leq \mathbb{E}X_n/\alpha</script><p>and that:</p>
<script type="math/tex; mode=display">\mathbb{P}[max_{k \leq n} |X_k| \geq \alpha] \leq \mathbb{E}X_n^2/\alpha^2</script><p>Note that this is a big improvement on the <strong>Chebyshev Inequality</strong>, which claims that given <script type="math/tex">L^2</script>-bounded random variable <script type="math/tex">X</script> and for any <script type="math/tex">k\in\mathbb{R}^+</script>:</p>
<script type="math/tex; mode=display">\mathbb{P}[|X - \mathbb{E}X| \geq k\sqrt{VarX}] \leq 1/k^2</script><h2 id="Martingale-Convergence-Theorem"><a href="#Martingale-Convergence-Theorem" class="headerlink" title="Martingale Convergence Theorem"></a>Martingale Convergence Theorem</h2><p><strong><em>Definition</em></strong> a sequence <script type="math/tex">x_i</script> of real numbers is called a <strong>Cauchy sequence</strong>  if for every positive real number <script type="math/tex">\epsilon</script>, there is a positive integer <script type="math/tex">N</script> such that for all natural numbers <script type="math/tex">m, n > N</script> such that <script type="math/tex">|x_m - x_n| \leq \epsilon</script></p>
<p><strong><em>Definition</em></strong> <script type="math/tex">L^2</script> martingales have <strong>orthogonal increments</strong>. Given <script type="math/tex">X_n</script> a <script type="math/tex">L^2</script> martingale with increments <script type="math/tex">\xi_n := X_n - X_{n-1}</script> and <script type="math/tex">X_0 = 0</script>, then:</p>
<ul>
<li><script type="math/tex">\mathbb{E}\xi_n\xi_{n+m} = 0</script>, <script type="math/tex">\forall \;n < m</script>, and</li>
<li><script type="math/tex; mode=display">\mathbb{E}X^2_n = \sum_{i=1}^n\mathbb{E}\xi^2_i</script></li>
</ul>
<p><strong><em>Theorem</em></strong> Suppose <script type="math/tex">X_n</script> is <script type="math/tex">L^1</script>-bounded martingale, then there exists a <script type="math/tex">L^1</script>-bounded random variable <script type="math/tex">X_{\infty}</script> such that:</p>
<script type="math/tex; mode=display">\lim_{n \rightarrow \infty} X_n = X_{\infty} \;\text{a.s.}</script><p><strong><em>Theorem</em></strong> Suppose <script type="math/tex">X_n</script> is <script type="math/tex">L^2</script>-bounded martingale, then there exists a <script type="math/tex">L^2</script>-bounded random variable <script type="math/tex">X_{\infty}</script> such that:</p>
<p>(1) <script type="math/tex">\lim_{n \rightarrow \infty} X_n = X_{\infty} \;\text{a.s.}</script><br>(2) <script type="math/tex">\lim_{n \rightarrow \infty} \mathbb{E}|X_n - X_{\infty}|^2 = 0, and\; \lim_{n \rightarrow \infty} \mathbb{E}X_n^2 = \mathbb{E}X_{\infty}^2</script></p>
<h2 id="Change-Of-Measure"><a href="#Change-Of-Measure" class="headerlink" title="Change Of Measure"></a>Change Of Measure</h2><p><strong><em>Proposition</em></strong> Given <script type="math/tex">P</script> a probability measure and <script type="math/tex">Z</script> is a non-negative random variable satisfying <script type="math/tex">\mathbb{E}_{P}Z = 1</script>, then there exist a probability measure <script type="math/tex">Q</script> such that for any bounded or non-negative random variable <script type="math/tex">Y</script> that <script type="math/tex">\mathbb{E}_QY = \mathbb{E}_PYZ</script>. Z is called the <strong>likelihood ratio</strong> of probability measure <script type="math/tex">Q</script> w.r.t. <script type="math/tex">P</script>, written as <script type="math/tex">Z = dQ/dP</script> and that:</p>
<script type="math/tex; mode=display">\mathbb{E}_QY = \mathbb{E}_P\dfrac{dQ}{dP}Y</script><p><strong><em>Proposition</em></strong> If the outcome space <script type="math/tex">\Omega</script> is finite, then for each outcome <script type="math/tex">\omega \in \Omega</script>, <script type="math/tex">Q(\omega) = P(\omega)Z(\omega)</script></p>
<p><strong><em>Example 1</em></strong> In a <script type="math/tex">N</script>-period market with finite set of outcomes and tradable assets. Let <script type="math/tex">P, Q</script> denote the risk-neutural measure for USD and EUR investors. Let <script type="math/tex">S_t^i, \tilde{S}_t^i</script> denote the USD and EUR price of the risk-less (w.r.t. its own measure) asset <script type="math/tex">B^i</script> at time t. Then <script type="math/tex">dP/dQ = S^1_0/S^1_N</script></p>
<p>Proof. By fundamental theorem, <script type="math/tex">\tilde{S}_t^i = \mathbb{E}_Q\tilde{S}_N^i</script>, and <script type="math/tex">\tilde{S}_t^i=S_t^i/S_t^1</script>, so:</p>
<script type="math/tex; mode=display">S_t^i = \mathbb{E}_Q[S_N^i\times S^1_0/S^1_N] = \mathbb{E}_PS_N^i</script><p><strong><em>Theorem</em></strong> Let <script type="math/tex">P</script> and <script type="math/tex">Q</script> be two probability measure on the same measurable space, and let <script type="math/tex">\mathcal{F}_n</script> be a filtration such that for all n <script type="math/tex">Q</script> is absolutely continuous w.r.t. <script type="math/tex">P</script> on <script type="math/tex">mathcal{F}_n</script>. Then the sequence of likelihood ratio <script type="math/tex">L_n</script> is a martingale:</p>
<script type="math/tex; mode=display">L_n := \{\dfrac{dQ}{dP}\}_{\mathcal{F_n}}</script><h1 id="Brownian-Motion"><a href="#Brownian-Motion" class="headerlink" title="Brownian Motion"></a>Brownian Motion</h1><h2 id="Standard-Bronwian-Motion"><a href="#Standard-Bronwian-Motion" class="headerlink" title="Standard Bronwian Motion"></a>Standard Bronwian Motion</h2><p><strong><em>Definition</em></strong> A standard <strong>Brownian motion</strong> (SBM) is a continuous-time random process <script type="math/tex">B_t</script> such that <script type="math/tex">B_0 = 0</script> and:<br>(a) <script type="math/tex">B_t</script> has stationary increments.<br>(b) <script type="math/tex">B_t</script> has independent increments.<br>(c) The sample path <script type="math/tex">t \rightarrow B_t</script> are continuous.</p>
<p>Note that (a), (b), and (c) imply that for some constant <script type="math/tex">\sigma^2>0</script> the distribution of <script type="math/tex">B_{t+s}-B_s</script> is <script type="math/tex">\mathcal{N}(0, \sigma^2t)</script></p>
<p><strong><em>Definition</em></strong> Given a SBM <script type="math/tex">B_t</script>, <script type="math/tex">W_t = \mu t + \sigma B_t</script> is a Brownian motion with drift <script type="math/tex">\mu</script> and variance <script type="math/tex">\sigma^2</script>.</p>
<p><strong><em>Proposition</em></strong> Given a SBM <script type="math/tex">B_t</script>, its reflection <script type="math/tex">-B_t</script> is also a SBM.</p>
<p><strong><em>Proposition</em></strong> Given a SBM <script type="math/tex">B_t</script>, then for any <script type="math/tex">\alpha \in\mathbb{R}^+</script>, <script type="math/tex">\tilde{B} := B_{\alpha t}/\sqrt{\alpha}</script> is a SBM</p>
<h2 id="Quadratic-Variation"><a href="#Quadratic-Variation" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h2><p><strong><em>Definition</em></strong> The <strong>nth level quadratic variation</strong> of a function <script type="math/tex">f: [0,t] \rightarrow \mathbb{R}</script> is the sum of squares of the increments across intervals of length <script type="math/tex">2^{-n}</script>:</p>
<script type="math/tex; mode=display">QV(f; n; [0,t]) = \sum_{k=1}^{2^nt} [f(\dfrac{k}{2^n})] - f(\dfrac{k-1}{2^n})]^2</script><p><strong><em>Theorem</em></strong> Given a SBM <script type="math/tex">W_t</script> with drift <script type="math/tex">\mu</script> and variance <script type="math/tex">\sigma^2 > 0</script>, then for all <script type="math/tex">t>0</script> with probability <script type="math/tex">1</script>:</p>
<script type="math/tex; mode=display">\lim_{n\rightarrow\infty} QV(W; n; [0, t]) = \sigma^2t</script><h2 id="Strong-Markov-Property"><a href="#Strong-Markov-Property" class="headerlink" title="Strong Markov Property"></a>Strong Markov Property</h2><p><strong><em>Definition</em></strong> Given a SBM <script type="math/tex">B_t</script>, a <strong>stoping time</strong> is a non-negative random variable <script type="math/tex">T</script> such that for every fixed <script type="math/tex">t \geq 0</script>, the event <script type="math/tex">\{T \leq t\}</script> depends only on the path <script type="math/tex">\{B_s\}_{s\leq t}</script></p>
<p><strong><em>Theorem</em></strong> If <script type="math/tex">W_t</script> is a Brownian motion and <script type="math/tex">T</script> is a stopping time then the <strong>strong Markov property</strong> holds:<br>(a) the process <script type="math/tex">\{B_{t+T} - B_T\}_{t\geq 0}</script> is a Brownian motion, and<br>(b) the process <script type="math/tex">\{B_{t+T} - B_T\}_{t\geq 0}</script> is independent of the path <script type="math/tex">\{B_s\}_{s\leq T}</script></p>
<p><strong><em>Theorem</em></strong> Run Brownian motion <script type="math/tex">W_t</script>, at the first time <script type="math/tex">\tau</script> that <script type="math/tex">W_{\tau} = a > 0</script>, reflect the path in the line <script type="math/tex">y=a</script>, by the <strong>reflection principle</strong> the new process <script type="math/tex">W^{\ast}_t</script> is another Brownian motion:</p>
<ul>
<li>for <script type="math/tex">t \leq \tau</script>, <script type="math/tex">W^{\ast}_t = W_t</script></li>
<li>for <script type="math/tex">t > \tau</script>, <script type="math/tex">W^{\ast}_t = 2a - W_t</script></li>
</ul>
<p><strong><em>Corollary</em></strong> <script type="math/tex">P[\tau \leq s] = 2P[W_s > a]</script></p>
<p><strong><em>Corollary</em></strong> <script type="math/tex">M_t := max_{s \leq t} W_s</script> has the same distribution as <script type="math/tex">|W_s|</script></p>
<p><strong><em>Corollary</em></strong> <script type="math/tex">-M_t^- := -min_{s \leq t} W_s</script> has the same distribution as <script type="math/tex">M_t</script>. Hence <script type="math/tex">P[M_t>a]=P[-M_t^-<-a]=2P[W_t>a]>0</script>. Consequently, for every <script type="math/tex">t>0</script> with probability 1 <script type="math/tex">M_t>0</script> adn <script type="math/tex">M_t^-<0</script>. Therefore for every <script type="math/tex">\epsilon>0</script>, the Brownian path crosses the t-axis infinitely many times by time <script type="math/tex">\epsilon</script></p>
<h2 id="Martingales-In-Continuous-Times"><a href="#Martingales-In-Continuous-Times" class="headerlink" title="Martingales In Continuous Times"></a>Martingales In Continuous Times</h2><p><strong><em>Definition</em></strong> A <strong>filtration</strong> is a nested family of <script type="math/tex">\sigma</script>-algebra indexed by time <script type="math/tex">t</script>.</p>
<p><strong><em>Definition</em></strong> The <strong>natural filtration</strong> for a Brownian motion <script type="math/tex">W_t</script> is the filtration with <script type="math/tex">\mathcal{F}_t</script>-the collection of all events determined by Brownian path up to time <script type="math/tex">t</script>.</p>
<p><strong><em>Definition</em></strong> A continuous-time stohastic process X_t is a martingale relative to a filtration <script type="math/tex">\mathcal{F_t}_{t\geq 0}</script> if:<br>(a) each random variable <script type="math/tex">X_t</script> is measurable w.r.t. <script type="math/tex">\mathcal{F_t}</script> and<br>(b) for any <script type="math/tex">s, t\geq 0</script>, <script type="math/tex">\mathbb{E}(X_{t+s}|\mathcal{F}_t)=X_t</script></p>
<p><strong><em>Proposition</em></strong> Given a SBM <script type="math/tex">B_t</script> then each of these is a martingale relative to the natural filtration:<br>(a) <script type="math/tex">B_t</script><br>(b) <script type="math/tex">B_t^2 - t</script><br>(c) <script type="math/tex">e^{\theta B_t - \theta^2t/2}</script></p>
<p><strong><em>Theorem</em></strong> Define <script type="math/tex">P_{\theta}</script> to be the probability measure with likehood ratio <script type="math/tex">Z_t^{\theta} = dP_{\theta}/dP_0= e^{\theta B_t - \theta^2t/2}</script>. The <strong>Cameron-Martin</strong> theorem states that the SBM <script type="math/tex">B_t</script> under <script type="math/tex">P_0</script> is a Brownian motion with drift <script type="math/tex">\theta</script> and variance <script type="math/tex">\sigma^2=1</script> under <script type="math/tex">P_{\theta}</script>.</p>
<p><strong><em>Corollary</em></strong> For any real value <script type="math/tex">\theta, \eta</script> and <script type="math/tex">t <\infty</script></p>
<script type="math/tex; mode=display">\dfrac{dP_{\theta}}{dP_{\eta}} = \dfrac{e^{\theta B_t - \theta^2t/2}}{e^{\eta B_t - \eta^2t/2}}</script><p><strong><em>Corollary</em></strong> For any stopping time <script type="math/tex">\tau</script> and <script type="math/tex">T <\infty</script>,</p>
<script type="math/tex; mode=display">P_{\theta}[\tau \leq T] = \mathbb{E}_{\eta}\textbf{1}\{\tau \leq T\}\dfrac{e^{\theta B_t - \theta^2t/2}}{e^{\eta B_t - \eta^2t/2}}</script><h1 id="Ito-Calculus"><a href="#Ito-Calculus" class="headerlink" title="Ito Calculus"></a>Ito Calculus</h1><h2 id="Ito-Integral"><a href="#Ito-Integral" class="headerlink" title="Ito Integral"></a>Ito Integral</h2><p><strong><em>Definition</em></strong> If <script type="math/tex">X_t</script> is an uniformally bounded process with continuous paths <script type="math/tex">t \rightarrow X_t</script> adapted to <script type="math/tex">\mathcal{F_t}</script> then we can define an <strong>Ito Integral</strong> <script type="math/tex">I_t(X)</script>, where <script type="math/tex">X^{(n)}</script> is <script type="math/tex">X</script> truncted at <script type="math/tex">\pm n</script> :</p>
<script type="math/tex; mode=display">I_t(X)= \int_0^t X_sdW_s = \lim_{n\rightarrow\infty} I_t(X^{(n)})</script><p><strong><em>Property</em></strong> The Ito Integral satisfy the following properties:<br>(1) Linearity: ô°<script type="math/tex">\int (aX_s +bY_s)dW_s = a\int X_sdW_s + b\int Y_sdW_s</script>.<br>(2) Continuity: the paths <script type="math/tex">t \rightarrow \int_0^t X_sdW_s</script> are continuous.<br>(3) Mean Zero: <script type="math/tex">\mathbb{E} \int_0^t X_sdW_s = 0</script><br>(4) Varianceï¼ a.k.a. <strong>Ito Isometry</strong>:</p>
<script type="math/tex; mode=display">\mathbb{E}(\int_0^t X_sdW_s)^2 = \mathbb{E}\int_0^t X_s^2ds = \int_0^t \mathbb{E}X_s^2ds</script><p><strong><em>Defintion</em></strong> Define the <strong>quadratic variation</strong> of the Ito Itegral:</p>
<script type="math/tex; mode=display">[I_t(X), I_t(X)] = \int_0^t X^2_sds</script><p><strong><em>Proposition</em></strong><br>(a) The process <script type="math/tex">I_t(X)</script> is a martingale<br>(b) The process <script type="math/tex">I_t(X)^2 - [I_t(X), I_t(X)]</script> is a martingale</p>
<p><strong><em>Example</em></strong> <script type="math/tex">\int_0^T W_sdW_s = (W_T^2 - T)/2</script></p>
<p><strong><em>Example</em></strong> For any stopping time <script type="math/tex">\tau</script> and any <script type="math/tex">t < \infty</script>:</p>
<script type="math/tex; mode=display">\mathbb{E} \int_0^{t\wedge\tau} X_sdW_s = 0 \text{ provided that } \int_0^t \mathbb{E}X_s^2ds < \infty</script><p><strong><em>Theorem</em></strong> Let <script type="math/tex">W_t</script> be a SBM and let <script type="math/tex">\mathcal{F}_t</script> be the <script type="math/tex">\sigma</script>âalgebra of all events determined by the path <script type="math/tex">\{W_s\}_{s\leq t}</script>. If <script type="math/tex">Y_t</script> is any random variable with mean 0 and finite variance that is measurable with respect to <script type="math/tex">\mathcal{F}_t</script> , for some <script type="math/tex">t > 0</script>, then the <strong>Ito representation theorem</strong> claims that <script type="math/tex">\exists</script> adapted process <script type="math/tex">A_s</script> such that:</p>
<script type="math/tex; mode=display">Y_t = \int_0^t A_sdW_s \\
\text{where} \;\; \mathbb{E}Y^2 = \int_0^t \mathbb{E}A_s^2ds</script><p>This theorem is of importance in finance because it implies that in the Black-Scholes setting, every contingent claim can be hedged.</p>
<h2 id="Ito-Formula"><a href="#Ito-Formula" class="headerlink" title="Ito Formula"></a>Ito Formula</h2><p><strong><em>Theorem</em></strong> Let <script type="math/tex">W_t</script> be a SBM, and let <script type="math/tex">f: \mathbb{R} \rightarrow \mathbb{R}</script> be a twice-continuously differentiable function such that <script type="math/tex">f, f', f''</script> are all bounded (or at most have exponential growth). Then for any <script type="math/tex">t > 0</script>:</p>
<script type="math/tex; mode=display">f(W_t) = f(W_0) + \int_0^t f'(W_s)dW_s + \dfrac{1}{2} \int_0^t f''(W_s)ds</script><p><strong><em>Theorem</em></strong> Let <script type="math/tex">W_t</script> be a SBM, and let <script type="math/tex">U: [0, \infty) \times \mathbb{R} \rightarrow \mathbb{R}</script> be a twice-continuously differentiable function whose partial derivatives are all bounded. Then for any <script type="math/tex">t > 0</script>:</p>
<script type="math/tex; mode=display">dU = (U_t + \dfrac{1}{2}U_{WW})dt + U_WdW</script><p><strong><em>Proposition</em></strong> Assume <script type="math/tex">f(t)</script> is nonrandom and continuously differentiable. Then:</p>
<script type="math/tex; mode=display">\int_t^{t+h} f(s) dW_s \sim \mathcal{N}(0, \int_t^{t+h} f(s)^2 ds)</script><h2 id="Ito-Process"><a href="#Ito-Process" class="headerlink" title="Ito Process"></a>Ito Process</h2><p><strong><em>Definition</em></strong> An <strong>Ito process</strong> is a stochastic process <script type="math/tex">X_t</script> that satisfies a stochastic differential equation of the form:</p>
<script type="math/tex; mode=display">dX_t = Y_t dW_t + Z_t dt</script><p>Equivalently, <script type="math/tex">X_t</script> satisfies the stochastic integral equation:</p>
<script type="math/tex; mode=display">X_t = X_0 + \int_0^t Y_sdW_s + \int_0^t Z_sds</script><p><strong><em>Definition</em></strong> For any adapted process <script type="math/tex">U_t</script> define:</p>
<script type="math/tex; mode=display">\int_0^t U_sdX_s = \int_0^t U_sY_sdW_s + \int_0^t U_sZ_sds</script><p><strong><em>Theorem</em></strong> Let <script type="math/tex">X_t</script> be an Ito process, and let <script type="math/tex">U</script> be a twice-continuously differentiable function whose partial derivatives are all bounded. Then:</p>
<script type="math/tex; mode=display">dU = U_tdt + U_XdX_t + \dfrac{1}{2}U_{XX}d[X_t, X_T]</script><h3 id="The-Ornstein-Uhlenbeck-Process"><a href="#The-Ornstein-Uhlenbeck-Process" class="headerlink" title="The Ornstein-Uhlenbeck Process"></a>The Ornstein-Uhlenbeck Process</h3><p><strong><em>Definition</em></strong> The Ornstein-Uhlenbeck SDE: <script type="math/tex">dX_t = â\alpha X_t dt + dW_t</script><br>(a) This SDE describes a process Xt that has a proportional tendency to return to an âequilibriumâ position 0.<br>(b) In finance, the OU process is often called the <a href="https://jackliu234.com/03/">Vasicek</a> model.<br>(c) Solving the SDE: <script type="math/tex">Xt =e^{â\alpha t}X_0 + e^{-\alpha t} \int_0^t e^{\alpha s}dW_s</script><br>(d) The Ornstein-Uhlenbeck process is Gaussian.</p>
<h3 id="The-Exponential-Martingale"><a href="#The-Exponential-Martingale" class="headerlink" title="The Exponential Martingale"></a>The Exponential Martingale</h3><p><strong><em>Definition</em></strong> The Exponential Martingale SDE: <script type="math/tex">dX_t = â\theta X_t dW_t</script><br>(a) Solving the SDE: <script type="math/tex">X_t = Ce^{ â \theta^2t/2 + \theta W_t}</script></p>
<h3 id="The-Diffusion-Process"><a href="#The-Diffusion-Process" class="headerlink" title="The Diffusion Process"></a>The Diffusion Process</h3><p><strong><em>Definition</em></strong> The Diffusion SDE: <script type="math/tex">dX_t = \mu(X_t)dt+ \sigma (X_t)dW_t</script></p>
<p><strong><em>Definition</em></strong> The <strong>Harmonic Function</strong> is a function <script type="math/tex">f(x)</script> that satisfies the ODE:</p>
<script type="math/tex; mode=display">\mu (x)f'(x) + \dfrac{1}{2}\sigma^2(x)f''(x) = 0</script><p><strong><em>Example</em></strong> Let <script type="math/tex">X_t</script> be a solution of the diffusion SDE with initial value <script type="math/tex">X_0 = x_0</script>, and for any real numbers <script type="math/tex">A \leq x_0 \leq B</script> let <script type="math/tex">\tau := min\{t: X_t \notin (A, B)\}</script>. Find <script type="math/tex">P(X_{\tau} = B)</script></p>
<p>We first apply the Ito Formula to <script type="math/tex">df(X_t)</script> and observe that a harmonic function <script type="math/tex">f</script> will force the <script type="math/tex">dt</script> term to vanish. Therefore <script type="math/tex">f(X_t)</script> is a martingale and that <script type="math/tex">\mathbb{E}f(X_{\tau}) = f(x_0):</script></p>
<script type="math/tex; mode=display">f(x_0) = P(X_{\tau} = B)f(B) + (1- P(X_{\tau} = B))f(A) \\
\rightarrow P(X_{\tau} = B) = \dfrac{f(x_0) - f(A)}{f(B) - f(A)}</script><p>We can solve for <script type="math/tex">f(x)</script>:</p>
<script type="math/tex; mode=display">f(x) = \int_A^x C' e^{-\int_A^z \dfrac{2\mu(y)}{\sigma^2(y)}dy}dz + C''</script><h3 id="The-Diffusion-Process-Bassel-Process"><a href="#The-Diffusion-Process-Bassel-Process" class="headerlink" title="The Diffusion Process - Bassel Process"></a>The Diffusion Process - Bassel Process</h3><p><strong><em>Definition</em></strong> The Diffusion SDE: <script type="math/tex">dX_t = a/X_tdt+ dW_t</script></p>
<p><strong><em>Example</em></strong> Similar problem as above:</p>
<script type="math/tex; mode=display">P(X_{\tau} = B) = \dfrac{f(x_0) - f(A)}{f(B) - f(A)} \;\;\text{where}\\
f(x) = Cx^{-2a+1} + C'</script><p>Note that if <script type="math/tex">x_0 > 0</script> and <script type="math/tex">a \geq 1/2</script> then <script type="math/tex">X_t</script> will never reach <script type="math/tex">0</script>.</p>
<h2 id="Ito-Formula-Multi-Variable"><a href="#Ito-Formula-Multi-Variable" class="headerlink" title="Ito Formula - Multi-Variable"></a>Ito Formula - Multi-Variable</h2><p><strong><em>Theorem</em></strong> Let <script type="math/tex">\textbf{W}_t =(W_t^1,W_t^2,...,W_t^K)</script> be a Kâdimensional SBM, and let <script type="math/tex">u: \mathbb{R}^K \rightarrow \mathbb{R}</script> be a <script type="math/tex">C^2</script> function with bounded first and second partial derivatives. Then the <strong>Ito Formula</strong> states:</p>
<script type="math/tex; mode=display">du(\textbf{W}_t) = \nabla u(\textbf{W}_t)d\textbf{W}_t + \dfrac{1}{2} \triangle u(\textbf{W}_t)dt</script><p>Where:</p>
<script type="math/tex; mode=display">\nabla u(\textbf{W}_t) = \sum_{i=1}^K \dfrac{\partial u}{\partial x_i}(\textbf{W}_t) \\
\triangle u(\textbf{W}_t) = \sum_{i=1}^K \dfrac{\partial^2 u}{\partial x_i^2}(\textbf{W}_t)</script><p><strong><em>Corollary</em></strong> If <script type="math/tex">\tau</script> is a stopping time for the SBM <script type="math/tex">\textbf{W}_t</script> then <strong>Dynkinâs Formula</strong> shows that for any fixed time <script type="math/tex">t</script>:</p>
<script type="math/tex; mode=display">\mathbb{E} u(\textbf{W}_{t\wedge\tau}) = u(\textbf{0}) + \dfrac{1}{2} \mathbb{E} \int_0^{t\wedge\tau} \triangle u(\textbf{W}_s)ds</script><p>And that <script type="math/tex">u(\textbf{W_t})  \dfrac{1}{2} \int_0^{t} \triangle u(\textbf{W}_s)ds</script> is a martingale</p>
<p><strong><em>Definition</em></strong> A <script type="math/tex">C^2</script> function <script type="math/tex">u: \mathbb{R}^K \rightarrow \mathbb{R}</script> is said to be a <strong>Harmonic Function</strong> in a region <script type="math/tex">\mathcal{U}</script> if <script type="math/tex">\triangle u(x)=0, \; \forall x \in \mathcal{U}</script></p>
<p>(a) 2D Harmonic Function Exmaple: <script type="math/tex">u(x,y)=log(x^2 +y^2)=2logr</script><br>(b) 3D Harmonic Function Example: <script type="math/tex">u(x,y,z)=1/\sqrt{x^2 +y^2 +z^2} =1/r</script></p>
<p><strong><em>Corollary</em></strong> Let <script type="math/tex">u</script> be harmonic in the an open region <script type="math/tex">\mathcal{U}</script> with compact support, and assume that <script type="math/tex">u</script> and its partials extend continuously to the boundary <script type="math/tex">\partial\mathcal{U}</script>. Define <script type="math/tex">\tau</script> to be the first exit time of Brownian motion from <script type="math/tex">\mathcal{U}</script>, then:</p>
<p>(a) the process <script type="math/tex">u(W_t\wedge\tau)</script> is a martingale, and<br>(b) for every <script type="math/tex">x \in \mathcal{U}</script>, <script type="math/tex">\;\mathbb{E}^xu(W_{\tau}) = u(x)</script></p>
<p><strong><em>Example</em></strong> If a <strong>2D</strong> SBM starts at a point on the circle <script type="math/tex">C_1</script> of radius 1, find out the probability <script type="math/tex">p</script> that it hits concentric circles <script type="math/tex">C_2</script> before <script type="math/tex">C_{1/2}</script>.</p>
<p>Let <script type="math/tex">u(x, y) = log r</script> be harmonic. Then <script type="math/tex">u(W_t\wedge\tau)</script> is a martingale and that <script type="math/tex">\mathbb{E} u(W_t\wedge\tau) = u(W_0) = log(1) = 0</script>.</p>
<script type="math/tex; mode=display">\mathbb{E} u(W_t\wedge\tau) = (p)log2 + (1-p)log(1/2) = 0 \\
\rightarrow p = 1/2</script><p><strong><em>Example</em></strong> If a <strong>3D</strong> SBM starts at a point on the sphere <script type="math/tex">C_1</script> of radius 1, find out the probability <script type="math/tex">p</script> that it hits concentric sphere <script type="math/tex">C_2</script> before <script type="math/tex">C_{1/2}</script>.</p>
<p>Let <script type="math/tex">u(x, y) = 1/r</script> be harmonic. Then <script type="math/tex">u(W_t\wedge\tau)</script> is a martingale and that <script type="math/tex">\mathbb{E} u(W_t\wedge\tau) = u(W_0) = 1/1 = 1</script>.</p>
<script type="math/tex; mode=display">\mathbb{E} u(W_t\wedge\tau) = (p)1/2 + (1-p)1/(1/2) = 1 \\
\rightarrow p = 2/3</script><h2 id="Ito-Process-Multi-Variable"><a href="#Ito-Process-Multi-Variable" class="headerlink" title="Ito Process - Multi-Variable"></a>Ito Process - Multi-Variable</h2><p><strong><em>Definition</em></strong> An <strong>Ito process</strong> is a continuous-time stochastic process <script type="math/tex">X_t</script> of the form:</p>
<script type="math/tex; mode=display">X_t = X_0 + \int_0^t M_sds + \int_0^t \textbf{N}_s d\textbf{W}_s</script><p>Where the quadratic variation <script type="math/tex">d[X_t, X_t] = \textbf{N}_t \cdot \textbf{N}_t dt</script></p>
<p>Let <script type="math/tex">\textbf{X}_t = (X^1_t,X^2_t,...,X^m_T)</script> be a vector of Ito processes. For any <script type="math/tex">C^2</script> function <script type="math/tex">u:\mathbb{R}^m \rightarrow \mathbb{R}</script> with bounded first and second partial derivatives, then:</p>
<script type="math/tex; mode=display">du(\textbf{X}_t) = \sum_{i=1}^m u_{X_i}(\textbf{X}_t)dXi + \dfrac{1}{2} \sum_{i=1}^m \sum_{j=1}^m u_{X^iX^j}(\textbf{X}_t)d[X^i_t, X^j_t]</script><p><strong><em>Theorem</em></strong> Let <script type="math/tex">\textbf{W}_t</script> be a K âdimensional SBM, and let <script type="math/tex">\textbf{U}_t</script> be an adapted, Kâdimensional process satisfying <script type="math/tex">|\textbf{U}_t|=1, \;\;\forall t \geq 0</script>. Then the <strong>Knightâs Theorem</strong> states that the 1-dimensional Ito process <script type="math/tex">X_t</script> is a SBM:</p>
<script type="math/tex; mode=display">X_t := \int_0^t \textbf{U}_s d\textbf{W}_s</script><p><strong><em>Proposition</em></strong> Let <script type="math/tex">\textbf{W}_t</script> be a K âdimensional SBM. Define <script type="math/tex">R_t := |\textbf{W}_t|</script> be the <strong>radial part</strong> of <script type="math/tex">\textbf{W}_t</script>. Then <script type="math/tex">R_t</script> is a <strong>Bessel process</strong> with parameter <script type="math/tex">(K-1)</script>:</p>
<script type="math/tex; mode=display">dR_t = (K-1)/2R_t \; dt + d\tilde{W}_t \\
\text{where}\;\; \tilde{W}_t := \int_0^t \dfrac{\textbf{W}_s}{|\textbf{W}_s|}d\textbf{W}_s \;\;\text{is a 1-D SBM}</script><h1 id="Barrier-Option"><a href="#Barrier-Option" class="headerlink" title="Barrier Option"></a>Barrier Option</h1><h2 id="Pricing"><a href="#Pricing" class="headerlink" title="Pricing"></a>Pricing</h2><p><strong><em>Definition</em></strong> A <strong>barrier option</strong> at time <script type="math/tex">T</script> pays:<br>(a) <script type="math/tex">\</script>1<script type="math/tex">if</script>max_{0 \leq t \leq T}\;S_t \geq AS_0$,<br>(b) <script type="math/tex">\</script>0$ otherwise.</p>
<p>Assume that <script type="math/tex">S_t</script> follows GBM:</p>
<script type="math/tex; mode=display">dS_t = rS_tdt + \sigma S_tdW_t \\
\rightarrow S_t = S_0e^{(r-\sigma^2/2)t + \sigma W_t}</script><p>The no-arbitrage price <script type="math/tex">V_t</script> of the barrier option at <script type="math/tex">t=0</script> is the expected payoff:</p>
<script type="math/tex; mode=display">\begin{align}
V_0 &= \mathbb{E}\textbf{1}_{max_{0 \leq t \leq T}\;S_t \geq AS_0}\\
&= e^{-rT}\mathbb{P}\{max_{0 \leq t \leq T}\;S_t \geq AS_0\} \\
&= e^{-rT}\mathbb{P}\{max_{0 \leq t \leq T}\;W_t + (r/\sigma -\sigma/2)t \geq (logA)/\sigma\} \;\;\text{[GBM]}\\
&= e^{-rT}\mathbb{P}\{max_{0 \leq t \leq T}\;W_t + \mu t \geq a\} \\
&= e^{-rT}\mathbb{P}_{\mu}\{max_{0 \leq t \leq T}\;W_t \geq a\} \;\;\text{[Cameron-Martin Theorem]}\\
&= e^{-rT}\mathbb{E} \;Z^{\mu}_T \;\textbf{1}_{\{max_{0 \leq t \leq T}\;W_t \geq a\}}\\
&= e^{-rT}\mathbb{E} \;e^{-\mu^2T/2 + \mu W_T} \;\textbf{1}_{\{max_{0 \leq t \leq T}\;W_t \geq a\}}\\
&= e^{-rT}e^{-\mu^2T/2} \mathbb{E} \;e^{\mu W_T} \;\textbf{1}_{\{max_{0 \leq t \leq T}\;W_t \geq a\}}\\
&= e^{-rT}e^{-\mu^2T/2} \dfrac{1}{2}[\Phi(\mu\sqrt{T}-a/\sqrt{T}) + e^{2\mu a}\Phi(-\mu\sqrt{T}-a/\sqrt{T})]\;\;\text{[Reflection Principle]}\\
\end{align}</script><p>At time <script type="math/tex">t</script>, there are two possibilities:<br>(a) if <script type="math/tex">max_{0 \leq r \leq t}\;S_r \geq AS_0</script>, then <script type="math/tex">V_t = e^{-r(T-t)}</script><br>(b) if <script type="math/tex">max_{0 \leq r \leq t}\;S_r \leq AS_0</script>, then <script type="math/tex">V_t</script> is the same as the time-<script type="math/tex">0</script> value <script type="math/tex">V_0</script> of a barrier option with time-to-maturity <script type="math/tex">T-t</script> and <script type="math/tex">A'=AS_0/S_t</script></p>
<h2 id="Hedging"><a href="#Hedging" class="headerlink" title="Hedging"></a>Hedging</h2><p>Let <script type="math/tex">v(t, S_t)</script> be the value of the barrier option at time <script type="math/tex">t</script>. The Fundamental Theorem and Ito Formula show that v(t, S_t satisfy the Black-Scholes PDE:</p>
<script type="math/tex; mode=display">rv = v_t + rSv_S + \dfrac{1}{2}\sigma^2S^2v_{SS} \\
\text{for} \;\; t \leq T \;\;\text{and}\;\; x\leq AS_0</script><p>A <strong>replicating portfolio</strong> for the barrier option holds<br>(a) <script type="math/tex">v_S</script> share of stock<br>(b) <script type="math/tex">e^{-rt}(v - v_SS)</script> share of cash</p>
<p>provided that <script type="math/tex">S_t\leq AS_0</script>. Once <script type="math/tex">S_t\geq AS_0</script> the portfolio convert all holdings to cash and hold till maturity.</p>
<h1 id="The-Black-Scholes"><a href="#The-Black-Scholes" class="headerlink" title="The Black-Scholes"></a>The Black-Scholes</h1><h2 id="The-Black-Scholes-Formula"><a href="#The-Black-Scholes-Formula" class="headerlink" title="The Black-Scholes Formula"></a>The Black-Scholes Formula</h2><p><strong><em>Theorem</em></strong> Under a risk-neutral <script type="math/tex">P</script>, the <strong>Fundamental Theorem</strong> asserts that discounted share price <script type="math/tex">S_t/M_t</script> is a martingale, where:</p>
<script type="math/tex; mode=display">dM_t = r_tM_tdt, \;\;\text{and}\;\; dS_t = \mu_t S_tdt + \sigma S_tdW_t</script><p>Therefore <script type="math/tex">\mu_t \equiv r_t</script>:</p>
<script type="math/tex; mode=display">\mathbb{E}[\dfrac{S_t}{M_t}] = \mathbb{E}[\dfrac{S_0}{M_0}e^{\int_0^t \mu_sds - \sigma^2t/2 + \sigma W_t - \int_0^t r_sds}] \\
\rightarrow \dfrac{S_t}{M_t} = \dfrac{S_0}{M_0}e^{- \sigma^2t/2 + \sigma W_t}</script><p><strong><em>Definition</em></strong> A <strong>European contingent claim</strong> with expiration date <script type="math/tex">T > 0</script> and payoff function <script type="math/tex">f: \mathbb{R}\rightarrow\mathbb{R}</script> is a tradeable asset with:<br>(a) share price at time <script type="math/tex">T</script>: <script type="math/tex">f(S_T)</script><br>(b) discounted share price at time <script type="math/tex">t < T</script>: <script type="math/tex">\mathbb{E}[f(S_T)/M_T | \mathcal{F}_t]</script></p>
<p><strong><em>Proposition</em></strong> Let <script type="math/tex">W_t</script> be a standard Brownian motion and <script type="math/tex">g:\mathbb{R}\rightarrow\mathbb{R}</script> is a function such that <script type="math/tex">\mathbb{E}|g(W_T)| < \infty</script>. Then for every <script type="math/tex">0 \leq t \leq T</script>:</p>
<script type="math/tex; mode=display">\mathbb{E}(g(W_T) | \mathcal{F}_t)=u(Tât,W_t) \;\;\text{where} \\
u(T-t, x)= \dfrac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} g(x+\sqrt{T-t}z)e^{-z^2/2} dz</script><p><strong><em>Corollary</em></strong> Given <script type="math/tex">dS_t = r_t S_tdt + \sigma S_tdW_t</script>, the <strong>Black Scholes Formula</strong> shows:</p>
<script type="math/tex; mode=display">\mathbb{E}(f(S_T)/M_T | \mathcal{F}_t) = v(Tât,S_t)/M_T \;\;\text{where} \\
v(T-t, x)= \dfrac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} f(xe^{\sigma\sqrt{T-t}z - \sigma^2(T-t)/2 + \int_0^T r_sds - \int_0^t r_sds})e^{-z^2/2} dz</script><p>Under risk-neutral <script type="math/tex">P</script>, the time <script type="math/tex">t</script> option price <script type="math/tex">u(t,S_t)/M_T</script> is a martingale. With the Ito Formula we can set the drift of <script type="math/tex">du</script> to be zero and therefore derive the <strong>Black Scholes PDE</strong>:</p>
<script type="math/tex; mode=display">-r_tu + u_t + r_tSu_S + \dfrac{1}{2}\sigma^2S^2u_{SS} = 0 \\
\text{with terminal condition} \;\; u(T, S_T) = f(S_T)</script><h2 id="Hedging-In-Continuous-Times"><a href="#Hedging-In-Continuous-Times" class="headerlink" title="Hedging In Continuous Times"></a>Hedging In Continuous Times</h2><p><strong><em>Definition</em></strong> A portfolio <script type="math/tex">V_t = \alpha_t M_t + \beta_t S_t</script> is <strong>self-financing</strong> if <script type="math/tex">dV_t = \alpha_t dM_t + \beta_t dS_t</script> for all <script type="math/tex">t \leq T</script></p>
<p><strong><em>Proposition</em></strong> A portfolio <script type="math/tex">V_t</script> is self-financing if and only if its discounted value <script type="math/tex">V_t/M_t</script> is a martingale and satisfies:</p>
<script type="math/tex; mode=display">V_t/M_t = V_0/M_0 + \int_0^t\beta_s\sigma S_s/M_s \;dW_s</script><p><strong><em>Definition</em></strong> A <strong>replicating portfolio</strong> <script type="math/tex">V_t</script> for a payoff function <script type="math/tex">f(S_T)</script> is a self-financing portfolio such that <script type="math/tex">V_T = f(S_T)</script></p>
<p><strong><em>Theorem</em></strong> A replicating portfolio for contingent claims <script type="math/tex">f(S_T)</script> is given by:<br>(a) <script type="math/tex">\alpha_t = (u - u_SS_t)/M_t</script> cash, and<br>(b) <script type="math/tex">\beta_t = u_S</script> shares of stock</p>
<p>where u is the solution of the Black Scholes PDE satisfying <script type="math/tex">u(T, S_T) = f(S_T)</script></p>
<h1 id="The-Girsanov-Theorem"><a href="#The-Girsanov-Theorem" class="headerlink" title="The Girsanov Theorem"></a>The Girsanov Theorem</h1><p><strong><em>Proposition</em></strong> The exponential process <script type="math/tex">Z_t</script> is a positive martingale.</p>
<script type="math/tex; mode=display">Z_t := e^{\int_0^t Y_sdW_s - \dfrac{1}{2}\int_0^t Y_s^2ds} \\
\text{given}\;\; \mathbb{E}\int_0^t Z_s^2Y_s^2 ds < \infty \;\;\forall t < \infty</script><p>Applying Ito Formula <script type="math/tex">Z_t = 1 + \int_0^t Z_sY_sdW_s</script> and therefore  <script type="math/tex">\mathbb{E}Z_t = 1</script></p>
<p><strong><em>Therorem</em></strong> Given <script type="math/tex">W_t</script> a SBM under <script type="math/tex">P</script>-measure and the likelihood ratio <script type="math/tex">Z_t</script>, define the <script type="math/tex">Q</script>-measure where <script type="math/tex">dQ/dP = Z_t</script>. Then the <strong>Girsanovâs Theorem</strong> states that under the <script type="math/tex">Q</script>-measure:<br>(a) <script type="math/tex">\tilde{W}_t = W_t - \int_0^t Y_sds</script> is a SBM<br>(b) <script type="math/tex">W_t</script> is a BM with time-dependent drift <script type="math/tex">\int_0^t Y_sds</script></p>
<p><strong><em>Example 1</em></strong> Given <script type="math/tex">W_t</script> a brownian motion with <script type="math/tex">W_0 \in (0, A)</script>, define measure <script type="math/tex">Q</script> be the <strong>conditional probability measure</strong> on event <script type="math/tex">\{W_T = A\}</script>. Therefore <script type="math/tex">W_t</script> is a BM with drift <script type="math/tex">W_t^{-1}dt</script>.</p>
<p>Proof. We know that <script type="math/tex">\mathbb{P}[W_T = A] = W_0/A</script>, therefore by change of measure:</p>
<script type="math/tex; mode=display">\begin{align}
\dfrac{dQ}{dP}|\mathcal{F_T} &= \dfrac{\textbf{1}\{W_T = A\}}{\mathbb{P}[W_T = A]} \\
\dfrac{dQ}{dP}|\mathcal{F_{T\wedge t}} &= \mathbb{E}[(\dfrac{dQ}{dP}|\mathcal{F_T})| \mathcal{F_{T\wedge t}}] \;\;\text{[Since LR is a martingale]}\\
&= \dfrac{\mathbb{P}[W_T = A | \mathcal{F}_{T\wedge t}]}{\mathbb{P}[W_T = A]} \\
&= W_{T\wedge t}/W_0 \\
&= e^{\int_0^{T\wedge t} W_s^{-1}ds - \dfrac{1}{2}\int_0^{T\wedge t} W_s^{-2}ds} \;\;\text{[Ito Formula]} \\
\end{align}</script><p>Therefore Girsanovâs Theorem implies that under <script type="math/tex">Q</script>, <script type="math/tex">\tilde{W}_t = W_t - \int_0^{T\wedge t} W_s^{-1}ds</script> is a SBM.</p>
<p><strong><em>Example 2</em></strong> Given currency <script type="math/tex">A, B</script> and their respective bank account <script type="math/tex">dA_t = r^A_tA_tdt</script> and <script type="math/tex">dB_t = r^B_tB_tdt</script>. Define exchange rate (# B per A) <script type="math/tex">Y_t</script> that <script type="math/tex">dY_t = \mu_t Y_tdt + \sigma Y_tdW_t</script></p>
<p><strong><em>Theorem</em></strong> If <script type="math/tex">W_t</script> is a SBM under measure <script type="math/tex">Q^B</script> then <script type="math/tex">\mu_t = r^B_t - r^A_t</script>.</p>
<p>Proof. <script type="math/tex">Y_t(A_t/B_t)</script> is a martingale only if <script type="math/tex">\mu_t = r^B_t - r^A_t</script></p>
<p><strong><em>Theorem</em></strong></p>
<script type="math/tex; mode=display">\dfrac{dQ^A}{dQ^B} | \mathcal{F}_T = e^{-\sigma^2T/2 + \sigma W_T} = Y_T(A_T/B_T)</script><h1 id="Levy-Process"><a href="#Levy-Process" class="headerlink" title="Levy Process"></a>Levy Process</h1><h2 id="Poisson-Process"><a href="#Poisson-Process" class="headerlink" title="Poisson Process"></a>Poisson Process</h2><p><strong><em>Definition</em></strong> A <strong>Levy process</strong> is a continuous-time random process <script type="math/tex">\{X_t\}_{t\geq 0}</script> such that <script type="math/tex">X_0 = 0</script> and:<br>(a) <script type="math/tex">X_t</script> has stationary increments;<br>(b) <script type="math/tex">X_t</script> has independent increments;<br>(c) the sample paths <script type="math/tex">t \rightarrow</script>X_t$ are right-continuous.</p>
<p>Note that Brownian motion and Poisson process are both Levy processes and the basic building blocks of Levy processes. Brownian motion is the only Levy process with continuous paths.</p>
<p><strong><em>Example</em></strong> Let <script type="math/tex">W_t</script> be a SBM and for <script type="math/tex">a \geq 0</script>, the random variable <script type="math/tex">\tau_a</script> is a Levy process.</p>
<script type="math/tex; mode=display">\tau_a = inf\{t>0: W_t>a\}</script><p>Note that:<br>(a) <script type="math/tex">\tau_a</script> has stationary, independent increments<br>(b) <script type="math/tex">\tau_{ab}</script> has the same distribution as <script type="math/tex">b^2\tau_a</script></p>
<p><strong><em>Definition</em></strong> A <strong>Poisson process</strong> with rate <script type="math/tex">\lambda > 0</script> is a Levy process <script type="math/tex">N_t</script> such that for all <script type="math/tex">t \geq 0</script> the random variable <script type="math/tex">N_t</script> follows Poisson distribution with mean <script type="math/tex">\lambda t</script>:</p>
<script type="math/tex; mode=display">P[N_t = k] = \dfrac{(\lambda t)^k}{k!}e^{-\lambda t}</script><p><strong><em>Proposition</em></strong> If <script type="math/tex">X, Y</script> are independent Poisson distributions with mean <script type="math/tex">\lambda, \mu</script>, then <script type="math/tex">X+Y \sim Poisson(\lambda + \mu)</script>.</p>
<p>Proof. <script type="math/tex">P(X+Y=n) = \sum_{m=0}^nP(X=m \;\;\text{and}\;\; Y=n-m)</script></p>
<p><strong><em>Corollary</em></strong> IF <script type="math/tex">N_t, M_t</script> are independent Poisson processes with rates <script type="math/tex">\lambda, \mu</script> then the <strong>superposition</strong> <script type="math/tex">N_t + M_t</script> is a Poisson process with rate <script type="math/tex">\lambda + \mu</script></p>
<p><strong><em>Proposition</em></strong> Every discontinuity of a Poisson process is of size <script type="math/tex">1</script></p>
<p><strong><em>Proposition</em></strong> Let <script type="math/tex">N_t</script> be a Poisson process of rate <script type="math/tex">\lambda > 0</script>, and let <script type="math/tex">\xi_i</script> be an independent sequence of i.i.d. Bernoulliâ<script type="math/tex">p</script> random variables. Then the <strong>Thinning Theorem</strong> states that <script type="math/tex">N^S_t, N^F_t</script> are independent Poisson processes with rates <script type="math/tex">\lambda p, \lambda (1-p)</script>:</p>
<script type="math/tex; mode=display">N^S_t = \sum_{i=1}^{N_t} \xi_i \sim Poission(\lambda p) \\
N^F_t = \sum_{i=1}^{N_t} (1 - \xi_i) \sim Poission(\lambda(1-p))</script><p><strong><em>Theorem</em></strong> If <script type="math/tex">n \rightarrow \infty</script> and <script type="math/tex">p_n \rightarrow 0</script> in such a way that <script type="math/tex">np_n \rightarrow \lambda > 0</script>, then the <strong>Law of Small Numbers</strong> states that the <script type="math/tex">Binomial(n, p_n)</script> distribution converges to the <script type="math/tex">Poisson(\lambda)</script> distribution.</p>
<p><strong><em>Proposition</em></strong> If <script type="math/tex">N_t</script> is a rateâ<script type="math/tex">\lambda</script> Poisson process, then for any real number <script type="math/tex">\theta</script> the process <script type="math/tex">Z_t :=e^{\theta N_t + (\lambda - \lambda e^{\theta})t}</script>ô° is a martingale.</p>
<p><strong><em>Theorem</em></strong> Define <script type="math/tex">Q</script> with likelihood ratio <script type="math/tex">Z_t</script> such that <script type="math/tex">dQ/dP | \mathcal{F}_t = Z_t</script>. Then under <script type="math/tex">Q</script> the process <script type="math/tex">N_t</script> is a rate-<script type="math/tex">-\lambda e^{\theta}</script> Poisson process.</p>
<h2 id="Compound-Poisson-Process"><a href="#Compound-Poisson-Process" class="headerlink" title="Compound Poisson Process"></a>Compound Poisson Process</h2><p><strong><em>Definition</em></strong> A <strong>compound Poisson process</strong> <script type="math/tex">X_t</script> is a Levy process of the form:</p>
<script type="math/tex; mode=display">X_t = \sum_{i=1}^{N_t} Y_i</script><p>Where <script type="math/tex">N_t</script> is rate-<script type="math/tex">\lambda</script> Poisson process and <script type="math/tex">Y_i</script> are i.i.d. random variable independent of <script type="math/tex">N_t</script>. The distribution <script type="math/tex">F_{Y}</script> is the <strong>compounding distribution</strong> and the measure <script type="math/tex">\lambda \times F_{Y}</script> is the <strong>Levy measure</strong>.</p>
<p>At each <script type="math/tex">T_i \in N_t</script>, a random <script type="math/tex">Y_i</script> is draw from <script type="math/tex">F_{Y}</script>. <script type="math/tex">X_t</script> is the sum of all draws made by time <script type="math/tex">t</script></p>
<p><strong><em>Proposition</em></strong> If <script type="math/tex">\psi(\theta) = \mathbb{E}e^{\theta Y_i} < \infty</script>, then <script type="math/tex">\mathbb{E} e^{\theta X_t} = e^{-t\lambda (1- \psi(\theta))}</script>, and <script type="math/tex">\theta \in \mathbb{R}</script>, <script type="math/tex">Z_t^{\theta} = e^{\theta X_t - \lambda t(\psi(\theta)-1)}</script> is an <strong>exponential martingale</strong>.</p>
<h2 id="Poisson-Point-Process"><a href="#Poisson-Point-Process" class="headerlink" title="Poisson Point Process"></a>Poisson Point Process</h2><p><strong><em>Definition</em></strong> Let <script type="math/tex">\mu</script> be a <script type="math/tex">\sigma</script>âfinite Borel measure on <script type="math/tex">\mathbb{R}^n</script>. A <strong>Poisson point process</strong> <script type="math/tex">\mathcal{P}</script> with intensity measure <script type="math/tex">\mu</script> is a collection <script type="math/tex">\{N_B\}_{B\in\mathcal{B}}</script> of extended nonnegative integer-valued random variables such that<br>(A) If <script type="math/tex">\mu(B) = \infty</script> then <script type="math/tex">N_B = \infty</script> a.s.<br>(B) If <script type="math/tex">\mu(B) < \infty</script> then <script type="math/tex">N_B \sim Poisson(\mu(B))</script><br>(C) If <script type="math/tex">\{N_i\}_{i\in\mathbb{N}}</script> are pairwise disjoint, then the r.v.s <script type="math/tex">N_{B_i}</script> are independent, and <script type="math/tex">N_{\cup_i B_i} = \sum_{i=1}^{\infty} N_{B_i}</script></p>
<p><strong><em>Proposition</em></strong> The point process <script type="math/tex">(T_n, Y_n)</script> associated with a CPP is a <strong>Poisson point process</strong> with intensity measure <script type="math/tex">Lebesgue \times v</script>, where <script type="math/tex">v=\lambda F</script> is the Levy measure for the CPP.</p>
<p><strong><em>Theorem</em></strong> Let <script type="math/tex">X_t</script> be any Levy process, and let <script type="math/tex">J</script> be the random set of points <script type="math/tex">(t,y) \in [0,\infty) \times \mathbb{R}</script> such that the Levy process <script type="math/tex">X</script> has a jump discontinuity of size <script type="math/tex">y</script> at time <script type="math/tex">t</script>, i.e.,</p>
<script type="math/tex; mode=display">X_t â X_{tâ} = y</script><p>Then <script type="math/tex">J</script> is a Poisson point process with intensity measure <script type="math/tex">Lebesgue \times v</script> where <script type="math/tex">v</script> is a <script type="math/tex">\sigma</script>âfinite measure called the Levy measure of the process.</p>
<p><br><br><br></p>
<p>Reference:</p>
<ul>
<li>Stochastic Calculus: An Introduction with Applications, Gregory F. Lawler</li>
<li>FINM 34500 Lecture Notes, Steve Lalley, the University of Chicago</li>
</ul>
</div></article></div></main><footer><div class="paginator"><a href="/2019/03/foreign-exchange-market/" class="prev">PREV</a><a href="/2019/03/generate-color-image/" class="next">NEXT</a></div><div id="container"></div><!-- link(rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css")--><link rel="stylesheet" href="/css/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
    clientID: '4ec287ddd4ac34ff5087',
    clientSecret: 'ae45426765f12ac3e2f903662b8938dc4881f703',
    repo: 'jackliu234.github.io',
    owner: 'jackliu234',
    admin: ['jackliu234'],
    perPage: 100,
    id: 'Sun Mar 10 2019 00:00:00 GMT-0600 GMT'.split('GMT')[0].replace(/\s/g, '-'),
    distractionFreeMode: false,
    pagerDirection: 'first'
})

gitalk.render('container')</script><!-- block copyright--></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-133275176-1",'auto');ga('send','pageview');</script><link rel="stylesheet" href="//cdn.datatables.net/1.10.7/css/jquery.dataTables.min.css" media="screen" type="text/css"><script src="//cdn.datatables.net/1.10.7/js/jquery.dataTables.min.js"></script><script>$(function(){$('.datatable').dataTable( {"order": [[ 0, "desc" ]],"iDisplayLength": -1,"lengthMenu": [[10, 25, 50, -1], [10, 25, 50, "All"]]} );});</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></body></html>