<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>Bitcoin Analysis (1): A Classification Approach · Rongjia Liu</title><meta name="description" content="Bitcoin Analysis (1): A Classification Approach - Rongjia Liu"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/arctic.css"><link rel="search" type="application/opensearchdescription+xml" href="http://jackliu234.com/atom.xml" title="Rongjia Liu"><script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/search/" target="_self" class="nav-list-link">SEARCH</a></li><!-- li.nav-list-item--><!--    a.nav-list-link(class="search" href=url_for("search") target="_self") <i class="fa fa-search" aria-hidden="true"></i>--></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Bitcoin Analysis (1): A Classification Approach</h1><div class="post-info">Jul 20, 2019<span id="busuanzi_container_page_pv">| Page Views:</span><span id="busuanzi_value_page_pv"></span><span>| &nbsp;</span><a href="/tags/Tech/" class="post-tags">#Tech</a><!-- if item.from && (is_home() || is_post())--><!--    a.post-from(href=item.from target="_blank" title=item.from)!= __('translated')-->
</div><div class="post-content"><p>In this research I looked at intraday Bitcoin trading based on price and volume information using classification models.</p>
<table>
  <thead>
    <tr style="text-align: center;">
      <th></th>
      <th>Strategy</th>
      <th>Precision</th>
      <th>P&amp;L</th>
      <th>Sharpe Ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>MLP Classifier</td>
      <td>0.55</td>
      <td>2.06</td>
      <td>1.79</td>
    </tr>
    <tr>
      <th>3</th>
      <td>KNN</td>
      <td>0.50</td>
      <td>1.95</td>
      <td>1.85</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Baseline</td>
      <td>0.00</td>
      <td>1.69</td>
      <td>1.14</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Decision Tree</td>
      <td>0.49</td>
      <td>1.61</td>
      <td>1.84</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Random Forest</td>
      <td>0.53</td>
      <td>1.55</td>
      <td>1.16</td>
    </tr>
    <tr>
      <th>8</th>
      <td>XGBoost</td>
      <td>0.52</td>
      <td>1.33</td>
      <td>0.86</td>
    </tr>
    <tr>
      <th>9</th>
      <td>SVC</td>
      <td>0.47</td>
      <td>1.31</td>
      <td>0.73</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Logistic Regression</td>
      <td>0.47</td>
      <td>1.14</td>
      <td>0.47</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Gradient Boost</td>
      <td>0.48</td>
      <td>1.06</td>
      <td>0.33</td>
    </tr>
    <tr>
      <th>6</th>
      <td>AdaBoost</td>
      <td>0.50</td>
      <td>0.86</td>
      <td>-0.09</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Linear Discriminant Analysis</td>
      <td>0.47</td>
      <td>0.85</td>
      <td>-0.17</td>
    </tr>
  </tbody>
</table>

<a id="more"></a>
<h1 id="Packages"><a href="#Packages" class="headerlink" title="Packages"></a>Packages</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> ticker</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> set_start_method</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, HTML, Image</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> pandas.plotting <span class="keyword">import</span> register_matplotlib_converters</span><br><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line">register_matplotlib_converters()</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">'font.family'</span>] = <span class="string">"serif"</span></span><br><span class="line">plt.rcParams[<span class="string">'font.serif'</span>] = <span class="string">"DejaVu Serif"</span></span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">12</span>, <span class="number">6</span>)</span><br><span class="line">plt.rcParams[<span class="string">'figure.dpi'</span>] = <span class="number">100</span></span><br><span class="line">plt.rcParams[<span class="string">'lines.linewidth'</span>] = <span class="number">0.75</span></span><br><span class="line">pd.set_option(<span class="string">'max_row'</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h1><p>This is a customized function used to plot confusion matrix in python.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">disp</span><span class="params">(df, max_rows=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> display(HTML(df.to_html(max_rows=max_rows, header=<span class="keyword">True</span>).replace(<span class="string">'&lt;table border="1" class="dataframe"&gt;'</span>,<span class="string">'&lt;table&gt;'</span>)))</span><br></pre></td></tr></table></figure>
<h1 id="Data-Exploration"><a href="#Data-Exploration" class="headerlink" title="Data Exploration"></a>Data Exploration</h1><p>I got the preliminary bitcoin data from <a href="https://api.bitcoincharts.com/v1/csv/" target="_blank" rel="noopener">bitcoincharts</a>. Data include price and volume information recorded by Bitstamp and split by seconds. This provide great granularity that can be grouped into any desirable levels later on.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">'bitstampUSD.csv'</span>, header=<span class="keyword">None</span>, names=[<span class="string">'time'</span>, <span class="string">'price'</span>, <span class="string">'volume'</span>])</span><br><span class="line">data[<span class="string">'time'</span>] = pd.to_datetime(data[<span class="string">'time'</span>], unit=<span class="string">'s'</span>)</span><br><span class="line">data.set_index(<span class="string">'time'</span>, inplace=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>Get 3-month treasury bill price.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">'https://fred.stlouisfed.org/graph/fredgraph.csv?id=DTB3'</span></span><br><span class="line">tr  = pd.read_csv(url, index_col=<span class="number">0</span>, parse_dates=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>We first resample our data by hour. Since most Bitcoin exchanges nowadays have transaction fees, which renders retail trading at a high frequency level unattainable. Therefore I leave out the second and minute level data and combine them into hours. Note that I average the price while summing the volume within an hour.</p>
<p>A 2 year data window from 2017 to 2019 is used, as this is when Bitcoin and other crypto has come into the attention of the larger public, and mostly importantly, started to be heavily traded. Therefore the training set will be more representative of any future trading environment. The plot below illustrates the total dollar amount traded per hours over time.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df0 = data.resample(<span class="string">'H'</span>).agg(&#123;<span class="string">'price'</span>: np.mean, <span class="string">'volume'</span>: np.sum&#125;).fillna(method=<span class="string">'ffill'</span>)</span><br><span class="line">plt.plot(df0.volume * df0.price, c=<span class="string">'black'</span>)</span><br><span class="line">plt.title(<span class="string">'Bitcoin Dollar Volume in Dollar Term'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_14_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df1  = data.loc[<span class="string">'2017-07-01'</span>:<span class="string">'2019-06-30'</span>].resample(<span class="string">'H'</span>).agg(&#123;<span class="string">'price'</span>: np.mean,</span><br><span class="line">                                                            <span class="string">'volume'</span>: np.sum&#125;).fillna(method=<span class="string">'ffill'</span>)</span><br><span class="line">df2 = tr.loc[<span class="string">'2017-07-01'</span>:<span class="string">'2019-06-30'</span>]</span><br><span class="line">df = df1.join(df2).replace(<span class="string">'.'</span>, np.NaN).fillna(method=<span class="string">'ffill'</span>).fillna(method=<span class="string">'bfill'</span>).rename(&#123;<span class="string">'DTB3'</span>: <span class="string">'tr'</span>&#125;, axis=<span class="number">1</span>)</span><br><span class="line">df.tr = df.tr.astype(float)/<span class="number">100</span></span><br><span class="line">disp(df)</span><br></pre></td></tr></table></figure>
<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>volume</th>
      <th>tr</th>
    </tr>
    <tr>
      <th>time</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-07-01 00:00:00</th>
      <td>2473.427264</td>
      <td>200.793669</td>
      <td>0.0104</td>
    </tr>
    <tr>
      <th>2017-07-01 01:00:00</th>
      <td>2463.946180</td>
      <td>228.853771</td>
      <td>0.0104</td>
    </tr>
    <tr>
      <th>2017-07-01 02:00:00</th>
      <td>2441.314976</td>
      <td>475.068038</td>
      <td>0.0104</td>
    </tr>
    <tr>
      <th>2017-07-01 03:00:00</th>
      <td>2449.063866</td>
      <td>177.876034</td>
      <td>0.0104</td>
    </tr>
    <tr>
      <th>2017-07-01 04:00:00</th>
      <td>2453.192311</td>
      <td>120.916328</td>
      <td>0.0104</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2019-06-30 19:00:00</th>
      <td>11173.875377</td>
      <td>389.958860</td>
      <td>0.0208</td>
    </tr>
    <tr>
      <th>2019-06-30 20:00:00</th>
      <td>11276.492157</td>
      <td>372.471619</td>
      <td>0.0208</td>
    </tr>
    <tr>
      <th>2019-06-30 21:00:00</th>
      <td>11340.807808</td>
      <td>295.522323</td>
      <td>0.0208</td>
    </tr>
    <tr>
      <th>2019-06-30 22:00:00</th>
      <td>11037.539360</td>
      <td>963.543871</td>
      <td>0.0208</td>
    </tr>
    <tr>
      <th>2019-06-30 23:00:00</th>
      <td>10838.165248</td>
      <td>1152.810243</td>
      <td>0.0208</td>
    </tr>
  </tbody>
</table>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(df.price, c=<span class="string">'black'</span>)</span><br><span class="line">plt.title(<span class="string">'Bitcoin Price 2017-07-01 to 2019-06-30'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_16_0.png" alt="png"></p>
<p>We then created several more data fields intending to extract more information from the previous n-hour window</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">interval = [<span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>, <span class="number">48</span>, <span class="number">120</span>] <span class="comment"># 0.25, 0.5, 1, 2, 5 days</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> interval:</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> [<span class="string">'price'</span>, <span class="string">'volume'</span>]:</span><br><span class="line">        df[c+<span class="string">'_change_'</span>+str(i)+<span class="string">'H'</span>]   = df[c]/df[c].shift(i)<span class="number">-1</span></span><br><span class="line">        df[c+<span class="string">'_high_'</span>+str(i)+<span class="string">'H'</span>]     = df[c].rolling(i).max().shift(<span class="number">1</span>) / df[c]</span><br><span class="line">        df[c+<span class="string">'_low_'</span>+str(i)+<span class="string">'H'</span>]      = df[c].rolling(i).min().shift(<span class="number">1</span>) / df[c]</span><br><span class="line">        df[c+<span class="string">'_avg_'</span>+str(i)+<span class="string">'H'</span>]      = df[c].rolling(i).mean().shift(<span class="number">1</span>) / df[c]  </span><br><span class="line">        df[c+<span class="string">'_std_'</span>+str(i)+<span class="string">'H'</span>]      = df[c].rolling(i).std().shift(<span class="number">1</span>) / df[c] * np.sqrt(<span class="number">24</span>/i)</span><br><span class="line"></span><br><span class="line">df.dropna(inplace=<span class="keyword">True</span>)</span><br><span class="line">disp(df.head())</span><br></pre></td></tr></table></figure>
<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>volume</th>
      <th>tr</th>
      <th>price_change_6H</th>
      <th>price_high_6H</th>
      <th>price_low_6H</th>
      <th>price_avg_6H</th>
      <th>price_std_6H</th>
      <th>volume_change_6H</th>
      <th>volume_high_6H</th>
      <th>volume_low_6H</th>
      <th>volume_avg_6H</th>
      <th>volume_std_6H</th>
      <th>price_change_12H</th>
      <th>price_high_12H</th>
      <th>price_low_12H</th>
      <th>price_avg_12H</th>
      <th>price_std_12H</th>
      <th>volume_change_12H</th>
      <th>volume_high_12H</th>
      <th>volume_low_12H</th>
      <th>volume_avg_12H</th>
      <th>volume_std_12H</th>
      <th>price_change_24H</th>
      <th>price_high_24H</th>
      <th>price_low_24H</th>
      <th>price_avg_24H</th>
      <th>price_std_24H</th>
      <th>volume_change_24H</th>
      <th>volume_high_24H</th>
      <th>volume_low_24H</th>
      <th>volume_avg_24H</th>
      <th>volume_std_24H</th>
      <th>price_change_48H</th>
      <th>price_high_48H</th>
      <th>price_low_48H</th>
      <th>price_avg_48H</th>
      <th>price_std_48H</th>
      <th>volume_change_48H</th>
      <th>volume_high_48H</th>
      <th>volume_low_48H</th>
      <th>volume_avg_48H</th>
      <th>volume_std_48H</th>
      <th>price_change_120H</th>
      <th>price_high_120H</th>
      <th>price_low_120H</th>
      <th>price_avg_120H</th>
      <th>price_std_120H</th>
      <th>volume_change_120H</th>
      <th>volume_high_120H</th>
      <th>volume_low_120H</th>
      <th>volume_avg_120H</th>
      <th>volume_std_120H</th>
    </tr>
    <tr>
      <th>time</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-07-06 00:00:00</th>
      <td>2607.823311</td>
      <td>233.619901</td>
      <td>0.0102</td>
      <td>0.005149</td>
      <td>1.001294</td>
      <td>0.994877</td>
      <td>0.998116</td>
      <td>0.005057</td>
      <td>-0.539692</td>
      <td>2.172459</td>
      <td>1.271991</td>
      <td>1.710225</td>
      <td>0.606196</td>
      <td>0.019447</td>
      <td>1.001294</td>
      <td>0.980924</td>
      <td>0.991722</td>
      <td>0.010182</td>
      <td>-0.137448</td>
      <td>2.604881</td>
      <td>0.986408</td>
      <td>1.724699</td>
      <td>0.659083</td>
      <td>0.012479</td>
      <td>1.001294</td>
      <td>0.973805</td>
      <td>0.985347</td>
      <td>0.008630</td>
      <td>-0.708220</td>
      <td>3.444264</td>
      <td>0.815879</td>
      <td>1.940980</td>
      <td>0.748083</td>
      <td>0.019561</td>
      <td>1.008966</td>
      <td>0.973805</td>
      <td>0.990540</td>
      <td>0.006865</td>
      <td>0.552344</td>
      <td>4.357035</td>
      <td>0.644187</td>
      <td>1.832178</td>
      <td>0.620839</td>
      <td>0.054336</td>
      <td>1.008966</td>
      <td>0.916032</td>
      <td>0.966001</td>
      <td>0.011353</td>
      <td>0.163482</td>
      <td>8.713623</td>
      <td>0.498690</td>
      <td>1.772706</td>
      <td>0.491582</td>
    </tr>
    <tr>
      <th>2017-07-06 01:00:00</th>
      <td>2592.974565</td>
      <td>229.561261</td>
      <td>0.0102</td>
      <td>-0.005044</td>
      <td>1.007028</td>
      <td>1.001879</td>
      <td>1.004691</td>
      <td>0.004088</td>
      <td>-0.415935</td>
      <td>1.872772</td>
      <td>1.017680</td>
      <td>1.541597</td>
      <td>0.657009</td>
      <td>0.011195</td>
      <td>1.007028</td>
      <td>0.988929</td>
      <td>0.999000</td>
      <td>0.009511</td>
      <td>-0.622775</td>
      <td>2.650935</td>
      <td>1.003848</td>
      <td>1.741677</td>
      <td>0.698711</td>
      <td>0.011259</td>
      <td>1.007028</td>
      <td>0.979381</td>
      <td>0.991506</td>
      <td>0.009179</td>
      <td>-0.707043</td>
      <td>3.505159</td>
      <td>0.830303</td>
      <td>1.872374</td>
      <td>0.713401</td>
      <td>0.009083</td>
      <td>1.014744</td>
      <td>0.979381</td>
      <td>0.996615</td>
      <td>0.006895</td>
      <td>0.168152</td>
      <td>4.434067</td>
      <td>0.830303</td>
      <td>1.872115</td>
      <td>0.625493</td>
      <td>0.052367</td>
      <td>1.014744</td>
      <td>0.921278</td>
      <td>0.971965</td>
      <td>0.011479</td>
      <td>0.003091</td>
      <td>8.867680</td>
      <td>0.507507</td>
      <td>1.805239</td>
      <td>0.499861</td>
    </tr>
    <tr>
      <th>2017-07-06 02:00:00</th>
      <td>2595.240970</td>
      <td>111.498601</td>
      <td>0.0102</td>
      <td>-0.005029</td>
      <td>1.006148</td>
      <td>0.999127</td>
      <td>1.002969</td>
      <td>0.005542</td>
      <td>-0.624789</td>
      <td>3.855797</td>
      <td>2.058871</td>
      <td>2.929583</td>
      <td>1.561810</td>
      <td>0.009963</td>
      <td>1.006148</td>
      <td>0.989687</td>
      <td>0.999049</td>
      <td>0.008379</td>
      <td>-0.765640</td>
      <td>4.551893</td>
      <td>2.058871</td>
      <td>3.302634</td>
      <td>1.296594</td>
      <td>0.016319</td>
      <td>1.006148</td>
      <td>0.978526</td>
      <td>0.991104</td>
      <td>0.009312</td>
      <td>-0.861432</td>
      <td>7.216670</td>
      <td>1.709488</td>
      <td>3.647934</td>
      <td>1.347291</td>
      <td>0.000808</td>
      <td>1.013858</td>
      <td>0.978526</td>
      <td>0.995932</td>
      <td>0.006872</td>
      <td>-0.870219</td>
      <td>9.129174</td>
      <td>1.709488</td>
      <td>3.860618</td>
      <td>1.283035</td>
      <td>0.063050</td>
      <td>1.013858</td>
      <td>0.920474</td>
      <td>0.971530</td>
      <td>0.011491</td>
      <td>-0.765300</td>
      <td>18.257410</td>
      <td>1.044891</td>
      <td>3.716808</td>
      <td>1.029132</td>
    </tr>
    <tr>
      <th>2017-07-06 03:00:00</th>
      <td>2601.939179</td>
      <td>154.465403</td>
      <td>0.0102</td>
      <td>0.001575</td>
      <td>1.003558</td>
      <td>0.996555</td>
      <td>0.999547</td>
      <td>0.005543</td>
      <td>-0.640708</td>
      <td>2.783251</td>
      <td>0.721835</td>
      <td>1.914348</td>
      <td>1.612821</td>
      <td>0.013029</td>
      <td>1.003558</td>
      <td>0.987139</td>
      <td>0.997297</td>
      <td>0.007360</td>
      <td>-0.329707</td>
      <td>3.285718</td>
      <td>0.721835</td>
      <td>2.187443</td>
      <td>1.098140</td>
      <td>0.017659</td>
      <td>1.003558</td>
      <td>0.976007</td>
      <td>0.989220</td>
      <td>0.009328</td>
      <td>-0.719538</td>
      <td>4.131480</td>
      <td>0.721835</td>
      <td>2.446232</td>
      <td>0.882973</td>
      <td>-0.004151</td>
      <td>1.011248</td>
      <td>0.976007</td>
      <td>0.993385</td>
      <td>0.006859</td>
      <td>-0.848249</td>
      <td>6.589761</td>
      <td>0.721835</td>
      <td>2.685895</td>
      <td>0.903309</td>
      <td>0.062422</td>
      <td>1.011248</td>
      <td>0.918104</td>
      <td>0.969522</td>
      <td>0.011449</td>
      <td>-0.131612</td>
      <td>13.178846</td>
      <td>0.721835</td>
      <td>2.663309</td>
      <td>0.746976</td>
    </tr>
    <tr>
      <th>2017-07-06 04:00:00</th>
      <td>2594.198903</td>
      <td>323.934946</td>
      <td>0.0102</td>
      <td>-0.006510</td>
      <td>1.006553</td>
      <td>0.999528</td>
      <td>1.002792</td>
      <td>0.005453</td>
      <td>-0.093037</td>
      <td>1.273228</td>
      <td>0.344201</td>
      <td>0.771118</td>
      <td>0.713993</td>
      <td>0.006701</td>
      <td>1.006553</td>
      <td>0.993343</td>
      <td>1.001348</td>
      <td>0.005868</td>
      <td>-0.345152</td>
      <td>1.566764</td>
      <td>0.344201</td>
      <td>1.023516</td>
      <td>0.558260</td>
      <td>0.021535</td>
      <td>1.006553</td>
      <td>0.978919</td>
      <td>0.992897</td>
      <td>0.009496</td>
      <td>-0.492401</td>
      <td>1.970058</td>
      <td>0.344201</td>
      <td>1.115490</td>
      <td>0.427613</td>
      <td>-0.005803</td>
      <td>1.014265</td>
      <td>0.978919</td>
      <td>0.996261</td>
      <td>0.006822</td>
      <td>0.102404</td>
      <td>2.598252</td>
      <td>0.344201</td>
      <td>1.225214</td>
      <td>0.392388</td>
      <td>0.057479</td>
      <td>1.014265</td>
      <td>0.920843</td>
      <td>0.972906</td>
      <td>0.011490</td>
      <td>1.679001</td>
      <td>6.284212</td>
      <td>0.344201</td>
      <td>1.269372</td>
      <td>0.356447</td>
    </tr>
  </tbody>
</table>


<h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h1><p>Due to the large number of features created in the last step, we use PCA to reduce the dimensionality of the data. Aside from price, 15 other principal components are retained. Since we mostly care about predicting accuracy, therefore we are okay with losing some interpretability in the PCA process.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = StandardScaler().fit_transform(df.iloc[:, <span class="number">3</span>:])</span><br><span class="line">comp = <span class="number">15</span></span><br><span class="line">pca = PCA(n_components=comp)</span><br><span class="line">X_pca = pca.fit_transform(X)</span><br><span class="line">np.round(pca.explained_variance_ratio_, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>array([0.29, 0.23, 0.13, 0.06, 0.05, 0.03, 0.03, 0.02, 0.02, 0.02, 0.01,
       0.01, 0.01, 0.01, 0.01])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.round(np.sum(pca.explained_variance_ratio_), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0.93
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_pca = pd.DataFrame(X_pca, index=df.index, columns = [<span class="string">'PC'</span> + str(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, comp+<span class="number">1</span>)])</span><br><span class="line">df = pd.DataFrame(df.iloc[:, <span class="number">0</span>:<span class="number">3</span>]).join(df_pca)</span><br><span class="line">disp(df.head())</span><br></pre></td></tr></table></figure>
<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>volume</th>
      <th>tr</th>
      <th>PC1</th>
      <th>PC2</th>
      <th>PC3</th>
      <th>PC4</th>
      <th>PC5</th>
      <th>PC6</th>
      <th>PC7</th>
      <th>PC8</th>
      <th>PC9</th>
      <th>PC10</th>
      <th>PC11</th>
      <th>PC12</th>
      <th>PC13</th>
      <th>PC14</th>
      <th>PC15</th>
    </tr>
    <tr>
      <th>time</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-07-06 00:00:00</th>
      <td>2607.823311</td>
      <td>233.619901</td>
      <td>0.0102</td>
      <td>1.204847</td>
      <td>-1.442388</td>
      <td>-0.936078</td>
      <td>0.562964</td>
      <td>-1.802252</td>
      <td>-0.126177</td>
      <td>-2.115852</td>
      <td>0.258446</td>
      <td>0.547159</td>
      <td>-0.005956</td>
      <td>-0.345683</td>
      <td>-0.077257</td>
      <td>-0.389290</td>
      <td>-0.253596</td>
      <td>0.501094</td>
    </tr>
    <tr>
      <th>2017-07-06 01:00:00</th>
      <td>2592.974565</td>
      <td>229.561261</td>
      <td>0.0102</td>
      <td>1.072486</td>
      <td>-0.509851</td>
      <td>-1.208146</td>
      <td>1.100969</td>
      <td>-1.991122</td>
      <td>0.106322</td>
      <td>-1.995090</td>
      <td>0.089313</td>
      <td>0.690748</td>
      <td>-0.003055</td>
      <td>-0.152291</td>
      <td>-0.266696</td>
      <td>-0.403753</td>
      <td>-0.415290</td>
      <td>0.602009</td>
    </tr>
    <tr>
      <th>2017-07-06 02:00:00</th>
      <td>2595.240970</td>
      <td>111.498601</td>
      <td>0.0102</td>
      <td>6.313332</td>
      <td>0.286169</td>
      <td>-0.274636</td>
      <td>1.772318</td>
      <td>-3.465762</td>
      <td>0.816421</td>
      <td>-5.245687</td>
      <td>0.737407</td>
      <td>1.652572</td>
      <td>0.043234</td>
      <td>0.118171</td>
      <td>-0.658779</td>
      <td>-0.606447</td>
      <td>-0.557087</td>
      <td>0.499793</td>
    </tr>
    <tr>
      <th>2017-07-06 03:00:00</th>
      <td>2601.939179</td>
      <td>154.465403</td>
      <td>0.0102</td>
      <td>1.986983</td>
      <td>-0.820551</td>
      <td>-1.195466</td>
      <td>0.697308</td>
      <td>-1.574198</td>
      <td>0.289253</td>
      <td>-1.100313</td>
      <td>0.593288</td>
      <td>0.655685</td>
      <td>-0.005791</td>
      <td>-0.018679</td>
      <td>-0.152047</td>
      <td>-0.354950</td>
      <td>-0.493463</td>
      <td>0.640942</td>
    </tr>
    <tr>
      <th>2017-07-06 04:00:00</th>
      <td>2594.198903</td>
      <td>323.934946</td>
      <td>0.0102</td>
      <td>-1.350755</td>
      <td>-0.873287</td>
      <td>-1.805126</td>
      <td>0.663435</td>
      <td>-0.972641</td>
      <td>0.036059</td>
      <td>-0.009574</td>
      <td>0.000981</td>
      <td>0.200082</td>
      <td>0.315963</td>
      <td>-0.225084</td>
      <td>-0.120908</td>
      <td>-0.308701</td>
      <td>-0.390018</td>
      <td>0.597231</td>
    </tr>
  </tbody>
</table>


<h1 id="Modeling"><a href="#Modeling" class="headerlink" title="Modeling"></a>Modeling</h1><p>Train and test sets are created for modeling purpose. Since it is time series data, randomization will not be performed. Rather, both train and test sets are chosen such that they both include a market upturn and market downturn.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train  = df.loc[<span class="string">'2017-07-01'</span>:<span class="string">'2018-06-30'</span>]</span><br><span class="line">test   = df.loc[<span class="string">'2018-07-01'</span>:<span class="string">'2019-06-30'</span>]</span><br></pre></td></tr></table></figure>
<p>Here we specify some modeling parameters. The trading frequency is set to one day.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">trade_interval      = <span class="string">'1H'</span></span><br><span class="line">trade_interval_min  = <span class="number">60</span></span><br><span class="line">ann_factor          = <span class="number">24</span> * <span class="number">365</span></span><br><span class="line">training_threshold  = <span class="number">0.0075</span></span><br><span class="line">transaction_fee     = <span class="number">0.0025</span></span><br></pre></td></tr></table></figure>
<p>Create a model engine that fit the train data and use grid search CV to tune the parameter grid. A long trade will be executed only if the model predict a next-5-day up move in the last 24 consecutive hours. This limits the frequency of trade which reduce the impact of the relatively large transaction fee per trade. The training threshold is set to 75 bps, which means the model is train to identify a potential up move of more than 75 bps in the next 5 days.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_model</span><span class="params">(Model, model_name, param, param_init, param_grid, search=False)</span>:</span></span><br><span class="line">    <span class="comment"># prepare data</span></span><br><span class="line">    train_copy = train.resample(trade_interval).first()</span><br><span class="line">    test_copy = test.resample(trade_interval).first()</span><br><span class="line">    train_copy.dropna(inplace=<span class="keyword">True</span>)</span><br><span class="line">    test_copy.dropna(inplace=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    indicator = <span class="number">24</span>  <span class="comment"># hr</span></span><br><span class="line">    offset    = <span class="number">120</span> <span class="comment"># hr</span></span><br><span class="line"></span><br><span class="line">    X_train = train_copy.iloc[:-offset, <span class="number">3</span>:]</span><br><span class="line">    Y_train = (train_copy.price.shift(-offset)/train_copy.price)[:-offset] &gt; (<span class="number">1</span> + training_threshold)</span><br><span class="line">    X_test  = test_copy.iloc[:-offset, <span class="number">3</span>:]</span><br><span class="line">    Y_test  = (test_copy.price.shift(-offset)/test_copy.price)[:-offset] &gt; (<span class="number">1</span> + training_threshold)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># run model</span></span><br><span class="line">    <span class="keyword">if</span> search:</span><br><span class="line">        model = GridSearchCV(estimator=Model(**param_init),</span><br><span class="line">                             cv=KFold(n_splits=<span class="number">5</span>, random_state=<span class="number">0</span>),</span><br><span class="line">                             scoring=<span class="string">'precision'</span>,</span><br><span class="line">                             param_grid=param_grid).fit(X_train, Y_train)</span><br><span class="line">        print(<span class="string">f'cv precision: <span class="subst">&#123;round(model.best_score_, <span class="number">2</span>)&#125;</span>, best param: <span class="subst">&#123;model.best_params_&#125;</span>'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model = Model(**param).fit(X_train, Y_train)</span><br><span class="line"></span><br><span class="line">    Y_pred    = model.predict(X_test)</span><br><span class="line">    cm        = confusion_matrix(Y_test, Y_pred)</span><br><span class="line">    precision = round(cm[<span class="number">1</span>][<span class="number">1</span>]/(cm[<span class="number">1</span>][<span class="number">1</span>] + cm[<span class="number">0</span>][<span class="number">1</span>]), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate pnl</span></span><br><span class="line">    <span class="comment"># test_copy['ind']     = np.append(Y_pred, False)</span></span><br><span class="line">    <span class="comment"># test_copy['pnl']     = test_copy.ind * (test_copy.price.shift(-1) / test_copy.price)</span></span><br><span class="line">    test_copy[<span class="string">'pred'</span>] = np.append(Y_pred, [<span class="keyword">False</span>] * offset)</span><br><span class="line">    test_copy[<span class="string">'ind'</span>]  = test_copy.pred.rolling(indicator).sum() == indicator</span><br><span class="line">    test_copy[<span class="string">'buy'</span>]  = test_copy.ind.rolling(offset).sum() &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    test_copy[<span class="string">'pnl'</span>]  = test_copy.buy * (test_copy.price.shift(<span class="number">-1</span>) / test_copy.price)</span><br><span class="line">    test_copy.pnl.replace(<span class="number">0</span>, <span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">    test_copy.dropna(inplace=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    test_copy[<span class="string">'fee'</span>]  = np.where(test_copy.ind != test_copy.ind.shift(<span class="number">1</span>), <span class="number">1</span>-transaction_fee, <span class="number">1</span>)</span><br><span class="line">    test_copy.pnl     *= test_copy.fee</span><br><span class="line"></span><br><span class="line">    test_pnl  = round(test_copy.pnl.cumprod()[<span class="number">-1</span>], <span class="number">2</span>)</span><br><span class="line">    test_spr  = round(np.mean(test_copy.pnl - <span class="number">1</span> - test_copy.tr/(ann_factor))</span><br><span class="line">                      / (test_copy.pnl - <span class="number">1</span>).std() * np.sqrt(ann_factor), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">f'test precision: <span class="subst">&#123;precision&#125;</span>; pnl: <span class="subst">&#123;test_pnl&#125;</span>, spr: <span class="subst">&#123;test_spr&#125;</span>'</span>)</span><br><span class="line">    <span class="keyword">return</span> test_copy.pnl, precision, test_pnl, test_spr</span><br></pre></td></tr></table></figure>
<h2 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">baseline        = test.resample(trade_interval).first()</span><br><span class="line">baseline[<span class="string">'pnl'</span>] = baseline.price / baseline.price.shift(<span class="number">1</span>) - <span class="number">1</span></span><br><span class="line">baseline_pnl    = round(baseline.price.iloc[<span class="number">-1</span>] / baseline.price.iloc[<span class="number">0</span>], <span class="number">2</span>)</span><br><span class="line">baseline_spr    = round(np.mean(baseline.pnl - baseline.tr/(ann_factor))</span><br><span class="line">                        / baseline.pnl.std() * np.sqrt(ann_factor), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">result = test[[<span class="string">'price'</span>]].copy().rename(&#123;<span class="string">'price'</span>: <span class="string">'Baseline'</span>&#125;, axis=<span class="number">1</span>)/test.price.iloc[<span class="number">0</span>]*<span class="number">1000</span></span><br><span class="line">comp = pd.DataFrame(&#123;<span class="string">'Strategy'</span>: <span class="string">'Baseline'</span>, <span class="string">'Precision'</span>: <span class="string">'NA'</span>,</span><br><span class="line">                     <span class="string">'P&amp;L'</span>: baseline_pnl, <span class="string">'Sharpe Ratio'</span>: baseline_spr&#125;, index=[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">f'test precision: <span class="subst">&#123;np.NaN&#125;</span>; pnl: <span class="subst">&#123;baseline_pnl&#125;</span>, spr: <span class="subst">&#123;baseline_spr&#125;</span>'</span>)</span><br></pre></td></tr></table></figure>
<p>test precision: nan; pnl: 1.69, spr: 1.14</p>
<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Model      = LogisticRegression</span><br><span class="line">model_name = <span class="string">'Logistic Regression'</span></span><br><span class="line">param      = &#123;<span class="string">'class_weight'</span>:<span class="string">'balanced'</span>,</span><br><span class="line">              <span class="string">'solver'</span>:<span class="string">'liblinear'</span>,</span><br><span class="line">              <span class="string">'random_state'</span>: <span class="number">0</span>,</span><br><span class="line">              <span class="string">'C'</span>: <span class="number">0.001</span>,</span><br><span class="line">              <span class="string">'penalty'</span>: <span class="string">'l2'</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'random_state'</span>: <span class="number">0</span>, <span class="string">'class_weight'</span>: <span class="string">'balanced'</span>&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'C'</span>: [<span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">10</span>], <span class="string">'penalty'</span>: [<span class="string">'l1'</span>, <span class="string">'l2'</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.52, best param: {‘C’: 0.01, ‘penalty’: ‘l1’}<br>test precision: 0.47; pnl: 1.14, spr: 0.47</p>
<h2 id="Linear-Discriminant-Analysis"><a href="#Linear-Discriminant-Analysis" class="headerlink" title="Linear Discriminant Analysis"></a>Linear Discriminant Analysis</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Model      = LinearDiscriminantAnalysis</span><br><span class="line">model_name = <span class="string">'Linear Discriminant Analysis'</span></span><br><span class="line">param      = &#123;<span class="string">'solver'</span>: <span class="string">'svd'</span>, <span class="string">'n_components'</span>: <span class="keyword">None</span>&#125;</span><br><span class="line">param_init = &#123;&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'solver'</span>: [<span class="string">'svd'</span>, <span class="string">'lsqr'</span>], <span class="string">'n_components'</span>: [<span class="keyword">None</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">25</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.5, best param: {‘n_components’: None, ‘solver’: ‘svd’}<br>test precision: 0.47; pnl: 0.85, spr: -0.17</p>
<h2 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Model      = KNeighborsClassifier</span><br><span class="line">model_name = <span class="string">'KNN'</span></span><br><span class="line">param      = &#123;<span class="string">'p'</span>: <span class="number">2</span>, <span class="string">'leaf_size'</span>: <span class="number">2</span>, <span class="string">'n_neighbors'</span>: <span class="number">100</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'p'</span>: <span class="number">2</span>&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'n_neighbors'</span>: [<span class="number">5</span>, <span class="number">25</span>, <span class="number">100</span>], <span class="string">'leaf_size'</span>: [<span class="number">2</span>, <span class="number">25</span>, <span class="number">100</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.53, best param: {‘leaf_size’: 2, ‘n_neighbors’: 100}<br>test precision: 0.5; pnl: 1.95, spr: 1.85</p>
<h2 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Model      = DecisionTreeClassifier</span><br><span class="line">model_name = <span class="string">'Decision Tree'</span></span><br><span class="line">param      = &#123;<span class="string">'random_state'</span>:<span class="number">0</span>, <span class="string">'criterion'</span>: <span class="string">'gini'</span>, <span class="string">'max_depth'</span>: <span class="keyword">None</span>, <span class="string">'max_features'</span>: <span class="number">10</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'random_state'</span>:<span class="number">0</span>&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'criterion'</span>: [<span class="string">'gini'</span>, <span class="string">'entropy'</span>],</span><br><span class="line">              <span class="string">'max_depth'</span>: [<span class="keyword">None</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">25</span>],</span><br><span class="line">              <span class="string">'max_features'</span>: [<span class="keyword">None</span>, <span class="string">'auto'</span>, <span class="number">5</span>, <span class="number">10</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.53, best param: {‘criterion’: ‘gini’, ‘max_depth’: 10, ‘max_features’: 5}<br>test precision: 0.49; pnl: 1.61, spr: 1.84</p>
<h2 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model      = RandomForestClassifier</span><br><span class="line">model_name = <span class="string">'Random Forest'</span></span><br><span class="line">param      = &#123;<span class="string">'class_weight'</span>:<span class="string">'balanced'</span>,</span><br><span class="line">              <span class="string">'random_state'</span>: <span class="number">0</span>,</span><br><span class="line">              <span class="string">'criterion'</span>: <span class="string">'entropy'</span>,</span><br><span class="line">              <span class="string">'max_depth'</span>: <span class="number">10</span>,</span><br><span class="line">              <span class="string">'max_features'</span>: <span class="number">5</span>,</span><br><span class="line">              <span class="string">'n_estimators'</span>: <span class="number">200</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'class_weight'</span>:<span class="string">'balanced'</span>, <span class="string">'random_state'</span>: <span class="number">0</span>, <span class="string">'n_estimators'</span>: <span class="number">200</span>&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'criterion'</span>: [<span class="string">'gini'</span>, <span class="string">'entropy'</span>],</span><br><span class="line">              <span class="string">'max_depth'</span>: [<span class="number">5</span>, <span class="number">25</span>],</span><br><span class="line">              <span class="string">'max_features'</span>: [<span class="number">5</span>, <span class="number">10</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.53, best param: {‘criterion’: ‘gini’, ‘max_depth’: 5, ‘max_features’: 10}<br>test precision: 0.53; pnl: 1.55, spr: 1.16</p>
<h2 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Model      = AdaBoostClassifier</span><br><span class="line">model_name = <span class="string">'AdaBoost'</span></span><br><span class="line">param      = &#123;<span class="string">'random_state'</span>: <span class="number">0</span>, <span class="string">'algorithm'</span>: <span class="string">'SAMME.R'</span>, <span class="string">'n_estimators'</span>: <span class="number">200</span>, <span class="string">'learning_rate'</span>: <span class="number">0.1</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'random_state'</span>: <span class="number">0</span>, <span class="string">'algorithm'</span>: <span class="string">'SAMME.R'</span>, <span class="string">'n_estimators'</span>: <span class="number">200</span>&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'learning_rate'</span>: [<span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">10</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.52, best param: {‘learning_rate’: 0.01}<br>test precision: 0.5; pnl: 0.86, spr: -0.09</p>
<h2 id="Gradient-Boost"><a href="#Gradient-Boost" class="headerlink" title="Gradient Boost"></a>Gradient Boost</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Model      = GradientBoostingClassifier</span><br><span class="line">model_name = <span class="string">'Gradient Boost'</span></span><br><span class="line">param      = &#123;<span class="string">'random_state'</span>: <span class="number">0</span>, <span class="string">'warm_start'</span>: <span class="keyword">True</span>, <span class="string">'n_estimators'</span>: <span class="number">200</span>,</span><br><span class="line">              <span class="string">'max_depth'</span>: <span class="number">10</span>,</span><br><span class="line">              <span class="string">'max_features'</span>: <span class="number">10</span>,</span><br><span class="line">              <span class="string">'learning_rate'</span>: <span class="number">0.1</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'random_state'</span>: <span class="number">0</span>, <span class="string">'warm_start'</span>: <span class="keyword">True</span>, <span class="string">'n_estimators'</span>: <span class="number">200</span>,&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'max_depth'</span>: [<span class="number">5</span>, <span class="number">25</span>],</span><br><span class="line">              <span class="string">'max_features'</span>: [<span class="number">5</span>, <span class="number">10</span>],</span><br><span class="line">              <span class="string">'learning_rate'</span>: [<span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">10</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.54, best param: {‘learning_rate’: 10, ‘max_depth’: 5, ‘max_features’: 5}<br>test precision: 0.48; pnl: 1.06, spr: 0.33</p>
<h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set_start_method(<span class="string">'forkserver'</span>, force=<span class="keyword">True</span>) <span class="comment"># enabling multi-threading</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model      = XGBClassifier</span><br><span class="line">model_name = <span class="string">'XGBoost'</span></span><br><span class="line">param      = &#123;<span class="string">'n_jobs'</span>:<span class="number">4</span>, <span class="string">'seed'</span>:<span class="number">0</span>, <span class="string">'n_estimators'</span>: <span class="number">200</span>,</span><br><span class="line">              <span class="string">'max_depth'</span>: <span class="number">5</span>,</span><br><span class="line">              <span class="string">'min_child_weight'</span>: <span class="number">1</span>,</span><br><span class="line">              <span class="string">'gamma'</span>: <span class="number">10</span>,</span><br><span class="line">              <span class="string">'learning_rate'</span>: <span class="number">0.01</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'n_jobs'</span>:<span class="number">4</span>, <span class="string">'seed'</span>:<span class="number">0</span>, <span class="string">'n_estimators'</span>: <span class="number">200</span>&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'max_depth'</span>: [<span class="number">5</span>, <span class="number">25</span>],</span><br><span class="line">              <span class="string">'min_child_weight'</span>: [<span class="number">1</span>, <span class="number">5</span>],</span><br><span class="line">              <span class="string">'gamma'</span>: [<span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">10</span>],</span><br><span class="line">              <span class="string">'learning_rate'</span>: [<span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">10</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.52, best param: {‘gamma’: 10, ‘learning_rate’: 0.01, ‘max_depth’: 25, ‘min_child_weight’: 1}<br>test precision: 0.52; pnl: 1.33, spr: 0.86</p>
<h2 id="SVC"><a href="#SVC" class="headerlink" title="SVC"></a>SVC</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Model      = SVC</span><br><span class="line">model_name = <span class="string">'SVC'</span></span><br><span class="line">param      = &#123;<span class="string">'probability'</span>:<span class="keyword">True</span>, <span class="string">'class_weight'</span>:<span class="string">'balanced'</span>, <span class="string">'C'</span>: <span class="number">10</span>, <span class="string">'gamma'</span>: <span class="number">0.01</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'probability'</span>:<span class="keyword">True</span>, <span class="string">'class_weight'</span>:<span class="string">'balanced'</span>&#125;</span><br><span class="line">param_grid = &#123;<span class="string">'C'</span>: [<span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">10</span>],</span><br><span class="line">              <span class="string">'gamma'</span>: [<span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">10</span>]&#125;</span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.64, best param: {‘C’: 0.1, ‘gamma’: 1}<br>test precision: 0.47; pnl: 1.31, spr: 0.73</p>
<h2 id="MLP-Classificer"><a href="#MLP-Classificer" class="headerlink" title="MLP Classificer"></a>MLP Classificer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model      = MLPClassifier</span><br><span class="line">model_name = <span class="string">'MLP Classifier'</span></span><br><span class="line">param      = &#123;<span class="string">'random_state'</span>: <span class="number">0</span>, <span class="string">'hidden_layer_sizes'</span>: (<span class="number">25</span>, <span class="number">25</span>), <span class="string">'alpha'</span>: <span class="number">0.01</span>&#125;</span><br><span class="line">param_init = &#123;<span class="string">'random_state'</span>: <span class="number">0</span>&#125;</span><br><span class="line">param_grid = &#123;<span class="comment"># 'hidden_layer_sizes': [x for x in itertools.product((5, 25, 100),repeat=2)],</span></span><br><span class="line">              <span class="string">'alpha'</span>             : [<span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">10</span>],</span><br><span class="line">              <span class="comment"># 'activation'        : ['identity', 'logistic', 'tanh', 'relu'],</span></span><br><span class="line">              <span class="comment"># 'solver'            : ['lbfgs', 'sgd', 'adam'],</span></span><br><span class="line">              <span class="comment"># 'learning_rate'     : ['constant', 'invscaling', 'adaptive'],</span></span><br><span class="line">              <span class="comment"># 'max_itr'           : [100, 200, 1000]</span></span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=<span class="keyword">True</span>)</span><br><span class="line">result     = result.join(a.cumprod() * <span class="number">1000</span>).rename(&#123;<span class="string">'pnl'</span>: model_name&#125;, axis=<span class="number">1</span>).dropna()</span><br><span class="line">comp       = comp.append(&#123;<span class="string">'Strategy'</span>: model_name, <span class="string">'Precision'</span>: b, <span class="string">'P&amp;L'</span>: c, <span class="string">'Sharpe Ratio'</span>: d&#125;, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>cv precision: 0.53, best param: {‘alpha’: 1}<br>test precision: 0.55; pnl: 2.06, spr: 1.79</p>
<h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><p>The results are summarized as follow.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">disp(comp.replace(<span class="string">'NA'</span>, <span class="number">0</span>).sort_values(<span class="string">'P&amp;L'</span>, ascending=<span class="keyword">False</span>), <span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<table>
  <thead>
    <tr style="text-align: center;">
      <th></th>
      <th>Strategy</th>
      <th>Precision</th>
      <th>P&amp;L</th>
      <th>Sharpe Ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>MLP Classifier</td>
      <td>0.55</td>
      <td>2.06</td>
      <td>1.79</td>
    </tr>
    <tr>
      <th>3</th>
      <td>KNN</td>
      <td>0.50</td>
      <td>1.95</td>
      <td>1.85</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Baseline</td>
      <td>0.00</td>
      <td>1.69</td>
      <td>1.14</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Decision Tree</td>
      <td>0.49</td>
      <td>1.61</td>
      <td>1.84</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Random Forest</td>
      <td>0.53</td>
      <td>1.55</td>
      <td>1.16</td>
    </tr>
    <tr>
      <th>8</th>
      <td>XGBoost</td>
      <td>0.52</td>
      <td>1.33</td>
      <td>0.86</td>
    </tr>
    <tr>
      <th>9</th>
      <td>SVC</td>
      <td>0.47</td>
      <td>1.31</td>
      <td>0.73</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Logistic Regression</td>
      <td>0.47</td>
      <td>1.14</td>
      <td>0.47</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Gradient Boost</td>
      <td>0.48</td>
      <td>1.06</td>
      <td>0.33</td>
    </tr>
    <tr>
      <th>6</th>
      <td>AdaBoost</td>
      <td>0.50</td>
      <td>0.86</td>
      <td>-0.09</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Linear Discriminant Analysis</td>
      <td>0.47</td>
      <td>0.85</td>
      <td>-0.17</td>
    </tr>
  </tbody>
</table>


<p>Plotting the cumulative return for each strategy with transaction fee reflected.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(result)</span><br><span class="line">plt.legend(result.columns, frameon=<span class="keyword">False</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">30</span>)</span><br><span class="line">plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">30</span>))</span><br><span class="line">plt.ylabel(<span class="string">'Cumulative Value Based on $1000 Investment'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_58_0.png" alt="png"></p>
</div></article></div></main><footer><div class="paginator"><a href="/2019/07/algo-2/" class="prev">PREV</a><a href="/2019/07/variance-swap/" class="next">NEXT</a></div><div id="container"></div><!-- link(rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css")--><link rel="stylesheet" href="/css/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
    clientID: '4ec287ddd4ac34ff5087',
    clientSecret: 'ae45426765f12ac3e2f903662b8938dc4881f703',
    repo: 'jackliu234.github.io',
    owner: 'jackliu234',
    admin: ['jackliu234'],
    perPage: 100,
    id: 'Sat Jul 20 2019 00:00:00 GMT-0500 GMT'.split('GMT')[0].replace(/\s/g, '-'),
    distractionFreeMode: false,
    pagerDirection: 'first'
})

gitalk.render('container')</script><!-- block copyright--></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-133275176-1",'auto');ga('send','pageview');</script><link rel="stylesheet" href="//cdn.datatables.net/1.10.7/css/jquery.dataTables.min.css" media="screen" type="text/css"><script src="//cdn.datatables.net/1.10.7/js/jquery.dataTables.min.js"></script><script>$(function(){$('.datatable').dataTable( {"order": [[ 0, "desc" ]],"iDisplayLength": -1,"lengthMenu": [[10, 25, 50, -1], [10, 25, 50, "All"]]} );});</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></body></html>