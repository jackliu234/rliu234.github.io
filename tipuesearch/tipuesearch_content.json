{"pages":[{"title":"Notes on Japanese","url":"/2021/06/japanese-notes/","text":"Hiragana / 平仮名あア いイ うウ えエ おオかカ きキ くク けケ こコさサ しシ すス せセ そソたタ ちチ つツ てテ とトなナ にニ ぬヌ ねネ のノはハ ひヒ ふフ へヘ ほホまア みミ むム めメ もモやヤ ゆユ よヨらラ りリ るル れレ ろロわワ をヲんン Grammar 课文 语法 L1 ～は 〜です 〜は 〜では ありません 〜は 〜じや ありません 〜は 〜ですか ＞ はい そうです ＞ いいえ ちがいます 〜人じん / 〜語ご L2 これは 〜です ｜ この 〜は 〜です それは 〜です ｜ その 〜は 〜です あれは 〜です ｜ あの 〜は 〜です 〜は どれ ですが （三个以上，表疑问） 〜は どの〜 ですが ～は どなた ですが （三个以上，哪一位？） なん ですが （那是什么？） だれ ですが （那人是谁？） あの 人ひとは あの 方かたは （敬语） 何歳なんさい ｜ いくつ 何歳なんさいですが ｜ おいくつですが （敬语） L3 ここは 〜です ｜ こちら 〜です（礼貌说法） そこは 〜です ｜ そちら 〜です あそこは 〜です ｜ あちら 〜です 〜は どこですが ｜ どちらですが 〜も 〜です 〜は 〜ですが 〜ですが 〜は いくらですが （这个多少钱？） あのう （Excuse Me / 用于搭话） L4 【场所】に 【物/人】が あります（物）/ います（人） 【物/人】は 【场所】に あります/います 〜の 上うえに あります/います 〜の 下したに あります/います 〜の 前まえに あります/います 〜の 後うしに あります/います 〜の 隣となりに あります/います 〜の 中なかに あります/います 〜の 外そとに あります/います 【场所】に だれ/何も ありません/いません （も表示全面否定） L5 今いま 午前ごぜん/午後ごご 〜時じ 〜分ぶんです 今 何時ですか ＞ はちじさんじゅぶんです （八点半的两种表述） ＞ はちじはんです 〜ます / 〜ません 〜ました / 〜ませんでした 【时间】に 【动词】 【时间】から 【时间】まで 【动词】 いつ/何時じに/何日にちに/何曜日ようびに 【动词】ますが いつから/何曜日ようびまで 【动词】ますが （询问持续性动作的起点或终点） Quanitity 1 いち 11 じゅういち 10 じゅう 100 百ひゃく 1,000 千せん 10K 一万いちまん 10M 一千万いっせんまん 10KM 一億いちおく 2 に 12 じゅうに 20 にじゅう 200 にひゃく 2,000 にせん 3 さん 13 じゅうさん 30 さんじゅう 300 さんびゃく 3,000 さんぜん 4 し/よん 14 じゅうよん 40 よんじゅう 400 よんひゃく 4,000 よんせん 5 ご 15 じゅうご 50 ごじゅう 500 ごひゃく 5,000 ごせん 6 ろく 16 じゅうろく 60 ろくじゅう 600 ろっぴゃく 6,000 ろくせん 7 しち/なな 17 じゅうなな 70 ななじゅう 700 ななひゃく 7,000 ななせん 8 はち 18 じゅうはち 80 ななじゅう 800 はっぴゃく 8,000 はっせん 9 く/きゅう 19 じゅうきゅう 90 きゅうじゅう 900 きゅうひゃく 9,000 きゅうせん 0 れい/ぜろ 0.1 れいてんいち 2/3 さんぶんのに Time 月曜日 げつようび 一時 いちじ 一分 いっぷん 火曜日 かようび 二時 にじ 二分 にふん 水曜日 すいようび 三時 さんじ 三分 さんぷん 木曜日 もくようび 四時 よじ 四分 よんぷん 金曜日 きんようび 五時 ごじ 五分 ごふん 土曜日 どようび 六時 ろくじ 六分 ろっぷん 日曜日 にちようび 七時 しちじ 七分 ななふん 八時 はちじ 八分 はっぷん 九時 くじ 九分 きゅうふん 十時 じゅうじ 十分 じゅっぷん 十一時 じゅういちじ 十一分 じゅういっぷん 十二時 じゅうにじ 十五分 じゅうごふん","tags":""},{"title":"Efficiently Compute KNN with Mahalanobis Distance","url":"/2020/11/mah/","text":"BackgroundThere are many proximity-based algorithms that can be used to detect potential data outliers. For example, the KNN (K-Nearest Neighbors) is a distance-based algorithm that work well in capturing outliers with extreme values. Specifically, when using the KNN algorithm using the Mahalanobis distance as the distance metric, it tends to capture more meaningful and subtle outliers considering the correlations between features. More specifically, it is best to apply Euclidean distance measurements only if the features are 1) independent and 2) having variances equal to 1. The second condition can usually be satisfied by standardizing while the first condition usually remains an issue. On the other hand, Mahalanobis distance measure first transforms the features into uncorrelated features with variances equal to 1 by dividing the features by their covariance matrix (or practically, multiplying by the inverse of the covariance matrix), then applies Euclidean distance on the transformed feature. ProblemGiven two observations x and y: \\text{Mahalanobis Distance} = \\sqrt{(x-y)^T\\Sigma^{-1}(x-y)}While the KNN with Mahalanobis distance can be carried out in some available modules (i.e. this pyod algorithm), runtime is usually a concern. Because the matrix multiplication by \\Sigma^{-1} needs to be computed in each pairwise distance calculation and therefore significantly increase the runtime (imagine doing this with 10 million observations). SolutionTo address this problem, we can first find the square root matrix A such that A^TA = \\Sigma^{-1} \\begin{align} \\text{Mahalanobis Distance} &= \\sqrt{(x-y)^T\\Sigma^{-1}(x-y)} \\\\ &= \\sqrt{(x-y)^TA^TA(x-y)} \\\\ &= \\sqrt{(Ax-Ay)^T(Ax-Ay)} \\\\ &= \\sqrt{(x'-y')^T(x'-y')} \\\\ &= \\text{Euclidean Distance b/w x' and y'} \\end{align}And then basically just run the normal KNN algorithm (with Euclidean distances) on the transformed observation x' and y', which will be significantly faster as it avoids extensive matrix multiplications: x' = Ax \\\\ y' = AyWell you may ask what if there are no real square root matrix A, in which case the tranformed x' and y' will have imaginary parts? Luckily, it seems most of the time we can just use the real part of A to do the transformation and the subsequent Mahalanobis distance calculation, provided that the estimation error (A^TA - \\Sigma^{-1}) is small.","tags":"math"},{"title":"&#128214; Notes on MSFM - Stochastic Calculus","url":"/2019/12/finm-notes/03_stochastic_calculus/","text":"img.resize { max-width:50%; max-height:50%; } Discrete Time MartingalesConditional expectationDefinition A Borel set is any set in a topological space that can be formed from open sets through the operations of: complement countable union countable intersection Definition Let Y be a random vector and X be a integrable random variable with \\mathbb{E}|X|0. We know that S_{n} is a martingale and S_{T\\wedge n} < max(A, B). Apply Doobs’s Identity and DCT we have: \\mathbb{E}S_{T} = 0We know that S_{n}^2 - n is a martingale. Apply Doobs’s Identity we have \\mathbb{E}S_{T\\wedge n}^2 = \\mathbb{E}(T\\wedge n). Since S_{T\\wedge n}^2 is bounded by max(A^2, B^2) and T\\wedge n is monotone, apply DCT on the RHS and MCT on LHS we get: \\mathbb{E}S^2_{T} = \\mathbb{E}TCombine both results we can get some interesting result for the Gambler’s Ruin problem: \\mathbb{P}[S_{T} = A] = B/(A + B) \\\\ \\mathbb{P}[S_{T} = B] = A/(A + B) \\\\ \\mathbb{E}T = ABExample 2 Let S_{n} be a simple random walk. Let stopping time T := min\\{n: S_{n} = +A\\}, where A>0. Note that now DCT fails as S_{T\\wedge n} is not bounded. Hence \\mathbb{E}S_{T} \\neq 0. In fact, \\mathbb{E}S_{T} = 1 because S_{T} \\equiv 1: \\mathbb{P}[T < \\infty] = \\lim_{B \\rightarrow \\infty} B/(A + B) = 1Doob’s Maximal InequalityDefinition An adapted sequence of random variable X_n is a: sub-martingale if \\mathbb{E}[X_n | \\mathcal{F}_{n-1}] \\geq X_{n-1} super-martingale if \\mathbb{E}[X_n | \\mathcal{F}_{n-1}] \\leq X_{n-1} Proposition If \\varphi :\\mathbb{R} \\rightarrow \\mathbb{R} is a convex function and X_n is a martingale, then: The Jensen’s Inequality holds: \\varphi(\\mathbb{E}X) \\leq \\mathbb{E}\\varphi(X) the sequence \\varphi(X_n) is a sub-martingale. Proposition If X_n is a martingale with X_0 = 0 and Z_n is a predictable sequence of boundedm non-negative random variables, then the martingale transform \\{Z \\cdot X\\}_n is a sub-martingale: \\{Z \\cdot X\\}_n = \\sum_{i=1}^n Z_i(X_i - X_{i-1})Proposition If X_n is a martingale with X_0 = 0 and Z_n is a predictable sequence of random variables such that Z_n \\in [0, 1], then \\mathbb{E}\\{Z \\cdot X\\}_n \\leq \\mathbb{E}X_n Corollary If X_n is a non-negative sub-martingale with initial term X_0 = 0, then Doob’s Maximal Inequality claims that for any \\alpha \\in \\mathbb{R}: \\mathbb{P}[max_{k \\leq n} X_k \\geq \\alpha] \\leq \\mathbb{E}X_n/\\alphaand that: \\mathbb{P}[max_{k \\leq n} |X_k| \\geq \\alpha] \\leq \\mathbb{E}X_n^2/\\alpha^2Note that this is a big improvement on the Chebyshev Inequality, which claims that given L^2-bounded random variable X and for any k\\in\\mathbb{R}^+: \\mathbb{P}[|X - \\mathbb{E}X| \\geq k\\sqrt{VarX}] \\leq 1/k^2Martingale Convergence TheoremDefinition a sequence x_i of real numbers is called a Cauchy sequence if for every positive real number \\epsilon, there is a positive integer N such that for all natural numbers m, n > N such that |x_m - x_n| \\leq \\epsilon Definition L^2 martingales have orthogonal increments. Given X_n a L^2 martingale with increments \\xi_n := X_n - X_{n-1} and X_0 = 0, then: \\mathbb{E}\\xi_n\\xi_{n+m} = 0, \\forall \\;n < m, and \\mathbb{E}X^2_n = \\sum_{i=1}^n\\mathbb{E}\\xi^2_i Theorem Suppose X_n is L^1-bounded martingale, then there exists a L^1-bounded random variable X_{\\infty} such that: \\lim_{n \\rightarrow \\infty} X_n = X_{\\infty} \\;\\text{a.s.}Theorem Suppose X_n is L^2-bounded martingale, then there exists a L^2-bounded random variable X_{\\infty} such that: (1) \\lim_{n \\rightarrow \\infty} X_n = X_{\\infty} \\;\\text{a.s.}(2) \\lim_{n \\rightarrow \\infty} \\mathbb{E}|X_n - X_{\\infty}|^2 = 0, and\\; \\lim_{n \\rightarrow \\infty} \\mathbb{E}X_n^2 = \\mathbb{E}X_{\\infty}^2 Change Of MeasureProposition Given P a probability measure and Z is a non-negative random variable satisfying \\mathbb{E}_{P}Z = 1, then there exist a probability measure Q such that for any bounded or non-negative random variable Y that \\mathbb{E}_QY = \\mathbb{E}_PYZ. Z is called the likelihood ratio of probability measure Q w.r.t. P, written as Z = dQ/dP and that: \\mathbb{E}_QY = \\mathbb{E}_P\\dfrac{dQ}{dP}YProposition If the outcome space \\Omega is finite, then for each outcome \\omega \\in \\Omega, Q(\\omega) = P(\\omega)Z(\\omega) Example 1 In a N-period market with finite set of outcomes and tradable assets. Let P, Q denote the risk-neutural measure for USD and EUR investors. Let S_t^i, \\tilde{S}_t^i denote the USD and EUR price of the risk-less (w.r.t. its own measure) asset B^i at time t. Then dP/dQ = S^1_0/S^1_N Proof. By fundamental theorem, \\tilde{S}_t^i = \\mathbb{E}_Q\\tilde{S}_N^i, and \\tilde{S}_t^i=S_t^i/S_t^1, so: S_t^i = \\mathbb{E}_Q[S_N^i\\times S^1_0/S^1_N] = \\mathbb{E}_PS_N^iTheorem Let P and Q be two probability measure on the same measurable space, and let \\mathcal{F}_n be a filtration such that for all n Q is absolutely continuous w.r.t. P on mathcal{F}_n. Then the sequence of likelihood ratio L_n is a martingale: L_n := \\{\\dfrac{dQ}{dP}\\}_{\\mathcal{F_n}}Brownian MotionStandard Bronwian MotionDefinition A standard Brownian motion (SBM) is a continuous-time random process B_t such that B_0 = 0 and:(a) B_t has stationary increments.(b) B_t has independent increments.(c) The sample path t \\rightarrow B_t are continuous. Note that (a), (b), and (c) imply that for some constant \\sigma^2>0 the distribution of B_{t+s}-B_s is \\mathcal{N}(0, \\sigma^2t) Definition Given a SBM B_t, W_t = \\mu t + \\sigma B_t is a Brownian motion with drift \\mu and variance \\sigma^2. Proposition Given a SBM B_t, its reflection -B_t is also a SBM. Proposition Given a SBM B_t, then for any \\alpha \\in\\mathbb{R}^+, \\tilde{B} := B_{\\alpha t}/\\sqrt{\\alpha} is a SBM Quadratic VariationDefinition The nth level quadratic variation of a function f: [0,t] \\rightarrow \\mathbb{R} is the sum of squares of the increments across intervals of length 2^{-n}: QV(f; n; [0,t]) = \\sum_{k=1}^{2^nt} [f(\\dfrac{k}{2^n})] - f(\\dfrac{k-1}{2^n})]^2Theorem Given a SBM W_t with drift \\mu and variance \\sigma^2 > 0, then for all t>0 with probability 1: \\lim_{n\\rightarrow\\infty} QV(W; n; [0, t]) = \\sigma^2tStrong Markov PropertyDefinition Given a SBM B_t, a stoping time is a non-negative random variable T such that for every fixed t \\geq 0, the event \\{T \\leq t\\} depends only on the path \\{B_s\\}_{s\\leq t} Theorem If W_t is a Brownian motion and T is a stopping time then the strong Markov property holds:(a) the process \\{B_{t+T} - B_T\\}_{t\\geq 0} is a Brownian motion, and(b) the process \\{B_{t+T} - B_T\\}_{t\\geq 0} is independent of the path \\{B_s\\}_{s\\leq T} Theorem Run Brownian motion W_t, at the first time \\tau that W_{\\tau} = a > 0, reflect the path in the line y=a, by the reflection principle the new process W^{\\ast}_t is another Brownian motion: for t \\leq \\tau, W^{\\ast}_t = W_t for t > \\tau, W^{\\ast}_t = 2a - W_t Corollary P[\\tau \\leq s] = 2P[W_s > a] Corollary M_t := max_{s \\leq t} W_s has the same distribution as |W_s| Corollary -M_t^- := -min_{s \\leq t} W_s has the same distribution as M_t. Hence P[M_t>a]=P[-M_t^-a]>0. Consequently, for every t>0 with probability 1 M_t>0 adn M_t^-0, the Brownian path crosses the t-axis infinitely many times by time \\epsilon Martingales In Continuous TimesDefinition A filtration is a nested family of \\sigma-algebra indexed by time t. Definition The natural filtration for a Brownian motion W_t is the filtration with \\mathcal{F}_t-the collection of all events determined by Brownian path up to time t. Definition A continuous-time stohastic process X_t is a martingale relative to a filtration \\mathcal{F_t}_{t\\geq 0} if:(a) each random variable X_t is measurable w.r.t. \\mathcal{F_t} and(b) for any s, t\\geq 0, \\mathbb{E}(X_{t+s}|\\mathcal{F}_t)=X_t Proposition Given a SBM B_t then each of these is a martingale relative to the natural filtration:(a) B_t(b) B_t^2 - t(c) e^{\\theta B_t - \\theta^2t/2} Theorem Define P_{\\theta} to be the probability measure with likehood ratio Z_t^{\\theta} = dP_{\\theta}/dP_0= e^{\\theta B_t - \\theta^2t/2}. The Cameron-Martin theorem states that the SBM B_t under P_0 is a Brownian motion with drift \\theta and variance \\sigma^2=1 under P_{\\theta}. Corollary For any real value \\theta, \\eta and t 0: dU = (U_t + \\dfrac{1}{2}U_{WW})dt + U_WdWProposition Assume f(t) is nonrandom and continuously differentiable. Then: \\int_t^{t+h} f(s) dW_s \\sim \\mathcal{N}(0, \\int_t^{t+h} f(s)^2 ds)Ito ProcessDefinition An Ito process is a stochastic process X_t that satisfies a stochastic differential equation of the form: dX_t = Y_t dW_t + Z_t dtEquivalently, X_t satisfies the stochastic integral equation: X_t = X_0 + \\int_0^t Y_sdW_s + \\int_0^t Z_sdsDefinition For any adapted process U_t define: \\int_0^t U_sdX_s = \\int_0^t U_sY_sdW_s + \\int_0^t U_sZ_sdsTheorem Let X_t be an Ito process, and let U be a twice-continuously differentiable function whose partial derivatives are all bounded. Then: dU = U_tdt + U_XdX_t + \\dfrac{1}{2}U_{XX}d[X_t, X_T]The Ornstein-Uhlenbeck ProcessDefinition The Ornstein-Uhlenbeck SDE: dX_t = −\\alpha X_t dt + dW_t(a) This SDE describes a process Xt that has a proportional tendency to return to an “equilibrium” position 0.(b) In finance, the OU process is often called the Vasicek model.(c) Solving the SDE: Xt =e^{−\\alpha t}X_0 + e^{-\\alpha t} \\int_0^t e^{\\alpha s}dW_s(d) The Ornstein-Uhlenbeck process is Gaussian. The Exponential MartingaleDefinition The Exponential Martingale SDE: dX_t = −\\theta X_t dW_t(a) Solving the SDE: X_t = Ce^{ − \\theta^2t/2 + \\theta W_t} The Diffusion ProcessDefinition The Diffusion SDE: dX_t = \\mu(X_t)dt+ \\sigma (X_t)dW_t Definition The Harmonic Function is a function f(x) that satisfies the ODE: \\mu (x)f'(x) + \\dfrac{1}{2}\\sigma^2(x)f''(x) = 0Example Let X_t be a solution of the diffusion SDE with initial value X_0 = x_0, and for any real numbers A \\leq x_0 \\leq B let \\tau := min\\{t: X_t \\notin (A, B)\\}. Find P(X_{\\tau} = B) We first apply the Ito Formula to df(X_t) and observe that a harmonic function f will force the dt term to vanish. Therefore f(X_t) is a martingale and that \\mathbb{E}f(X_{\\tau}) = f(x_0): f(x_0) = P(X_{\\tau} = B)f(B) + (1- P(X_{\\tau} = B))f(A) \\\\ \\rightarrow P(X_{\\tau} = B) = \\dfrac{f(x_0) - f(A)}{f(B) - f(A)}We can solve for f(x): f(x) = \\int_A^x C' e^{-\\int_A^z \\dfrac{2\\mu(y)}{\\sigma^2(y)}dy}dz + C''The Diffusion Process - Bassel ProcessDefinition The Diffusion SDE: dX_t = a/X_tdt+ dW_t Example Similar problem as above: P(X_{\\tau} = B) = \\dfrac{f(x_0) - f(A)}{f(B) - f(A)} \\;\\;\\text{where}\\\\ f(x) = Cx^{-2a+1} + C'Note that if x_0 > 0 and a \\geq 1/2 then X_t will never reach 0. Ito Formula - Multi-VariableTheorem Let \\textbf{W}_t =(W_t^1,W_t^2,...,W_t^K) be a K−dimensional SBM, and let u: \\mathbb{R}^K \\rightarrow \\mathbb{R} be a C^2 function with bounded first and second partial derivatives. Then the Ito Formula states: du(\\textbf{W}_t) = \\nabla u(\\textbf{W}_t)d\\textbf{W}_t + \\dfrac{1}{2} \\triangle u(\\textbf{W}_t)dtWhere: \\nabla u(\\textbf{W}_t) = \\sum_{i=1}^K \\dfrac{\\partial u}{\\partial x_i}(\\textbf{W}_t) \\\\ \\triangle u(\\textbf{W}_t) = \\sum_{i=1}^K \\dfrac{\\partial^2 u}{\\partial x_i^2}(\\textbf{W}_t)Corollary If \\tau is a stopping time for the SBM \\textbf{W}_t then Dynkin’s Formula shows that for any fixed time t: \\mathbb{E} u(\\textbf{W}_{t\\wedge\\tau}) = u(\\textbf{0}) + \\dfrac{1}{2} \\mathbb{E} \\int_0^{t\\wedge\\tau} \\triangle u(\\textbf{W}_s)dsAnd that u(\\textbf{W_t}) \\dfrac{1}{2} \\int_0^{t} \\triangle u(\\textbf{W}_s)ds is a martingale Definition A C^2 function u: \\mathbb{R}^K \\rightarrow \\mathbb{R} is said to be a Harmonic Function in a region \\mathcal{U} if \\triangle u(x)=0, \\; \\forall x \\in \\mathcal{U} (a) 2D Harmonic Function Exmaple: u(x,y)=log(x^2 +y^2)=2logr(b) 3D Harmonic Function Example: u(x,y,z)=1/\\sqrt{x^2 +y^2 +z^2} =1/r Corollary Let u be harmonic in the an open region \\mathcal{U} with compact support, and assume that u and its partials extend continuously to the boundary \\partial\\mathcal{U}. Define \\tau to be the first exit time of Brownian motion from \\mathcal{U}, then: (a) the process u(W_t\\wedge\\tau) is a martingale, and(b) for every x \\in \\mathcal{U}, \\;\\mathbb{E}^xu(W_{\\tau}) = u(x) Example If a 2D SBM starts at a point on the circle C_1 of radius 1, find out the probability p that it hits concentric circles C_2 before C_{1/2}. Let u(x, y) = log r be harmonic. Then u(W_t\\wedge\\tau) is a martingale and that \\mathbb{E} u(W_t\\wedge\\tau) = u(W_0) = log(1) = 0. \\mathbb{E} u(W_t\\wedge\\tau) = (p)log2 + (1-p)log(1/2) = 0 \\\\ \\rightarrow p = 1/2Example If a 3D SBM starts at a point on the sphere C_1 of radius 1, find out the probability p that it hits concentric sphere C_2 before C_{1/2}. Let u(x, y) = 1/r be harmonic. Then u(W_t\\wedge\\tau) is a martingale and that \\mathbb{E} u(W_t\\wedge\\tau) = u(W_0) = 1/1 = 1. \\mathbb{E} u(W_t\\wedge\\tau) = (p)1/2 + (1-p)1/(1/2) = 1 \\\\ \\rightarrow p = 2/3Ito Process - Multi-VariableDefinition An Ito process is a continuous-time stochastic process X_t of the form: X_t = X_0 + \\int_0^t M_sds + \\int_0^t \\textbf{N}_s d\\textbf{W}_sWhere the quadratic variation d[X_t, X_t] = \\textbf{N}_t \\cdot \\textbf{N}_t dt Let \\textbf{X}_t = (X^1_t,X^2_t,...,X^m_T) be a vector of Ito processes. For any C^2 function u:\\mathbb{R}^m \\rightarrow \\mathbb{R} with bounded first and second partial derivatives, then: du(\\textbf{X}_t) = \\sum_{i=1}^m u_{X_i}(\\textbf{X}_t)dXi + \\dfrac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m u_{X^iX^j}(\\textbf{X}_t)d[X^i_t, X^j_t]Theorem Let \\textbf{W}_t be a K −dimensional SBM, and let \\textbf{U}_t be an adapted, K−dimensional process satisfying |\\textbf{U}_t|=1, \\;\\;\\forall t \\geq 0. Then the Knight’s Theorem states that the 1-dimensional Ito process X_t is a SBM: X_t := \\int_0^t \\textbf{U}_s d\\textbf{W}_sProposition Let \\textbf{W}_t be a K −dimensional SBM. Define R_t := |\\textbf{W}_t| be the radial part of \\textbf{W}_t. Then R_t is a Bessel process with parameter (K-1): dR_t = (K-1)/2R_t \\; dt + d\\tilde{W}_t \\\\ \\text{where}\\;\\; \\tilde{W}_t := \\int_0^t \\dfrac{\\textbf{W}_s}{|\\textbf{W}_s|}d\\textbf{W}_s \\;\\;\\text{is a 1-D SBM}Barrier OptionPricingDefinition A barrier option at time T pays:(a) \\1ifmax_{0 \\leq t \\leq T}\\;S_t \\geq AS_0$,(b) \\0$ otherwise. Assume that S_t follows GBM: dS_t = rS_tdt + \\sigma S_tdW_t \\\\ \\rightarrow S_t = S_0e^{(r-\\sigma^2/2)t + \\sigma W_t}The no-arbitrage price V_t of the barrier option at t=0 is the expected payoff: \\begin{align} V_0 &= \\mathbb{E}\\textbf{1}_{max_{0 \\leq t \\leq T}\\;S_t \\geq AS_0}\\\\ &= e^{-rT}\\mathbb{P}\\{max_{0 \\leq t \\leq T}\\;S_t \\geq AS_0\\} \\\\ &= e^{-rT}\\mathbb{P}\\{max_{0 \\leq t \\leq T}\\;W_t + (r/\\sigma -\\sigma/2)t \\geq (logA)/\\sigma\\} \\;\\;\\text{[GBM]}\\\\ &= e^{-rT}\\mathbb{P}\\{max_{0 \\leq t \\leq T}\\;W_t + \\mu t \\geq a\\} \\\\ &= e^{-rT}\\mathbb{P}_{\\mu}\\{max_{0 \\leq t \\leq T}\\;W_t \\geq a\\} \\;\\;\\text{[Cameron-Martin Theorem]}\\\\ &= e^{-rT}\\mathbb{E} \\;Z^{\\mu}_T \\;\\textbf{1}_{\\{max_{0 \\leq t \\leq T}\\;W_t \\geq a\\}}\\\\ &= e^{-rT}\\mathbb{E} \\;e^{-\\mu^2T/2 + \\mu W_T} \\;\\textbf{1}_{\\{max_{0 \\leq t \\leq T}\\;W_t \\geq a\\}}\\\\ &= e^{-rT}e^{-\\mu^2T/2} \\mathbb{E} \\;e^{\\mu W_T} \\;\\textbf{1}_{\\{max_{0 \\leq t \\leq T}\\;W_t \\geq a\\}}\\\\ &= e^{-rT}e^{-\\mu^2T/2} \\dfrac{1}{2}[\\Phi(\\mu\\sqrt{T}-a/\\sqrt{T}) + e^{2\\mu a}\\Phi(-\\mu\\sqrt{T}-a/\\sqrt{T})]\\;\\;\\text{[Reflection Principle]}\\\\ \\end{align}At time t, there are two possibilities:(a) if max_{0 \\leq r \\leq t}\\;S_r \\geq AS_0, then V_t = e^{-r(T-t)}(b) if max_{0 \\leq r \\leq t}\\;S_r \\leq AS_0, then V_t is the same as the time-0 value V_0 of a barrier option with time-to-maturity T-t and A'=AS_0/S_t HedgingLet v(t, S_t) be the value of the barrier option at time t. The Fundamental Theorem and Ito Formula show that v(t, S_t satisfy the Black-Scholes PDE: rv = v_t + rSv_S + \\dfrac{1}{2}\\sigma^2S^2v_{SS} \\\\ \\text{for} \\;\\; t \\leq T \\;\\;\\text{and}\\;\\; x\\leq AS_0A replicating portfolio for the barrier option holds(a) v_S share of stock(b) e^{-rt}(v - v_SS) share of cash provided that S_t\\leq AS_0. Once S_t\\geq AS_0 the portfolio convert all holdings to cash and hold till maturity. The Black-ScholesThe Black-Scholes FormulaTheorem Under a risk-neutral P, the Fundamental Theorem asserts that discounted share price S_t/M_t is a martingale, where: dM_t = r_tM_tdt, \\;\\;\\text{and}\\;\\; dS_t = \\mu_t S_tdt + \\sigma S_tdW_tTherefore \\mu_t \\equiv r_t: \\mathbb{E}[\\dfrac{S_t}{M_t}] = \\mathbb{E}[\\dfrac{S_0}{M_0}e^{\\int_0^t \\mu_sds - \\sigma^2t/2 + \\sigma W_t - \\int_0^t r_sds}] \\\\ \\rightarrow \\dfrac{S_t}{M_t} = \\dfrac{S_0}{M_0}e^{- \\sigma^2t/2 + \\sigma W_t}Definition A European contingent claim with expiration date T > 0 and payoff function f: \\mathbb{R}\\rightarrow\\mathbb{R} is a tradeable asset with:(a) share price at time T: f(S_T)(b) discounted share price at time t < T: \\mathbb{E}[f(S_T)/M_T | \\mathcal{F}_t] Proposition Let W_t be a standard Brownian motion and g:\\mathbb{R}\\rightarrow\\mathbb{R} is a function such that \\mathbb{E}|g(W_T)| < \\infty. Then for every 0 \\leq t \\leq T: \\mathbb{E}(g(W_T) | \\mathcal{F}_t)=u(T−t,W_t) \\;\\;\\text{where} \\\\ u(T-t, x)= \\dfrac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} g(x+\\sqrt{T-t}z)e^{-z^2/2} dzCorollary Given dS_t = r_t S_tdt + \\sigma S_tdW_t, the Black Scholes Formula shows: \\mathbb{E}(f(S_T)/M_T | \\mathcal{F}_t) = v(T−t,S_t)/M_T \\;\\;\\text{where} \\\\ v(T-t, x)= \\dfrac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} f(xe^{\\sigma\\sqrt{T-t}z - \\sigma^2(T-t)/2 + \\int_0^T r_sds - \\int_0^t r_sds})e^{-z^2/2} dzUnder risk-neutral P, the time t option price u(t,S_t)/M_T is a martingale. With the Ito Formula we can set the drift of du to be zero and therefore derive the Black Scholes PDE: -r_tu + u_t + r_tSu_S + \\dfrac{1}{2}\\sigma^2S^2u_{SS} = 0 \\\\ \\text{with terminal condition} \\;\\; u(T, S_T) = f(S_T)Hedging In Continuous TimesDefinition A portfolio V_t = \\alpha_t M_t + \\beta_t S_t is self-financing if dV_t = \\alpha_t dM_t + \\beta_t dS_t for all t \\leq T Proposition A portfolio V_t is self-financing if and only if its discounted value V_t/M_t is a martingale and satisfies: V_t/M_t = V_0/M_0 + \\int_0^t\\beta_s\\sigma S_s/M_s \\;dW_sDefinition A replicating portfolio V_t for a payoff function f(S_T) is a self-financing portfolio such that V_T = f(S_T) Theorem A replicating portfolio for contingent claims f(S_T) is given by:(a) \\alpha_t = (u - u_SS_t)/M_t cash, and(b) \\beta_t = u_S shares of stock where u is the solution of the Black Scholes PDE satisfying u(T, S_T) = f(S_T) The Girsanov TheoremProposition The exponential process Z_t is a positive martingale. Z_t := e^{\\int_0^t Y_sdW_s - \\dfrac{1}{2}\\int_0^t Y_s^2ds} \\\\ \\text{given}\\;\\; \\mathbb{E}\\int_0^t Z_s^2Y_s^2 ds < \\infty \\;\\;\\forall t < \\inftyApplying Ito Formula Z_t = 1 + \\int_0^t Z_sY_sdW_s and therefore \\mathbb{E}Z_t = 1 Therorem Given W_t a SBM under P-measure and the likelihood ratio Z_t, define the Q-measure where dQ/dP = Z_t. Then the Girsanov’s Theorem states that under the Q-measure:(a) \\tilde{W}_t = W_t - \\int_0^t Y_sds is a SBM(b) W_t is a BM with time-dependent drift \\int_0^t Y_sds Example 1 Given W_t a brownian motion with W_0 \\in (0, A), define measure Q be the conditional probability measure on event \\{W_T = A\\}. Therefore W_t is a BM with drift W_t^{-1}dt. Proof. We know that \\mathbb{P}[W_T = A] = W_0/A, therefore by change of measure: \\begin{align} \\dfrac{dQ}{dP}|\\mathcal{F_T} &= \\dfrac{\\textbf{1}\\{W_T = A\\}}{\\mathbb{P}[W_T = A]} \\\\ \\dfrac{dQ}{dP}|\\mathcal{F_{T\\wedge t}} &= \\mathbb{E}[(\\dfrac{dQ}{dP}|\\mathcal{F_T})| \\mathcal{F_{T\\wedge t}}] \\;\\;\\text{[Since LR is a martingale]}\\\\ &= \\dfrac{\\mathbb{P}[W_T = A | \\mathcal{F}_{T\\wedge t}]}{\\mathbb{P}[W_T = A]} \\\\ &= W_{T\\wedge t}/W_0 \\\\ &= e^{\\int_0^{T\\wedge t} W_s^{-1}ds - \\dfrac{1}{2}\\int_0^{T\\wedge t} W_s^{-2}ds} \\;\\;\\text{[Ito Formula]} \\\\ \\end{align}Therefore Girsanov’s Theorem implies that under Q, \\tilde{W}_t = W_t - \\int_0^{T\\wedge t} W_s^{-1}ds is a SBM. Example 2 Given currency A, B and their respective bank account dA_t = r^A_tA_tdt and dB_t = r^B_tB_tdt. Define exchange rate (# B per A) Y_t that dY_t = \\mu_t Y_tdt + \\sigma Y_tdW_t Theorem If W_t is a SBM under measure Q^B then \\mu_t = r^B_t - r^A_t. Proof. Y_t(A_t/B_t) is a martingale only if \\mu_t = r^B_t - r^A_t Theorem \\dfrac{dQ^A}{dQ^B} | \\mathcal{F}_T = e^{-\\sigma^2T/2 + \\sigma W_T} = Y_T(A_T/B_T)Levy ProcessPoisson ProcessDefinition A Levy process is a continuous-time random process \\{X_t\\}_{t\\geq 0} such that X_0 = 0 and:(a) X_t has stationary increments;(b) X_t has independent increments;(c) the sample paths t \\rightarrowX_t$ are right-continuous. Note that Brownian motion and Poisson process are both Levy processes and the basic building blocks of Levy processes. Brownian motion is the only Levy process with continuous paths. Example Let W_t be a SBM and for a \\geq 0, the random variable \\tau_a is a Levy process. \\tau_a = inf\\{t>0: W_t>a\\}Note that:(a) \\tau_a has stationary, independent increments(b) \\tau_{ab} has the same distribution as b^2\\tau_a Definition A Poisson process with rate \\lambda > 0 is a Levy process N_t such that for all t \\geq 0 the random variable N_t follows Poisson distribution with mean \\lambda t: P[N_t = k] = \\dfrac{(\\lambda t)^k}{k!}e^{-\\lambda t}Proposition If X, Y are independent Poisson distributions with mean \\lambda, \\mu, then X+Y \\sim Poisson(\\lambda + \\mu). Proof. P(X+Y=n) = \\sum_{m=0}^nP(X=m \\;\\;\\text{and}\\;\\; Y=n-m) Corollary IF N_t, M_t are independent Poisson processes with rates \\lambda, \\mu then the superposition N_t + M_t is a Poisson process with rate \\lambda + \\mu Proposition Every discontinuity of a Poisson process is of size 1 Proposition Let N_t be a Poisson process of rate \\lambda > 0, and let \\xi_i be an independent sequence of i.i.d. Bernoulli−p random variables. Then the Thinning Theorem states that N^S_t, N^F_t are independent Poisson processes with rates \\lambda p, \\lambda (1-p): N^S_t = \\sum_{i=1}^{N_t} \\xi_i \\sim Poission(\\lambda p) \\\\ N^F_t = \\sum_{i=1}^{N_t} (1 - \\xi_i) \\sim Poission(\\lambda(1-p))Theorem If n \\rightarrow \\infty and p_n \\rightarrow 0 in such a way that np_n \\rightarrow \\lambda > 0, then the Law of Small Numbers states that the Binomial(n, p_n) distribution converges to the Poisson(\\lambda) distribution. Proposition If N_t is a rate−\\lambda Poisson process, then for any real number \\theta the process Z_t :=e^{\\theta N_t + (\\lambda - \\lambda e^{\\theta})t}􏰍 is a martingale. Theorem Define Q with likelihood ratio Z_t such that dQ/dP | \\mathcal{F}_t = Z_t. Then under Q the process N_t is a rate--\\lambda e^{\\theta} Poisson process. Compound Poisson ProcessDefinition A compound Poisson process X_t is a Levy process of the form: X_t = \\sum_{i=1}^{N_t} Y_iWhere N_t is rate-\\lambda Poisson process and Y_i are i.i.d. random variable independent of N_t. The distribution F_{Y} is the compounding distribution and the measure \\lambda \\times F_{Y} is the Levy measure. At each T_i \\in N_t, a random Y_i is draw from F_{Y}. X_t is the sum of all draws made by time t Proposition If \\psi(\\theta) = \\mathbb{E}e^{\\theta Y_i} < \\infty, then \\mathbb{E} e^{\\theta X_t} = e^{-t\\lambda (1- \\psi(\\theta))}, and \\theta \\in \\mathbb{R}, Z_t^{\\theta} = e^{\\theta X_t - \\lambda t(\\psi(\\theta)-1)} is an exponential martingale. Poisson Point ProcessDefinition Let \\mu be a \\sigma−finite Borel measure on \\mathbb{R}^n. A Poisson point process \\mathcal{P} with intensity measure \\mu is a collection \\{N_B\\}_{B\\in\\mathcal{B}} of extended nonnegative integer-valued random variables such that(A) If \\mu(B) = \\infty then N_B = \\infty a.s.(B) If \\mu(B) < \\infty then N_B \\sim Poisson(\\mu(B))(C) If \\{N_i\\}_{i\\in\\mathbb{N}} are pairwise disjoint, then the r.v.s N_{B_i} are independent, and N_{\\cup_i B_i} = \\sum_{i=1}^{\\infty} N_{B_i} Proposition The point process (T_n, Y_n) associated with a CPP is a Poisson point process with intensity measure Lebesgue \\times v, where v=\\lambda F is the Levy measure for the CPP. Theorem Let X_t be any Levy process, and let J be the random set of points (t,y) \\in [0,\\infty) \\times \\mathbb{R} such that the Levy process X has a jump discontinuity of size y at time t, i.e., X_t − X_{t−} = yThen J is a Poisson point process with intensity measure Lebesgue \\times v where v is a \\sigma−finite measure called the Levy measure of the process.","tags":"notes"},{"title":"&#128214; Notes on MSFM - Option Theory","url":"/2019/12/finm-notes/02_option_theory/","text":"img.resize { max-width:50%; max-height:50%; } This is a study note on the fundamental theory of the pricing of a financial derivative, whose payoff is defined in terms of an underlying asset. We hereby try to compute a consistent price of the derivative in relative terms to the market price of the underlying asset. Option Pricing TheoryWe make our first assumption that the market is frictionless, by which we mean that: no transaction cost (commission, bid-ask spread, taxes) can hold negative asset (shortting) and there is no margin constraint can hold fractional asset no market impact from trading Arbitrage (Static Portfolio)We assume that the market lives in a probability space \\mathbb{P} and it includes N tradable assets with non-random time-0 prices and random time-T prices: \\textbf{X}_t := (X^1_t, \\dots, X^N_t)A static portfolio is a vector of quantities, where each \\theta is non-random and constant in time: \\Theta := (\\theta^1, \\dots, \\theta^N)Thus the time-t value of the static portfolio \\Theta is; V_t := \\Theta \\cdot \\textbf{X}_tA static portfolio \\Theta is an arbitrage if its value V_t satisfies that: V_0 = 0 \\text{, and both } \\mathbb{P}[V_T \\geq 0] = 1 \\text{ and } \\mathbb{P}[V_T > 0] > 0Suppose portfolio \\Theta^a super-replicates portfolio \\Theta^b, which means that \\mathbb{P}[V^a_T > V^b_T] = 1. Then V^a_0 \\geq V^b_0, otherwise arbitrage exists. Same goes if it is a sub-replication. Therefore, if \\Theta^a replicate \\Theta^b, which menas that \\mathbb{P}[V^a_T = V^b_T] = 1, then V^a_0 = V^b_0. This is called the law of one price. AssetsDiscount BondA discount bond Z pays 1 at maturity T. Given non-random interest rate r_t, the no-arbitrage price of the discount bond is: Z_0 = 1/B_T = e^{-\\int_0^Tr_tdt} \\\\ = e^{-rT} \\text{ if r is constant}Forward ContractA forward contract on S_T with non-random delivery price K obligates its holder to pay K and receive S_T at time T. The time-0 value of the forward contract is S_0 - KZ_0. A forward price F_0 is delivery price such that the value of forward contract at time-0 is zero. F_0 = S_0/Z_0\\\\ = S_0e^{-rT} \\text{ if r is constant}European Call OptionAn European call option gives its holder the right at time T to pay K and receive S_T. A call has payoff (S_T-K)^+, and it is in the money if S_t>K at time t\\leq T. The time-0 price C_0 of a call option satisfies: (S_0-KZ_0)^+\\leq C_0 \\leq S_0For strike K_1 0Ito ProcessWe define an Ito process to be a stochastic process X that: X_t = X_0+\\int_0^t\\mu_sds + \\int_0^t\\sigma_sdW_s \\\\ \\text{equivalently, } dX_t = \\mu_tdt + \\sigma_tdW_tThe existence and uniqueness of a solution of X can be guaranteed by Lipschitz-type technical condition on \\mu_t and \\sigma_t Ito’s RuleThe Ito&#39;s rule states that give n an Ito process X_t, and a sufficiently smooth function f(X_t): df(X_t) = \\dfrac{\\partial f}{\\partial x}dX_t + \\dfrac{1}{2}\\dfrac{\\partial^2f}{\\partial x^2}(dX_t)^2With two processes X_t and Y_t, and f(X_t, Y_t): df(X_t, Y_t) = \\dfrac{\\partial f}{\\partial x}dX_t + \\dfrac{\\partial f}{\\partial y}dY_t + \\dfrac{1}{2}\\dfrac{\\partial^2f}{\\partial x^2}(dX_t)^2 + \\dfrac{1}{2}\\dfrac{\\partial^2f}{\\partial y^2}(dY_t)^2 + \\dfrac{\\partial^2f}{\\partial x\\partial y}(dX_t)(dY_t)In a special case where Y_t = t, the formula becomes: df(X_t, t) = \\dfrac{\\partial f}{\\partial x}dX_t + \\dfrac{\\partial f}{\\partial t}dt + \\dfrac{1}{2}\\dfrac{\\partial^2f}{\\partial x^2}(dX_t)^2Note that the Ito’s Rule applies under any probability measure, it is purely math. Black-Scholes ModelAssumptions Consider two basic assets B_t and S_t in continuous time, where: dB_t = rB_tdt \\text{ , }\\\\ \\text{ where }B_0=1And S_t follows GBM dynamics, dS_t = \\mu S_tdt + \\sigma S_tdW_t \\\\ \\text{ where }S_0>0 \\text{ , }\\sigma>0\\text{ ,and W is BM under physical measure}Conclusion Then by no-arbitrage and Ito&#39;s rule, the time-t price C_t of a call option with payoff (S_T-K)^{+} satisfies the Black-Scholes PDE for (S, t)\\in [0, \\infty]\\times (0, T) \\dfrac{\\partial C}{\\partial t} + rS\\dfrac{\\partial C}{\\partial S} + \\dfrac{1}{2}\\sigma^2S^2\\dfrac{\\partial^2C}{\\partial S^2} = rC \\\\ \\text{ with terminal condition: } C(S, T)=(S-K)^{+}We can solve the call price analytically with the Black-Scholes formula: C^{BS}(S_t, t) := S_tN(d_1) - Ke^{-r(T-t)}N(d_2) \\\\ \\text{where } d_{1,\\ 2} := \\dfrac{log(S_t/K) + (r \\pm \\sigma^2/2)(T-t))}{\\sigma\\sqrt(T-t)}Here we plotted the BS call price C^{BS}, the intrinsic value (S_t - K)^{+} and the lower bound (S_t - Ke^{-r(T-t)})^{+} against the current underlying price S_t, with paramters K=100, T-t=1, \\sigma=0.2 and r=0.05 The GreeksDeltaSuppose an asset has a time t value V_t(S_t, t), then its Delta at time t is \\partial V_t(S_t, t)/\\partial S_t. Delta can be interpreted as: the slope of the asset value V_t, plotted as a function of S_t. how much the asset value movies per unit move in S_t humber of S_t needed to replicate this asset. If the asset is a call option on S_t and we assumes the Black-Scholes assumptions on S_t, then: \\begin{align} \\text{Delta} &:= \\dfrac{\\partial C^{BS}}{\\partial S_t} \\\\ &=N(d_1) + S_tN'(d_1)\\dfrac{\\partial d_1}{\\partial S_t} - Ke^{-(T-t)}N'(d_2)\\dfrac{\\partial d_2}{\\partial S_t} \\\\ &=N(d_1) \\end{align}The Delta of a call option is strictly between 0 and 1. As the time-to-maturity decreases, the Delta increases faster the the option becomes more ITM. Here we plotted the BS Delta for T-t equals 1 and 0.25 against the current underlying price S_t. GammaFor a call option in a B-S model, \\text{Gamma} = \\dfrac{\\partial^2 C^{BS}}{\\partial S_t^2} = N'(d_1)\\dfrac{1}{S_t\\sigma\\sqrt{T-t}}In this case, the Gamma can be interpreted as: the convextity of C^{BS} w.r.t. S_t how much the Delta moves, per unit move in S_t how much rebalancing of the replicating portfolio is needed, per unit move in S_t The Gamma of a call option is strictly positive. As the time-to-maturity decreases, the Gamma increases for ATM options. Here we plotted the BS Delta for T-t equals 1 and 0.25 against the current underlying price S_t. ThetaFor a call in B-S model, \\text{Theta} = \\dfrac{\\partial C^{BS}}{\\partial t}The Theta of a call option is strictly negative. As the time-to-maturity decreases, the Theta decreases for ATM options (faster time-decay). Here we plotted the BS Theta for T-t equals 1 and 0.25 against the current underlying price S_t. Discrete Delta Hedge and Gamma ScalpingA discretely Delta-hedged portfolio could buy C and short \\text{Delta} \\cdot S. In this case it is a Delta neutral and long Gamma/Gamma scalping portfolio: Delta of the portfolio is 0 Gamma of the portfolio is positive achieve net profit only if the realized volatility of S is high enough to overcome time decay, otherwise portfolio loss happens. This is the opposite from a short Gamma position, e.g. sell C and long Delta S We can visualize the P&amp;L of a long Gamma portfolio in the following graph, where the green area indicate profits and the red area indicate losses. The curved line is C_{t+\\Delta t} the straight line is \\text{Delta}_t \\cdot S_{t+\\Delta t}. As \\Delta t increases, C_{t+\\Delta t} shifts downwards due to time-decay. In addition, we can show that the P&amp;L of such portfolio dV = dC - C_S dS does not depend on the drift \\mu of the stock: \\begin{align} dV &= dC - C_S dS \\\\ &= C_tdt + C_SdS^{\\sigma_{implied}} + C_{SS}dS^2 - C_SdS^{\\sigma_{realized}} \\\\ &= (C_t + C_{SS}\\sigma_{implied}^2S^2/2)dt + C_S(\\sigma_{implied} - \\sigma_{realized})SdW \\end{align}Continue on L5 Numerical MethodsThe Taylor series of a real or complex value function f(x) that is differentiable at a is: f(x) = f(a) + \\dfrac{f'(a)}{1!}(x-a) + \\dfrac{f''(a)}{2!}(x-a)^2 ...Implied VolatilityGiven the time-t price of a European call option on a non-dividend stock S, the time-t Black Scholes implied volatility \\sigma(t) is the unique solution to C_t = C^{BS}(\\sigma(t)). Uniqueness is because C^{BS} is strictly increasing in \\sigma and Existence is because C^{BS} covers the full range of arbitrage-free prices of the European option [S_0-Ke^{-rT}, S_0] If S_t follows the SDE dynamic dS_t = rS_tdt + \\sigma(t)S_tdW_t, where \\sigma(t) a non-random function of t, then we can first find the implied volatility \\bar{\\sigma}_T given call prices with different maturity T, and use the equation below to find (not uniquely) the true function \\sigma(t): \\begin{align} logS_T &= logS_0 + (r-\\bar{\\sigma}^2_T/2)T + \\int_0^T \\sigma(t)dW_t \\\\ &\\sim \\mathcal{N}(logS_0 + (r-\\bar{\\sigma}^2_T/2)T, \\;\\bar{\\sigma}^2_TT) \\\\ &\\text{where } \\bar{\\sigma}_T := \\sqrt{\\dfrac{1}{T} \\int_0^T \\sigma^2(t)dt} \\end{align}Volatility Smile, Skew and SurfaceIf S_t truely follows GBM with constant volatility \\sigma, then \\sigma_{imp}(K, T) = \\sigma, \\;\\forall\\;K, T. However, empirically the \\sigma_{imp} is lower when K \\approx S_t (volatility smile), possibly because the market price option using a risk-neutral distribution of log-returns with fatter tails than Normal Note that \\sigma_{imp} is also higher when K < S_t (volatility skew), possibly due to: instantaneous volatility increases as price decreases possibility of severe crash fuels demand for downside protection In addition, the \\sigma_{imp} has a term structure and varies for different T. The function \\sigma_{imp}(K, T) is call the implied volatility surface Tree ModelBinomial TreeEuropean OptionGiven option price at the j-th node C_T^j = f(S_T^j), we can induct backward to find C_t^j: C_t^j = e^{-r\\tau}[p_n^jC_{t+1}^{j+1} + (1-p_n^j)C_{t+1}^{j-1}] \\\\ \\text{where } p_n^j = \\dfrac{S_t^je^{r\\tau} - S_{t+1}^{j-1}\\;}{S_{t+1}^{j+1} - S_{t+1}^{j-1}\\;}American Option - PutGiven option price at the j-th node C_T^j = (K - S_T^j)^+, we can induct backward to find C_t^j: C_t^j = max[(K - S_t^j)^+,\\;e^{-r\\tau}[p_n^jC_{t+1}^{j+1} + (1-p_n^j)C_{t+1}^{j-1}]] \\\\ \\text{where } p_n^j = \\dfrac{S_t^je^{r\\tau} - S_{t+1}^{j-1}\\;}{S_{t+1}^{j+1} - S_{t+1}^{j-1}\\;}American Option - CallGiven option price at the j-th node C_T^j = (S_T^j - K)^+. If r>0 and stock dividend \\delta=0, then it is never optimal to exercise early on an American call option. Therefore C^{American} = C^{European} Argument 1 At all t>0, the American call is worth more than the exercise payoff S_t - K: \\text{American Call} \\geq \\text{European Call} \\geq S_t - KZ_t > S_t - KArgument 2 If C^{American} > C^{European} then construct portfolio V = [-C^{American}, C^{European}]. Then V is an arbitrage as V_0 > 0 and V_T \\geq 0. Trinomial TreeLet \\Delta t:= T/N and choose \\Delta x \\approx \\sigma\\sqrt{3\\Delta t} to improve accruacy. Finite Difference ModelExplicit SchemeInducting backward from t=T to 0: \\begin{align} \\dfrac{\\partial C}{\\partial t} &\\approx \\dfrac{C^j_{t+1} - C^j_t}{\\Delta t} \\\\ \\dfrac{\\partial C}{\\partial x} &\\approx \\dfrac{C^{j+1}_{t+1} - C^{j-1}_{t+1}\\;}{2\\Delta x} \\\\ \\dfrac{\\partial^2 C}{\\partial x^2} &\\approx \\dfrac{1}{\\Delta x} (\\dfrac{C^{j+1}_{t+1} - C^{j}_{t+1}\\;}{\\Delta x} - \\dfrac{C^{j}_{t+1} - C^{j-1}_{t+1}\\;}{\\Delta x}) = \\dfrac{C^{j+1}_{t+1} -2C^{j}_{t+1} + C^{j-1}_{t+1}\\;}{(\\Delta x)^2} \\end{align}Solving for the B-S PDE: rC = C_t + vC_S + 0.5\\sigma^2C_{SS} where v = (r-\\sigma^2/2), we get: C^j_t = \\dfrac{1}{1 + r\\Delta t}(q_uC^{j+1}_{t+1} + q_mC^{j}_{t+1} + q_dC^{j-1}_{t+1})Where: \\begin{align} q_u &= \\dfrac{1}{2}[\\dfrac{\\sigma^2\\Delta t}{(\\Delta x)^2} + \\dfrac{v\\Delta t}{\\Delta x}] &=p_u - \\dfrac{v^2(\\Delta t)^2}{2(\\Delta x)^2}\\\\ q_m &= 1 - \\dfrac{\\sigma^2\\Delta t}{(\\Delta x)^2} &=p_m + \\dfrac{v^2(\\Delta t)^2}{(\\Delta x)^2}\\\\ q_d &= \\dfrac{1}{2}[\\dfrac{\\sigma^2\\Delta t}{(\\Delta x)^2} - \\dfrac{v\\Delta t}{\\Delta x}] &=p_d - \\dfrac{v^2(\\Delta t)^2}{2(\\Delta x)^2}\\\\ \\end{align}Note that p_u, p_m, p_d are trinomial tree probabilities. Implicit SchemeInducting backward from t=T to 0: (-\\alpha C^{j+1}_{t} + (1+2\\alpha)C^{j}_{t} + \\alpha C^{j-1}_{t}) = C^j_{t+1}Solving the LHS requires solutions of a system of 2J-1 equation with 2J-1 unknowns. Crank-Nicolson SchemeInducting backward from t=T to 0: -F^j_tC^{j+1}_t + (1+G^j_t)C^j_t - H^j_tC^{j-1}_t = F^j_{t+1}C^{j+1}_{t+1} + (1-G^j_{t+1})C^j_{t+1} + H^j_{t+1}C^{j-1}_{t+1}If given terminal conditions, then we know C_{t+1}‘s and can solve for C_t. Monte Carlo ModelGiven Y be a discounted payoff and the time-0 price of the payoff C=\\mathbb{E}Y. The Monte Carlo estimator \\hat{C}_M of C: \\hat{C}_M = \\dfrac{1}{M}\\sum Y \\\\ \\text{where } \\mathbb{E}\\hat{C}_M = C \\text{, and } Var(\\hat{C}_M) = Var(Y)/MBy the strong law of large numbers, the sample average \\hat{C}_M converges almost surely to the expected value C as M \\rightarrow \\infty. By the central limit theorem: \\dfrac{\\hat{C}_M - C}{Var(Y)/M} \\rightarrow \\mathcal{N}(0, 1) \\text{, as } M \\rightarrow \\inftyOften times we need to estimate \\sigma with sample estimator for the variance of Y: \\hat\\sigma^2_M := \\dfrac{\\sum (Y - \\hat{C}_M)^2}{M-1} \\\\ \\text{so then } \\dfrac{\\hat{C}_M - C}{\\hat{\\sigma}_M^2/M} \\rightarrow \\mathcal{N}(0, 1) \\text{, as } M \\rightarrow \\inftyThe standard error SE = \\hat{\\sigma}_M/\\sqrt{M}, and a 95\\% confident interval for C is \\hat{C}_M \\pm 1.96SE Variance Reduction TechniquesAntithetic VariateLet \\tilde{Y}:=Y_{Z = -z\\;}. The antithetic variate estimoator \\hat{C}^{av}_M: \\hat{C}^{av}_M = \\dfrac{1}{M}\\sum \\dfrac{Y + \\tilde{Y}\\;}{2} \\\\ \\text{where } Var(\\hat{C}^{av}_M) = \\dfrac{Var(Y) + Cov(Y, \\tilde{Y})}{M}Control VariateA control variate Y^\\ast is a random variable, correlated to Y such that C^\\ast := \\mathbb{E}Y^\\ast has an explicit formula. Example Let Y be the discounted payoff on a call on S_t where dS_t = \\sigma(t)S_tdW_t. We can choose Y^\\ast to be the discounted payoff on a call on S_t^{\\ast} where dS_t^{\\ast} = \\sigma S^{\\ast}_tdW_t, in which case C^{\\ast} can be calculated explicitely through B-S formula given constant \\sigma close to \\sigma(t). The control variate estimator \\hat{C}^{cv, \\beta}_M estimates C by simulating Y - \\beta Y^{\\ast}. Y^{cv, \\beta}_M = \\beta C^{\\ast} + (Y - \\beta dsY^{\\ast}) \\\\ \\hat{C}^{cv, \\beta}_M = \\mathbb{E}Y^{cv, \\beta}_M = \\beta C^{\\ast} + \\dfrac{1}{M}\\sum (Y - \\beta Y^{\\ast}) \\\\ \\text{and }Var(\\hat{C}^{cv}_M) = \\dfrac{1}{M}[Var(Y) - 2\\beta Cov(Y, Y^{\\ast}) + \\beta^2Var(Y^{\\ast})]Choose \\beta to minimize Var(\\hat{C}^{cv}_M), we get: \\beta^{\\ast} = \\dfrac{Cov(Y, Y^{\\ast})}{Var(Y^{\\ast})} \\rightarrow \\hat{\\beta^{\\ast}\\;} = \\dfrac{\\sum(Y - \\bar{Y})(Y^{\\ast} - \\bar{Y}^{\\ast})}{\\sum(Y^{\\ast} - \\bar{Y}^{\\ast})^2} \\\\ \\text{so then } Var(\\hat{C}^{cv, \\beta^{\\ast}\\;}_M) = Var(\\hat{C}_M)[1 - Corr^2(Y, Y^{\\ast})]Note that when using sample estimate \\hat{\\beta^{\\ast}\\;}, the estimated \\hat{C}^{cv, \\hat{\\beta}^{\\ast}\\;}_M is biased, only when M is small. Importance SamplingSuppose X are IID draws from density f, and C := \\mathbb{E}h(X). Ordinary Monte Carlo estimator provides: \\hat{C}_M = \\dfrac{1}{M}\\sum h(X)With importance sampling, find g s.t. g(x) > 0 iff f(x)g(x) \\neq 0. Then re-draw X from density g and the importance sampling estimator \\hat{C}^{is}_M is: \\hat{C}^{is}_M = \\dfrac{1}{M}\\sum h(X)\\dfrac{f(X)}{g(X)} \\\\ \\text{where } Var(\\hat{C}^{is}_M) = \\dfrac{1}{M}Var(h(X)\\dfrac{f(X)}{g(X)})Conditional Monte CarloGiven a random variable X: C = \\mathbb{E}Y = \\mathbb{E}[\\mathbb{E}(Y|X)] = f(X)The condintional Monte Carlo estimator: \\hat{C}^{cmc}_M = \\dfrac{1}{M}\\sum f(X) \\\\ \\text{where } Var(\\hat{C}^{cmc}_M) = \\dfrac{1}{M}Varf(X) < Var(\\hat{C}_M) \\\\ \\text{because } Var(Y) = Var[\\mathbb{E}(Y|X)] + \\mathbb{E}Var(Y|X)Fourier Transform ModelGiven f:\\mathbb{R}\\rightarrow\\mathbb{R} be integrable, meaning \\int|f(x)|dx < \\infty. The Fourier transform of f is the function \\hat{f}: \\mathbb{R}\\rightarrow\\mathbb{C} defined by: \\hat{f}(z) = \\int_{-\\infty}^{\\infty} \\hat{f}(x)e^{izx}dxTheorem If \\hat{f} is also integrable, then the inversion formula holds: f(x) = \\dfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat{f}(z)e^{-izx}dzCharacteristic FunctionThe complex conjugate of a complex number z = x + yi is given by \\bar{z} = x - yi. so \\text{Re}(z) = \\text{Re}(\\bar{z}). The characteristic function of any random variable X is the function F_X(z) defined by: F_X(z) := \\mathbb{E}e^{izX}Therefore if X has density f, then F_X(z) = \\hat{f}(z). A characteristic function uniquely identifies a distribution. For example, F_X(z) = e^{-z^2/2}, if X\\sim\\mathcal{N}(0,1) To calculate the moments of X using CF, take the n-derivatives of F_X(z) w.r.t. z: \\mathbb{E}X^n = (-i)^nF_X^{(n)}(0) To calculate the CDF of X using CF: \\mathbb{P}[X < k] = 0.5 - \\dfrac{1}{\\pi}\\int_0^{\\infty} \\text{Re}[\\dfrac{F_X(z)}{iz}e^{-izk}]\\;dz To calculate asset-or-nothing call price using CF, given e^X be the asset share price, define the share measure \\mathbb{P}^{\\ast} with likelihood ratio e^X/\\mathbb{E}e^X. F^{\\ast}_X(z) = \\mathbb{E}^{\\ast}e^{izX} = F_X(z - i)/F_X(-i)Therefore for any k\\in\\mathbb{R}, the asset-or-nothing call price: \\begin{align} e^{-rT}\\mathbb{E}e^X\\textbf{1}_{X>k} &= e^{-rT}\\mathbb{E}e^X\\mathbb{P}^{\\ast}(X>K) \\\\ &= e^{-rT}[\\dfrac{F_X(-i)}{2} + \\dfrac{1}{\\pi}\\int_0^{\\infty} \\text{Re}[\\dfrac{F_X(z - i)}{iz}e^{-izk}]\\;dz] \\end{align} To calculate a vanilla European call price on e^X struck at K with k := log\\;K: C_0 = e^{-rT}[\\mathbb{E}e^X\\textbf{1}_{X>k} - K\\mathbb{P}[X > k]]Heston ModelProvided that: \\begin{align} dS_t &= rS_tdt + \\sqrt{V_t}S_tdW_t^S \\text{ , and let} X = logS_t\\\\ \\text{so that } dX &= (r - 0.5V_t)dt + \\sqrt{V_t}dW_t^S \\\\ dV_t &= \\kappa(\\theta - V_t)dt + \\eta\\sqrt{V_t}dW_t^V \\end{align}Where W^S and W^V are \\mathbb{P} BM with correlation \\rho, \\kappa is the rate of mean-reversion, \\theta is the long-term mean, and \\eta is the volatility of volatility. We want to find the CF of X in order to price options on S_T. The time-t conditional Heston CF provides an answer: F_X(z) = e^{A + izX_t + BV_t}","tags":"notes"},{"title":"&#128214; Notes on MSFM - Credit Risk Model","url":"/2019/12/finm-notes/04_credit_risk_model/","text":"img.resize { max-width:50%; max-height:50%; } Standard Simulation Model on Credit PortfolioCredit RiskLenders, such as banks, are subject to many kinds of risks. among which credit risk is the most likely to cause bank failure. Credit risk Market risk Operation risk Reputation risk Each loan is part of a legal agreement that requires the borrower to pay interest and repay principle on schedule, while some borrowers are required to obey specified covenants, such as maintaining earning above a certain threshold. If the borrower fails to follow the agreement, the lender holds the borrower to be in default, which can be money default or covenant default. Purchaser of public bonds only experiences money default. At default, the loan agreement calls for fee to be paid by the borrower, gives the bank power to seize collateral (for secured loans), and has a cross default provision (where all loans are in default once one loan is in default). In the 20th century, most banks did not define default until they discovered a model that could help them manage credit risk. Rating AgenciesThere are 3 major Nationally Recognized Statistical Rating Organizations (NRSRO) to which firms pay to rate their bonds to increase liquidity. Standard &amp; Poor Moody’s Fitch Under S&amp;P ratings, the grades are: Investment grade: AAA, AA, A, BBB Non-investment grade: BB, B, CCC, CC Selectively defaulted: SD Defaulted: D D and PDLet D be the default indicator of a loan, taking only two values: 0 and 1. PD is the probability of default annually. PD = P[D = 1] = \\mathbb{E}DBy mathematical identity: Knowing PD, we can simulate D by a Bernoulli Distribution with parameter as PD. Given data on D, we can calculate the implied PD. In a portfolio of N firms, the portfolio default rate, DR, equals: DR = \\dfrac{\\sum{D}}{N} Exposure, Recovery and LGDExposure is the amount that is owed to the borrowers. Recovery is measured in either of two ways: Market price of the loan at the time of default Discounted future cash flows back to the time of default LGD (Loss Given Defaults) is a random variable with values usually between 0 and 1: LGD = 1 - \\dfrac{Recovery}{Exposure}For a defaulted loan, there are two ways to measure recovery/LGD. For a current loan, there is a distribution for LGD. The expectation is written as: \\mathbb{E}LGDUS investment grade bond LGD is about 0.20%, while non-investment grade is about 3.60%. Bank loans are almost alwasy senior to bonds and have lower LGD. Loss and ELLoss is measured as a fraction of exposure: Loss = D \\times LGDEL is the expected loss. Because D and LGD are indepndent, so: \\mathbb{E}L = \\mathbb{E}[D \\times LGD] = PD \\times \\mathbb{E}LGDLenders often need to estimate and include EL in the spread they charged. Spread = RiskFreeRate + \\mathbb{E}L Change Of VariableNote the LGD is often measured in fractions. To change the measure to dollar amount, we need to use the Chain Rule. Given the pdf of LGD: pdf_{LGD}[x]We define the function g such that: LGD^{dollar} = g(LGD) = LGD \\times ExposureHence the function g-inverse is: LGD = g^{-1}(LGD^{dollar}) = \\dfrac{1}{Exposure} \\times LGD^{dollar}The partial derivative can be expressed as: \\dfrac{\\partial g^{-1}(x)}{\\partial x} = \\dfrac{1}{Exposure} By definition: cdf_{LGD^{dollar}}[x] = P[LGD^{dollar} < x] = P[LGD < g^{-1}(x)] = cdf_{LGD}[g^{-1}(x)]Taking derivative on both sides and with chain rule: pdf_{LGD^{dollar}}[x] = pdf_{LGD}[g^{-1}(x)] \\times |\\dfrac{\\partial g^{-1}(x)}{\\partial x}|Finally: pdf_{LGD^{dollar}}[x] = pdf_{LGD}[\\dfrac{x}{Exposure}] \\times \\dfrac{1}{Exposure} Simulate Portfolio Loss On One Single LoanWe know that: Loss = D \\times LGDTo simulate loss, we first simulate D:123Draw x ~ Uniform[0, 1] If x &lt; PD, then D = 1 Else D = 0 Then simulate LGD based on the pdf of LGD. Multiple each D and LGD to get Loss. Repeat the process to produce a distribution of Loss. Simulate Portfolio Loss On N Independent LoanAssume the default of each of the N loan is independent and have the same probability of default, PD: D_{i} \\sim Bernoulli[PD]Then the total number of defaults follows binomial distribution: \\sum D_{i} \\sim Binomial(PD, N)var\\sum D_{i} = N \\times PD \\times (1-PD)However, based on historically data, the variance is much higher than that of the binomial distribution. Hence default correltion needs to be introduced. Simulate Portfolio Loss On N Correlated LoanAssume that there is a latent unobserved variable zi that is responsible for the default of firm i, i.e. firm i defaults if: z_{i} < \\Phi^{-1}(PD_{i})Assume any two firms i and j are jointly normal. Denote the correlation between zi and zj: \\rho_{i, j}Let ri, j be the correlation between asset return of firm i and j, we know that almost certainly: \\rho_{i, j} < r_{i, j}Denote PDJ as the probability that both firm i and j default: PDJ = P[D_{i} = 1, D_{j} = 1] = \\int_{-\\infty}^{\\Phi^{-1}[PD_{i}]} \\int_{-\\infty}^{\\Phi^{-1}[PD_{j}]} \\phi_{2}(z_{i}, z_{j}, \\rho_{i, j}) \\,dx\\,dyTo calculate PDJ with python:12345678910111213import numpy as npfrom scipy.stats import normfrom scipy.stats import multivariate_normalPD1, PD2 = 0.1, 0.2mean = [0, 0]cov = [[1, .5], [.5, 1]]result = multivariate_normal(mean, cov)PDJ = round(result.cdf(np.array([norm.ppf(PD1), norm.ppf(PD2)])), 4)print(\"Pr[D1=1, D2=1]:\", PDJ) Returns:1Pr[D1=1, D2=1]: 0.0515 Now that we have the Di, we can simulate portfolio loss rate, given the LGD distribution and exposures for each firm. Portfolio Loss Rate = \\dfrac{\\sum D_{i} \\times LGD_{i} \\times Exposure_{i}}{\\sum Exposure}Denote Dcorr to be the correlation between Di and Dj: Dcorr[D_{i}, D_{j}] = \\dfrac{cov[D_{i}, D_{j}]}{\\sqrt{var[D_{i}]var[D_{j}]}} \\\\\\\\ = \\dfrac{PDJ - PD_{i}PD_{j}}{\\sqrt{PD_{i}(1-PD_{i})PD_{j} (1-PD_{j})}} Note that holding PDi, PDj fixed: greater Dcorr =&gt; greater PDJ greater &rho; =&gt; greater PDJ &rho; between -1 and 1 =&gt; PDJ between 0 and min[PDi, PDj] CopulaWhen we model more than three firms, pair-wise correlation is not enough to determine the entire distribution of outcomes. For example, there are N PD’s and N(N-1)/2 pair-wise correlations while we want to calculate 2N outcomes. Hence we introduce the Gauss copula which helps describe the group-wise correlations. Consider a set of multivariate normals: (Z_1, Z_2, ..., Z_N)The quantiles of the set are uniformly distributed by definition: (\\Phi(Z_1), \\Phi(Z_2), ..., \\Phi(Z_N)) \\sim (U_1, U_2,, ..., U_3)The copula of the set (Z1, Z2, …, ZN) is defined as the joint cumulative distribution function of (&#934;(Z1), &#934;(Z2), …, &#934;(ZN)): \\mathbb{C}_{Z_i}(\\vec{x}) = cdf_{\\Phi(\\vec{Z_i})}(\\vec{x}) \\\\\\\\ = P[\\Phi(Z_1) \\leq x_1, \\Phi(Z_2) \\leq x_2, ..., \\Phi(Z_N) \\leq x_N] \\\\\\\\ = P[Z_1 \\leq \\Phi^{-1}(x_1), Z_2 \\leq \\Phi^{-1}(x_2), ..., Z_N \\leq \\Phi^{-1}(x_3)] \\\\\\\\ =cdf_{\\vec{Z_i}}(\\Phi^{-1}(\\vec{x}))The Gauss copula is as follow. Note that among all possible copula, the Central Limit Theorem defines and supports the Gauss copula: \\mathbb{C}^{Gauss}_{Z_i}(\\vec{x}) = cdf^{Gauss}_{\\vec{Z_i}}(\\Phi^{-1}(\\vec{x})) = \\Phi(\\Phi^{-1}(x_1), \\Phi^{-1}(x_2), ... , \\Phi^{-1}(x_N)) In fact, the copula does not contain any information on the marginal distribution. Here we set the marginal distribution FZ to follow standard normal only as an example, but it can be anything continuous such that: F(Z_i) \\sim U_iAnd so: \\mathbb{C}_{Z_i}(\\vec{x}) = cdf_{F(\\vec{Z_i})}(\\vec{x}) \\\\\\\\ = P[F(Z_1) \\leq x_1, F(Z_2) \\leq x_2, ..., F(Z_N) \\leq x_N] \\\\\\\\ = P[Z_1 \\leq F^{-1}(x_1), Z_2 \\leq F^{-1}(x_2), ..., Z_N \\leq F^{-1}(x_N)] \\\\\\\\ =cdf_{\\vec{Z_i}}(F^{-1}(\\vec{x})) In the context of default modeling, we assume that each company’s default follows Bernoulli and simulate with standard normal distribution: P[D_{i}=1] = P[Z_{i} Critical\\;\\; Value_{95th\\;percentile}^{df}For example when df = 1, the critical value = 3.84, we will reject the null with 95% confidence when: D > 3.84OverfitAn overfit model makes worse forecast than a simpler model. We assume the population data (X, Y) follows bivariate normal distribution: X, Y \\sim N^2(0, \\Sigma=\\begin{bmatrix}1 & \\rho \\\\\\\\ \\rho & 1\\end{bmatrix})Given &rho;, the population regression line is: \\hat{Y} = \\rho XThe sample regression line is: \\hat{Y} = bX + aFrom a sample of 30 observations of (X, Y), ordinary least square (OLS) is performed to find the in-sample p-value for the coefficient and R2. MSE is used to evaluate forecast error. When &rho; = 0.8, the sample regression line (yellow) is close to the population regression line (red): When &rho; = 0.2, the sample regression line does NOT match well. This shows that when the population has a week relationship (&rho; = 0.2), estimates of slope are more dispersed. Now we look at the relationship between statistically significance and MSE. The population Mean-Squared Error (MSE) is an out-of-sample measure of forecast errors. The population MSE does NOT depend on any in-sample data: MSE = \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} (Y - \\hat{Y})^2 \\;pdf[X, Y]\\;dXdY = 1 + a ^2 + b ^2 - 2b \\rhoWe can see that the population regression (b = &rho;, a = 0) would minimize MSE, by taking partial derivatives. We can also see that higher the &rho;, lower the MSE. \\dfrac{\\partial MSE}{\\partial a} = 0 \\rightarrow a = 0, \\; \\dfrac{\\partial MSE}{\\partial b} = 0 \\rightarrow b = \\rho A regression is significant (at 95% confidence) if the p-value for the coefficient b is less than 0.05. We have observed that when population has a weak relationship (&rho; = 0.2): Forecasts by significant regressions tend to have greater MSE. Forecasts by regressions with higher R-square tend to have greater MSE. This is because the strong relationship suggested by the regression does NOT forecast the week population relationship well. When population has a strong relation (&rho; = 0.8), however, the significant regression/high R-square holds out-of-sample. Conditional LGD RiskcLGDThe history of bond LGD shows that LGD is elevated when default rate is elevated. The elevation is shown to be moderate and similar across different debt types: DR \\uparrow \\;\\;\\rightarrow LGD \\uparrowIt is important to model LGD appropriately in different economic conditions. Like cDR, we define cLGD: Loss = D \\times LGD\\\\\\\\ \\mathbb{E}L = PD \\times \\mathbb{E}LGD\\\\\\\\ cLoss = cDR \\times cLGDNote that: \\mathbb{E}cDR = PD\\\\\\\\ \\mathbb{E}cLoss = \\mathbb{E}L\\\\\\\\ however, \\mathbb{E}cLGD \\neq \\mathbb{E}LGDThere are two ways to calculate ELGD: \\mathbb{E}LGD = \\dfrac{\\mathbb{E}L}{PD} = \\mathbb{E} \\dfrac{cDR \\times cLGD}{PD}Futhermore, \\mathbb{E}cLGD < \\mathbb{E}LGDWhere: EcLGD is the average LGD over conditions ELGD is the average LGD over different loans ELGD is higher than EcLGD because when cLGD is higher, cDR/PD is also higher, which increase the probability weight on the higher cLGDs, while in EcLGD, higher cLGD does not have higher weight. Frye-JacobsModeling cLGD separately from cDR introduces complexity and potential overfit to the cLoss model. Instead, the Frye-Jacobs LGD function assumes that both cDR and cLoss follow Vasicek distribution, and infers cLGD as a function of cDR. Frey-Jacobs assumptions: cDR and cLoss are comonotonic. If cDR goes up, cLoss must go up. If cDR is in its qth quantile, then cLoss must also be in its qth quantile. This implies that there is a cLGD function of cDR: cLGD[cDR] = \\dfrac{F^{-1}_{cLoss}[F_{cDR}\\;[cDR]\\;]}{cDR} cDR follows Vasicek distribution, which stems from the simplest portfolio structure: Large number of Firms Each firm same PD Each pair-wise &rho; the same (same PDJ) Gauss copulas cDR \\sim Vasicek [PD, \\rho] Distribution of cLoss does NOT depend of the definition of default. \\times This implies the distribution of cLoss does not have separate parameters for PD and ELGD. It does have a parameter EL. cLoss follows Vasicek distribution cLoss \\sim Vasicek [PD, \\rho] cLoss and cDR have the same &rho; parameter. \\times This ensure that the LGD function is monotonic Finally, cLGD[cDR] = \\dfrac{\\Phi[\\Phi^{-1}[cDR] - k]}{cDR}, where \\;\\; k = \\dfrac{\\Phi^{-1}[PD] - \\Phi^{-1}[\\mathbb{E}L]}{\\sqrt{1-\\rho}}]Observations: cLGD is strictly monotonic with range (0, 1), for all k \\dfrac{\\partial LGD[DR]}{\\partial DR} > 0, \\forall\\; k cLGD increases slowly, and similarly for all k, at low cDR Elasticity is greatest for loans wth low LGD. Elasticity = \\dfrac{\\dfrac{\\partial LGD[DR]}{\\partial DR}}{\\dfrac{LGD[DR]}{DR}}Frye-Jacobs: Develop Alternative HypothesisIntroduce an additional sensitivity parameter to test the slope of the LGD function. We know that: \\mathbb{E}L = \\mathbb{E}[cDR \\times cLGD[cDR]]In integration form: \\mathbb{E}L = \\int_0^1 x \\times cLGD[x] \\times pdf_{cDR}[x, PD, \\rho] \\;dxBring in the Frye-Jacobs cLGD function: \\mathbb{E}L = \\int_0^1 \\Phi[\\Phi^{-1}[x] - \\dfrac{\\Phi^{-1}[PD] - \\Phi^{-1}[\\mathbb{E}L]}{\\sqrt{1-\\rho}}] \\times pdf_{cDR}[x, PD, \\rho] \\;dxNote that EL is in both lhs and rhs, divide both EL by ELGDa: \\mathbb{E}L = \\int_0^1 \\mathbb{E}LGD^a \\Phi[\\Phi^{-1}[x] - \\dfrac{\\Phi^{-1}[PD] - \\Phi^{-1}[\\dfrac{\\mathbb{E}L}{\\mathbb{E}LGD^a}]}{\\sqrt{1-\\rho}}] \\times pdf_{cDR}[x, PD, \\rho] \\;dxNote that we have identified a new LGD function: cLGD[cDR] = \\dfrac{\\mathbb{E}LGD^a \\Phi[\\Phi^{-1}[cDR] - \\dfrac{\\Phi^{-1}[PD] - \\Phi^{-1}[\\dfrac{\\mathbb{E}L}{\\mathbb{E}LGD^a}]}{\\sqrt{1-\\rho}}]}{cDR}Analyzing the choice of a: When a = 0, the cLGD function is the Frye-Jacob formula. When a = 1, cLGD = ELGD, which implies cLGD does not depend on conditions: cLGD[cDR] = \\mathbb{E}LGDFrye-Jacobs: Hypothesis TestWe introduce finite portfolio, which brings randomness into the D’s and LGD^{dollar}s. We assume the finite portfolio is uniform and all N loans have the same PD and &rho; We assume that given portfolio cDR, the number of defaults is binomial: \\sum D \\sim Binomial (cDR, N) We assume that LGD is normally distributed around cLGD, with &sigma; = 0.2. Note under this assumption, ELGD = cLGD which correspond with a = 1. LGD \\sim N(cLGD [cDR], \\sigma^2)Under finite portfolio, the probability of 0 defaults is: P[\\sum D = 0] = \\int_0^1 (1-x)^N pdf_{cDR}[x] \\;dxWhen conditional on cDR and &Sigma; D &gt; 0, the average portfolio LGD rate is normal: LGD_{portfolio} \\sim N(cLGD [cDR], \\dfrac{\\sigma^2}{\\sum D})Let Y ~ N(0, 1) be a standard normal variable, then LGD becomes: LGD = cLGD[cDR] + \\dfrac{\\sigma}{\\sqrt{\\sum D}}YNow calculate Loss based on DR and LGD: Loss = \\dfrac{\\sum D}{N} \\times LGD = \\dfrac{cLGD[cDR]\\sum D + \\sigma Y\\sqrt{\\sum D}}{N}Use change-of-variable technique to calculate the pdf for Loss: pdf_{Loss}[x] = pdf_Y[g^{-1}(x)] \\times |\\dfrac{\\partial g^{-1}(x)}{\\partial x}|Where: g^{-1}(Loss) = Y = \\dfrac{N Loss + cLGD[cDR]\\sum D}{\\sigma\\sqrt{\\sum D}} \\\\\\\\ |\\dfrac{\\partial g^{-1}(x)}{\\partial x}| = \\dfrac{N}{\\sigma\\sqrt{\\sum D}}Finally, the pdf of loss conditional on &Sigma; D and cDR: pdf_{Loss | \\sum D, cDR}[x] = \\dfrac{N}{\\sigma\\sqrt{\\sum D}} \\phi[\\dfrac{N x + cLGD[cDR]\\sum D}{\\sigma\\sqrt{\\sum D}}]Removing the conditional, the distribution of loss in a uniform portfolio, with N loans, same PD and &rho; and the cLGD function, becomes: pdf_{Loss}[x] = \\int \\sum_{\\sum D = 1}^{N} pdf_{Loss | \\sum D, cDR}[x] \\times pmf_{\\sum D | cDR}[\\sum D] \\times pdf_{cDR}[cDR] \\;dcDR \\\\\\\\ where\\;\\; pmf_{\\sum D | cDR}[\\sum D] = \\binom{N}{\\sum D}cDR^{\\sum D}(1-cDR)^{N-\\sum D}Here is a plot of the the unconditional loss density in a finite (N = 10) portfolio in red and loss density in an infinite portfolio (Vasicek) in blue. (note that the plot use D to denote &Sigma; D): Now we have the pdf for loss, we an test the hypothesis: H0: a = 0 H1: a = MLE Based On Moody’s Loss data As a result MLE(a) = 0.01 based on all loan data and the test failed to reject the null. Same with other bonds and bonds/loans data combination. We conclude that the Fyre-Jacob model is consistent with Moody’s data Vender EstimationDistance-To-Default and EDFRobert Merton argues that: the default of firm i depends on its asset return Merton asserts that a firm defaults if and only if the value of its asset drops below the value of its liability, i.e. its asset return is too low joint default of firm i and j depends on PD and asset return correlation Moody’s suggests that loan contains the option to default, and attempts to use risk-neutral probability to estimate the probability of default. In the context of a put: \\mathbb{P}[S_T < K ] = \\Phi(-d_2) = \\Phi(-\\dfrac{\\log{\\dfrac{S_T}{K}} + (r-\\dfrac{\\sigma^2}{2})T}{\\sigma \\sqrt{T}})Under Moody’s assumption, the firm has an option to default on its assets once it drops below its liability. Here, liability is the strike price, for which Moody’s uses D, or “default point”, to denote short term debt plus half of long term debt to represent liability. DD stands for Distance-To-Default, suggested by Merton. So the probability of default is: \\mathbb{P}[Asset < D] = \\Phi(-DD) = \\Phi(-\\dfrac{\\log{\\dfrac{Asset}{D}}}{AnnualVolatilityOfAssets})Moody’s then estimates the value and volatility of the assets (unobservable) based on the value and volatility of the market capitalization (observable). However, since &Phi;(-DD) gave very poor estimate for the default probability, Moody’s sets the EDF(Estimated Default Frequency) of a firm equal to the average historical default rate of firms with the same Distance-To-Default. An EDF uses DD to find historical analogs of current firms. CorrelationMerton assumes that the correlation &rho; between the latent variable Z’s is equal to the asset return correlation r. However, data suggests that correlation estimated from credit data is less than the correlation based on asset returns. Hence a credit portfolio model that uses asset correlation to estimate &rho; overstates credit risk.","tags":"notes"},{"title":"&#128214; Notes on MSFM","url":"/2019/12/finm-notes/","text":"01. Portfolio Theory02. Option Theory03. Stochastic Calculus04. Credit Risk Model05. Foreign Exchange06. C++","tags":"notes"},{"title":"&#128214; Notes on MSFM - Portfolio Theory","url":"/2019/12/finm-notes/01_portfolio_theory/","text":"img.resize { max-width:50%; max-height:50%; } Portfolio DiversificationTwo-Asset PortfolioConsider an investment portfolio V on two assets: P = wB + (1-w)SWe can calculate the mean and variance of the return on the portfolio, based on the mean and variance of the return on each asset. \\begin{align} \\mu_p &= w\\mu_b + (1-w)\\mu_s \\\\ \\sigma^2_p &= w^2\\sigma^2_b + (1-w)^2\\sigma^2_s + 2w(1-w)\\rho\\sigma_s\\sigma_b \\end{align}We can see that if \\rho","tags":"notes"},{"title":"&#128214; Notes on MSFM - C++","url":"/2019/12/finm-notes/06_c_plus_plus/","text":"img.resize { max-width:50%; max-height:50%; } C++ is a complied （vs interpreted: python), general-purpose (vs domain-specific: HTML) programming language created by Danish programmer Bjarne Stroustrup as an extension to C. BasicCompilerA compiler translate a high level language into a low level language and create an executable program. Pre-processor: read preprocessing lines #include &quot;foo.hpp&quot; Compiler: turn the above code it into assembly code (ASM). front end create IR (intermediate representation) with SSA (static singale assignment). The runtime is O(n). middle end optimize IR. remove unnecessary operations, O(n^2) or more. back end produce ASM Assembler: turn ASM into binary code Linker: link all relevant headers, libraries together Debugger: type checking Object Copy: generate .exe (for windows), and .bin (for mac) G++Compile with g++ at the command line:123$ g++ toto.cpp$ g++ toto.cpp -E (show c pre-processor)$ g++ toto.cpp --verbose (ask compile to give different steps) Running the complied result:1$ /a.exe HeaderThe C++ standard library is a collection of classes and functions, represented by different headers. For example, include the &lt;iostream&gt; header to handle input and outputs and other non-standard headers using double quoto.12#include &lt;iostream&gt;#include \"foo.h\" Macro12define N 4std::cout &lt;&lt; N + 2; // show 6 GuardsIn C++, function, class and variable can only be declared once. We use guards to make sure we do not duplicate declaration in multiple files.12#ifndef &quot;foo.h&quot;#define &quot;foo.h&quot; NamespaceSome classes and functions are grouped under the same name, which divides the global scope into sub-scopes, each with its own namespaces. Functions and classes in the C++ standard library are defined in the std namespace. For example, the cin (standard input), cout (standard output) and end (end line) objects.1234char c;std::cin &gt;&gt; c;std::cout &lt;&lt; c;std::endl; Alternatively, we can use using namespace std;. Data TypeEvery variable has to have a type in C++, and the type has to be declared and cannot be changed. There are fundamental types and user-defined types (classes) Characters In computer, each bit stores a binary (0/1) value. A byte is 8 bits. The computer stores characters in a byte using the ASCII format. Numbers The computer stores numbers in binary format with bits. The leftmost bit is used to store the sign of a number. (See twos-complement method). Real values are stored using a mantissa and an exponent: Value = Mantissa \\times 2^{Exponent}Note that very few values can be exactly represented, and how close we can get depends on the number of bits available. Type Size (Bytes) Value Range bool 1 true or false char 1 -128 to 127 short 2 -32,768 to 32,767 int 4 -2,147,483,648 to 2,147,483,647 float 4 3.4E +/- 38 double 8 1.7E +/- 308 C++ is a strongly typed language, which means type errors needs to be resolved for all variables at compile time. FunctionEvery console application has to have a main() function, which takes no argument and returns an integer value by default. A function that adds two numbers:12345678910111213#include &lt;iostream&gt;using namespace std;int Add(int a, int b)&#123; return a+b;&#125;int main()&#123; int result = Add(2, 3); cout &lt;&lt; \" Result: \" &lt;&lt; result &lt;&lt; endl;&#125; Overloading allows 2 or more functions to have the same name, but they must have different input argument types. Function ObjectFunction object, or functors, are objects that behave like functions, are functions with state. A regular function looks like this:12345int AddOne(int val)&#123; return val+1;&#125;int result = AddOne(2) A function object implementaion:123456789101112class AddOne&#123;public: int operator()(int&amp; val) &#123; return val+1; &#125;&#125;;AddOne addone;int val = 2;int result = addone(val) LambdaLambdas is a new feature introduced in C++11, which is an inline function that can be used as a parameter or local object.1234[] (string s) // [] is the lambda introducer/capture clause&#123; cout &lt;&lt; s &lt;&lt; endl;&#125; Example 1123vector&lt;int&gt; v&#123;1, 3, 2, 4, 6&#125;;for_each(v.cbegin(), v.cend(), //range [](int elem) &#123;cout &lt;&lt; elem &lt;&lt; endl;&#125;) //lambda Example 2123vector&lt;int&gt; v&#123;1, 3, 2, 4, 6&#125;;transform(v.begin(), v.end(), v.begin(), [] (int elem) &#123;return elem * elem&#125;); Example 31234567vector&lt;Person&gt; ppl;sort(ppl.begin(), ppl.end(), [](const Person&amp; p1, const Person&amp;p2) &#123; if (p1.GetAge() &lt; p2.GetAge()) return true; else return false; &#125;); ExternThe keyword extern means the function is declared in another file.12extern int foo(int a);int main() &#123; return foo(100); &#125; Inline FunctionC++ provides inline funcitons such that the overhead of a small function can be reduced. When inline function is called the entire code of the function is inserted at the point of the inline function call. TypedefUse typedef keyword to define a type alias.1234typedef double OptionPrice;typedef double StockPrice;typedef double Strike;OptionPrice BSPrice(StockPrice S, Strike K) OperatorsStandard operations:123456789Arithmetic: +, -, *, /Comparison: &lt;, &gt;, &lt;=, &gt;=Negate: !Equality, non Equality: ==, !=Logical and, or, &amp;&amp;, ||Assignment: =Modulo: %Increment, Decrement: i++, i--Multiple Operations: i += 1, i -= 1, i *= 1, i /= 1 Note the difference between i++ and ++i12i++; // return (old) i and increment i++i; // increment i and return new i ConstUse the const keyword to define a constant value. The compiler will stop any attempt to alter the constant values. Since C++ is a strongly typed language, it is preferred to use const int N = 4, instead of #define N 4, as the former defines a type. ReferenceExample 1 A reference is an alias for a variable and cannot rebind to a different variable. We can change val by changing ref:123int val = 10;int&amp; ref = val;ref = 20; // this will change val to 20 Example 2 We can also bind a const reference to a const object. An error will be raised if attempt to change the value or the reference.1234const int val = 10;const int&amp; ref = val;val = 20; // errorref = 20; // error Example 3 We can also bind a const reference to a non-const object, thereafter we can NOT change the object using the reference.1234int val = 10;const int&amp; ref = val;val = 20; // okref = 20; // error Pass By Value In a function, we can pass an argument by either value or reference. When passing by value, the variable x will NOT be changed. In this case, we waste time to both create a copy inside the function and memory to store the copy1234567891011void DoubleValue(int number)&#123; number = number * 2;&#125;int main()&#123; int x = 5; DoubleValue(x); cout&lt;&lt;\"x = \"&lt;&lt;x&lt;&lt;endl;&#125; 1x = 5 Pass By Reference When passing by reference (by adding &amp; in the function argument parameter), the variable x WILL be changed.1234567891011void DoubleValue(int&amp; number)&#123; number = number * 2;&#125;int main()&#123; int x = 5; DoubleValue(x); cout&lt;&lt;\"x = \"&lt;&lt;x&lt;&lt;endl;&#125; 1x = 10 Pass By Const Reference We add const when we do not want the specific function argument to be tempered when passed by reference. In this example, there will be a compiler error as we are trying to change the const reference number in the function.1234567891011void DoubleValue(const int&amp; number)&#123; number = number * 2; // error, cannot change const ref \"number\"&#125;int main()&#123; int x = 5; DoubleValue(x); cout&lt;&lt;\"x = \"&lt;&lt;x&lt;&lt;endl;&#125; PointerIn computer memory, each stored values has an address associated with it. We use a pointer object to store address of another object and access it indirectly. There are two pointer operator: &amp;: address of operator, used to get the address of an object *: de-reference operator, used to access the object Example 1123int* ptr = nullptr; // initiate an empty pointerint* ptr = &amp;val; // initiate ptr with the address of val*ptr = 20; // change val using the ptr pointer Example 2 If the object is const, a pointer cannot be used to change it.123const int val = 10;const int* ptr = &amp;val;*ptr = 20; // error Example 3 You can have a pointer that itself is const123456int val = 10;int* const ptr = &amp;val;*ptr = 20; // okint val2 = 20;ptr = &amp;val2 // error, as the pointer is const CastingC++ allows implicit and explicit conversions of types.1234short a = 1;int b;b = a; // implicit conversionb = (int) a; // explicit conversion However, the traditional explicit type-casting allows conversions between any types, and leads to run-time error. To control these conversions, we introduce four specific casting operators: dynamic_cast&lt;new_type&gt;( ): used only with pointers (and/or references to objects); can cast a derived class to its base class; base-to-derived conversions are allowed only with polymorphic base class 1234567891011121314151617181920class Base &#123;virtual void foo() &#123;&#125; &#125;;class Derived : public Base &#123; &#125;;int main() &#123; Derived* derived_ptr; Base* base_ptr = dynamic_cast&lt;Base*&gt; (derived_ptr); Base* base_ptr_2 = new Derived; Derived* derived_ptr_2 = dynamic_cast&lt;Derived*&gt; (base_ptr_2); // ok, base class polymorphic Base* base_ptr_3 = new Base; Derived* derived_ptr_3 = dynamic_cast&lt;Derived*&gt; (base_ptr_3); // will not work, derived_ptr_3 will be assigned a nullptr std::cout &lt;&lt; \"derived_ptr_2: \" &lt;&lt; derived_ptr_2 &lt;&lt; std::endl; std::cout &lt;&lt; \"derived_ptr_3: \" &lt;&lt; derived_ptr_3 &lt;&lt; std::endl; return 0;&#125; 12derived_ptr_2: 0x7fa5cec00630derived_ptr_3: 0x0 static_cast &lt; new_type&gt;( ): used only with pointers (and/or references to objects); can cast base-to-derived or derived-to-base, but no safety check at run-time; 123Base* base_ptr_3 = new Base;Derived* derived_ptr_3 = static_cast&lt;Derived*&gt; (base_ptr_3);// not nullptr this time, but lead to error when de-referencing derived_ptr_3 1derived_ptr_3: 0x7fc3d7400690 reinterpret_cast &lt;new_type&gt;( ): convert pointer to another unrelated class; often lead to unsafe de-referencing 12345class A &#123;&#125;;class B &#123;&#125;;A* a = new A;B* b = reinterpret_cast&lt;B*&gt; (a); const_cast &lt;new_type&gt;( ): remove/set the constant-ness of an object Array (C-Style)An array is a fixed collection of similar kinds of items that are stored in a contiguous block in memory. We define the size of the array at creation, and the array index starts a 0 in C++.12int a[10];int a[] &#123;1, 2, 3&#125; // uniform initializer syntax The address of the array is the same as the address of the first element of the array. Therefore, we can access an array using pointer increment - very efficient.1234int a[10];int* ptr = &amp;a[0]; // the same as int* ptr = aint a0 = a[0]; // the same as int a0 = *ptrint a3 = a[3]; // the same as int a3 = *(ptr+3) or *(a+3) Dynamic AllocationDynamic memory allocation is necessary when you do NOT know the size of the array at compile time. We use a new keyword paired with a delete keyword.123int* a = new int[10];delete[] = a; // correct. this tells the CPU that it needs to clean up multiple variables instead of a single variabledelete a; // incorrect. using this version will lead to a memory leak. Dynamic allocate a 4\\times4 matrix with cast.1234567891011121314151617181920212223#include &lt;iostream&gt;void func(double** a) &#123; * a = new double[16];&#125;int main() &#123; int (* a)[4]; func( (double**)&amp;a ); for (int i=0; i&lt;4; i++) &#123; for (int j=0; j&lt;4; j++) &#123; a[i][j] = 1; &#125; &#125; for (int i=0; i&lt;4; i++) &#123; for (int j=0; j&lt;4; j++) &#123; std::cout &lt;&lt; a[i][j] &lt;&lt; \" \" ; &#125; std::cout &lt;&lt; std::endl; &#125;&#125; 123451 1 1 11 1 1 11 1 1 11 1 1 1` LibraryA C++ library is a package of reusable code typically with these two components: header file precompiled binary containing the machine code for functionality implemntation There are two types of c++ libraries: static and dynamic libraries. a static library has a .a (.lib on Windows) extension and the library codes are complied as part of the executable - so that user only need to distribute the executable for other users to run the file with a static library. a dynamic library has a .so (.dll on Windows) extension and is loaded at run times. It saves space as many program can share a copy of dynamic library code, and it can be upgraded to new versions without replacing all the executables using it. ConditionIf/Else123456789101112if (condition_1)&#123; statement1;&#125;else if (condition_2)&#123; statement2;&#125;else&#123; statement2;&#125; SwitchA switch statement tests an integral or enum value against a set of constants. we can NOT use a string in the switch statement.12345678910111213141516int main()&#123; int value = 0; cin &gt;&gt; value; switch(value) &#123; case 0: cout &lt;&lt; \"value is zero\"; break; // if remove this break, it will also show case 1 even if value is 0 case 1: cout &lt;&lt; \"value is one\"; break; default: cout &lt;&lt; \"value is not 0 or 1\"; &#125;&#125; While / Do While / For LoopWhile loop:123456int n = 0;while (n &lt; 10)&#123; cout &lt;&lt; \" n: \" &lt;&lt; n &lt;&lt; endl; n = n + 1;&#125; Do while loop:123456do &#123; cout &lt;&lt; \"Enter number (0 to end): \"; cin &gt;&gt; n; cout &lt;&lt; \"You entered: \" &lt;&lt; n &lt;&lt; \"\\n\"; &#125; while (n != 0); For loop:1234for (unsigned int n = 0; n &lt; 10; ++n)&#123; cout &lt;&lt; \"n: \" &lt;&lt; n &lt;&lt; endl;&#125; For loop with two variables:1234for (unsigned int i = 0, j = 0; i &lt; 10 &amp;&amp; j &lt; 10; ++i, j+=2)&#123; cout &lt;&lt; \"i:\" &lt;&lt; i &lt;&lt; \", j:\" &lt;&lt; j &lt;&lt; endl;&#125; EnumThe enum (enumerated) type is used to define collections of named integar constants.1234567enum CurrencyType &#123;USD, EUR, GBP&#125;;cout &lt;&lt; USD &lt;&lt; \" \" &lt;&lt; EUR &lt;&lt; \" \" &lt;&lt; GBP;0 1 2enum CurrencyType &#123;USD, EUR=10, GBP&#125;;cout &lt;&lt; USD &lt;&lt; \" \" &lt;&lt; EUR &lt;&lt; \" \" &lt;&lt; GBP;0 10 11 ClassA class achieve data abstraction and encapsulation. abstraction refers to the separation of interface and implementation encapsulation refers to combining data and functions so that data is only accessible through functions. Member Variable &amp; FunctionDefine a customer class with member variable and function.123456789101112131415class Customer&#123;public: Customer(); // default constructor Customer(string name, string address); ~Customer(); // destructor, to free up resources string GetName(); string GetAddress(); void SetAddress(string address);private: string name_; string address_;&#125;; Instantiate Customer class instances to represent different customer.1234567Customer c1(\"Joe\", \"Hyde Park\");Customer c2(\"Jim\", \"Chicago\");Customer c3(\"John\", \"New York\");// Use `.` to access member function.c1.GetName()c2.SetAddress(\"Beijing\") Protection LevelThere are three protection levels to keep class data member internal to the class. public accessible to all. protected accessible in the class that defines them and in classes that inherit from that class. private only accessible within the class defining them. Constructor / DestructorA constructor is a special member functions used to initialize the data members when an object is created. This is an example to use initializer list to create more efficient constructors123456789101112131415Customer::Customer() : name_(\"\"), address_(\"\")&#123; // name_ = \"\"; // address_ = \"\";&#125;Customer::Customer(string name, string address) : name_(name), address_(address)&#123;&#125;Customer::~Customer()&#123;&#125; Free-StoreThere are several ways to create objects on a computer: Automatic/Stack int a; Dynamic Allocated Free Store int* ptr = new a[10]; Heap allocated/freed by malloc/free Summarized in a table from geeksforgeeks Parameter Stack Heap Basic Memory is allocated in a contiguous block Memory is allocated in any random order Allocated and de-allocation Automatic by compiler instructions Manual by programmer Cost Less More Access time Faster Slower Main issue Shortage of memory Memory leak/fragmentation We use -&gt; to access free-store object’s member functions:123Customer* c = new Customer(\"Joe\", \"Chicago\");c-&gt;GetName()c-&gt;SetAddress(\"New York\") Const Member FunctionsA const object can only invoke const member function on the class. A const member function is not allowed to modify any of the data members on the object on which it is invoked. However, if a data member is marked mutable, it then can be modified inside a const member function.12const Customer c1(\"Joe\", \"Hyde Park\");cout &lt;&lt; c1.GetName(); // ok if GetName() is a const member function. Static MemberWe use static keyword to associate a member with the class, as oppose to class instances. A static data member can NOT be accessed directly using a non-static member function. Static member variables can NOT be initialized through the class constructor, rather, they are initialized once outside the class body. However, a const static member variable can be initialized within the class body.123456789101112131415class Counter&#123;public: Counter(); static int GetCount(); static void Increment();private: static int count_; // non-const static need to be initialized outside const static int count_2_ = 0; // const static can be initialized within&#125;;int Counter::count_ = 0;Counter c;c.Increment(); // or Counter::Increment() ThisEvery non-static member function has access to a this pointer, which is initialized with the address of the object when the member function is invoked.123456double Currency::GetExchangeRate()&#123; return exchangeRate_; return this-&gt;exchangeRate_; // equivalent return (*this).exchangeRate_; // equivalent&#125; Copy ConstructorWe use the copy constructor to construct an object from another already constructed object of the same type.1234567891011class Customer&#123; Customer(const Customer&amp; other);&#125;;Customer::Customer(const Customer&amp; other) : name_(other.name_) address_(other.address_)&#123;&#125;Customer c2(c1); Assignment OperatorWe use the assignment operator to assign an object of the same type.123456789101112131415class Customer&#123; Customer&amp; operator=(const Customer&amp; other);&#125;;Customer&amp; Customer::operator=(const Customer&amp; other)&#123; if (this != &amp;other) //checking for self assignment &#123; name_ = other.name_; address_ = other.address_; &#125; //return the object on which the function was invoked return (*this);&#125; Shallow / Deep CopyThe default copy constructor and assignment operator provides shallow copy, which copies each member of the class individually. For pointer member, the shallow copying copies the address of the pointer, resulting in both members pointing to the same object on the free store. A deep copy, however, creates a new object on the free store and copy the contents of the object the original pointer is pointing to. Deep Copy copy constructor123456Customer::Customer(const Customer&amp; other) :name_(other.name_), address_(other.address_), account_(new Account(other.account_-&gt;GetAccountNumber(), other.account_-&gt;GetAccountBalance()))&#123;&#125; Deep Copy assignment operator123456789101112Customer&amp; Customer::operator=(const Customer&amp; other)&#123; if (this != &amp;other) &#123; name_ = other.name_; address_ = other.address_; delete account_; account_= new Account(other.account_-&gt;GetAccountNumber(), other.account_-&gt;GetAccountBalance()); &#125; return (*this);&#125; The Rule of 3There are 3 operations that control the copies of an object: copy constructor, assignment operator, and destructor. If you define one of them, you will most likely need to define the other two as well. Singleten ClassThe Singleton design pattern makes sure only one instance of an object of a given type is instantiated in a program, and provides a global point of access to it change the access level of the constructor to private add new public member function Instance() to create the object use static member variable to hold the object 12345678910class CurrencyFactory&#123;public: static CurrencyFactory* Instance(); Currency CreateCurrency(int currencyType);private: CurrencyFactory(); static CurrencyFactory* instance_;&#125;; 1234567891011121314151617181920212223CurrencyFactory* CurrencyFactory::Instance()&#123; if (!instance_) instance_ = new CurrencyFactory; return instance_; // no more than one CurrencyFactory object.&#125;Currency CurrencyFactory::CreateCurrency(int currencyType)&#123; switch(currencyType) &#123; case EUR: return Currency(\"EUR\", 0.7901); case GBP: return Currency(\"GBP\", 0.6201); case CAD: return Currency(\"CAD\", 1.1150); case AUD: return Currency(\"AUD\", 1.1378); default: return Currency(\"USD\", 1.0); &#125;&#125; 123456789101112131415#include \"CurrencyFactory.h\"int main()&#123; cout &lt;&lt; \"Enter amount in USD:\"; double amount; cin &gt;&gt; amount; cout &lt;&lt; \"Enter currency to convert to (ECU/GBP/CHF/JPY): \"; string symbol; cin &gt;&gt; symbol; double convertedAmount = 0.0; Currency currency = CurrencyFactory::Instance()-&gt;CreateCurrency(symbol); cout &lt;&lt; currency.ConvertFromUSD(amount) &lt;&lt; endl;&#125; InheritanceClasses related by inheritance form a hierachy consisting of base and derived classes. The derived class inherit some members from the base class subject to protection level restrictions, and may extend/override implementation of member functions in the base class.12345678910class Person&#123;protected: string name_; string address_;&#125;;class Student : public Person&#123; string school_;&#125;; VirtualDifferent derived classes may inplement member functions from the base class differently. The base class uses virtual keyword to indicate a member function that may be specialized by derived classes.12345678910111213class Base&#123;public: virtual void Method1(); virtual void Method2(); void Method3();&#125;;class Derived : public Base&#123; void Method1(); // specializes Method1() // uses default implementation of Method2() // can NOT specialize Method3()&#125;; Abstract ClassThe base class has to either provide a default implementation for that function or declare it pure virtual. If a class has one or more pure virtual function, it is called an abstract class or interface. An abstract class cannot be instantiated.123456789class Base&#123;public: virtual void Method1() = 0;&#125;;class Derived : public Base&#123; // this derived is also an abstract&#125;; Virtual DestructorWhen we delete a derived class we should execute both the derived class destructor and the base class destructor. A virtual base class destructor is needed to make sure the destructors are called properly when a derived class object is deleted through a pointer to a base class. If we delete a derived class object through a pointer to a base class when the base class destructor is non-virtual, the result is undefined. PolymorphismThe types related by inheritance are known as polymorphic. types. We can use polymorphic types interchangeably. We can use a pointer or a reference to a base class object to point to an object of a derived class – this is known as the Liskov Substitution Principle (LSP). This allows us to write code without needing to know the dynamic type of an object 12345BankAccount* acc1 = new Savings();acc1-&gt;ApplyInterest(); // ApplyInterest() on the Savings objectBankAccount* acc2 = new Checking();acc2-&gt;ApplyInterest(); // ApplyInterest() on the Checking object We can write one function which applies to all account types.12345void UpdateAccount(BankAccount* acc)&#123; acc-&gt;ApplyBankingFees(); acc-&gt;ApplyInterest();&#125; 12345void UpdateAccount(BankAccount&amp; acc)&#123; acc.ApplyBankingFees(); acc.ApplyInterest();&#125; Standard Template Library (STL)Sequential Containerstd::arrayThe STL array class from offers a more efficient and reliable alternative for C-style arrays, where size is known and we do not have to pass size of array as separate parameter.12345678#include &lt;array&gt;array &lt;int&gt; a1 = &#123;1, 2, 3&#125;;a1.front();a1.back();a1.size();a1.at(1);get&lt;1&gt;(a1); std::vectorVectors are the stored contiguously same as dynamic arrays with the ability to resize itself automatically when an element is inserted or deleted. Vector size is double whenever half is reached.12345678910111213#include &lt;vector&gt;vector&lt;int&gt; v1;v1.begin();v1.end();v1.size();v1.push_back(); // pushes the elements into a vector from the backv1.pop_back(); // removes the elements from a vector from the back.v1.insert(i); // inserts new elements before the element at the specified positionv1.assign(i); // assigns new value to the vector elements by replacing old onesv1.erase(i); // removes elements from a container from the specified position or range std::listDifferent from arrays and vectors, A list is a sequential container that allows non-contiguous memory allocation.123456789101112131415#include &lt;list&gt;list&lt;int&gt; l1;for (int i = 0; i &lt; 10; i++) &#123; l1.front(); // returns the value of the first element l1.back(); // returns the value of the last element l1.push_front(i); // adds a new element ‘i’ at the beginning of the list l1.push_back(i); // adds a new element ‘i’ at the back of the list l1.pop_front(); // removes the first element and reduces list size by 1 l1.pop_back(); // removes the last element and reduces list size by 1 l1.begin(); // returns an iterator pointing to the first element of the list l1.end(); // returns an iterator pointing to the last element of the list &#125; std::stringThe STL string class stores the characters as a sequence of bytes, allowing access to single byte character. Any string is terminated by a \\0, so the string foo actually stores four characters. size()The use sizeof() to return the size of an array in bytes. Use .size() member function to return the number of elements in a STL container.1234567891011121314#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() &#123; int a[5] &#123;1, 2, 3, 4, 5&#125;; cout &lt;&lt; \"The size of a: \" &lt;&lt; sizeof(a) &lt;&lt; \" bytes\" &lt;&lt; endl; vector&lt;int&gt; b &#123;1, 2, 3, 4, 5&#125;; cout &lt;&lt; \"The size of b: \" &lt;&lt; sizeof(b) &lt;&lt; \" bytes\" &lt;&lt; endl; cout &lt;&lt; \"The size of b: \" &lt;&lt; b.size() &lt;&lt; \" elements\" &lt;&lt; endl;&#125; 123The size of a: 20 bytesThe size of b: 24 bytesThe size of b: 5 elements Associative Containerstd::setSets are an associative container where each element is unique. The value of the element cannot be modified once it is added to the set.1234567891011#include &lt;set&gt;set&lt;int&gt; s1;for (int i = 0; i &lt; 10; i++) &#123; s1.begin(); s1.end(); s1.size(); s1.insert(i); s1.erase(i); s1.find(i);&#125; std::mapA std::map sorts its elements by the keys. AlgorithmThe STL provides implementations of some widely used algorithms. &lt;algorithms&gt; header: sorting, searching, copying, modifying elements &lt;numeric&gt; header: numeric operation Sort123456int main()&#123; vector&lt;int&gt; values&#123;10, 1, 22, 12, 2, 7&#125;; //sort takes a range sort(values.begin(), values.end());&#125; Binary Search123456int main()&#123; vector&lt;int&gt; values&#123;10, 1, 22, 12, 2, 7&#125;; //binary_search takes a range and a value bool found = binary_search(values.begin(), values.end(), 12);&#125; Copy12345678int main()&#123; vector&lt;int&gt; values1&#123; 10, 1, 22, 12, 2, 7 &#125;; //destination vector &lt;int&gt; values2; copy(values1.begin(), values1.end(), //input range back_inserter(values2)); //output iterator&#125; Replace1234567int main()&#123; vector&lt;int&gt; values&#123; 10, 1, 22, 12, 2, 7 &#125;; replace(values.begin(), values.end(), //range 1, //old value 111); //new value&#125; Numeric123456789int main()&#123; vector&lt;int&gt; v2&#123; 5, 4, 3, 2, 1 &#125;; vector&lt;int&gt; v2&#123; 1, 2, 3, 4, 5 &#125;; int r1 = accumulate(v1.begin(), v1.end(), 0); //range int r2 = inner_product(v1.begin(), v1.end(), v2.begin(), 0);&#125; Complexity Comparison Smart Pointerstd::unique_ptrA unique pointer takes unique ownership in its pointed object. The unique pointer delete the object they managed either when the unique pointer is destroyed or when the object’s value changes. 12345678910111213#include &lt;memory&gt;std::unique_ptr&lt;Option&gt; sp(new Option());// initates a smart pointer (or through reset: sp.resert(Option()).)std::unique_ptr&lt;Option&gt; sp2(sp);// error: does not allow two reference (sp, sp2) to the same object (new Option());std::unique_ptr&lt;Option&gt; sp2(std::move(sp));// now sp is destroyed and sp2 takes ownership of the Option objectsp2-&gt;getPrice();// smart pointer can be used as regular pointer std::shared_ptrThe shared pointer counts the reference to its pointed object and can store and pass a reference beyond the scope of a function. In OOP, the share pointer is used to store a pointer as a member variable and can be used to reference value outside the scope of the class. 1234567std::share_ptr&lt;Option&gt; sp2;&#123; std::share_ptr&lt;Option&gt; sp(new Option()); sp2=sp;&#125;sp2-&gt;getPrice();// the Option object is not deleted after local scope ends Creating a vector of shared_ptr:12345#include &lt;vector&gt;std::vector&lt;std::shared_ptr&lt;Option&gt;&gt; option_list;for (int i=0; i&lt; 10; i++) &#123; option_list.push_back(std::shared_ptr&lt;Option&gt;(new Option(i)));&#125; std::weak_ptrA weak_ptr works the same as shared pointer, but will not increment the reference count.123456std::weak_ptr&lt;Option&gt; sp2;&#123; std::share_ptr&lt;Option&gt; sp(new Option()); sp2=sp;&#125;sp2-&gt;getPrice(); // error! the Option object does not exist beyond scope. Parallel ProcessingThreadingA thread is a small sequence of programmed instruction and is usually a component of a process. Multi-threading can exist within one process, executing concurrently and share resources such as memory, while processes do not share their resources. The std::thread class in c++ supports multi-threading, and can be initiated to represent a single thread. We need to pass a callable object (function pointer, function, or lambda) to the constructor of the std::thread class. We use the std::thread.join() method to wait for the copmletion of a thread. Here we initiate two threads. Both threads share memory and attempt to modify the balance variable at the same time which lead to concurrency issue.123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;thread&gt;using namespace std;int main() &#123; int balance = 0; // t1 starts thread t1([&amp;balance] &#123;for (int i=0; i&lt;1000000; i++) &#123;balance++;&#125;&#125;); // t2 starts thread t2([&amp;balance] &#123;for (int i=0; i&lt;1000000; i++) &#123;balance--;&#125;&#125;); t1.join(); // the main() waits here until t1 completes t2.join(); // the main() waits here until t2 completes cout &lt;&lt; balance &lt;&lt; endl; cout &lt;&lt; \"END OF CODE\" &lt;&lt; endl;&#125; 12153258END OF CODE We introduce the an mutex, or mutual exclusive, object, which contains a unique id for the resources allocated to the program. A thread can lock the resource by a std::mutex.lock() method, which prevent other thread from sharing the resource until the mutex becomes unlocked. 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;using namespace std;int main() &#123; int balance = 0; mutex m; // t1 starts thread t1([&amp;balance, &amp;m] &#123;for (int i=0; i&lt;1000000; i++) &#123; m.lock(); balance++; m.unlock(); &#125;&#125;); // t2 starts thread t2([&amp;balance, &amp;m] &#123;for (int i=0; i&lt;1000000; i++) &#123; m.lock(); balance--; m.unlock(); &#125;&#125;); t1.join(); // the main() waits here until t1 completes t2.join(); // the main() waits here until t2 completes cout &lt;&lt; balance &lt;&lt; endl; cout &lt;&lt; \"END OF CODE\" &lt;&lt; endl;&#125; 120END OF CODE Condition VariableA condition variable is an object that can block the calling thread until notified to resume. It uses a unique_lock (over a mutex) to lock the thread when one of its wait functions is called. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;mutex&gt;#include &lt;thread&gt;#include &lt;vector&gt;using namespace std;mutex m;condition_variable cv;vector&lt;int&gt; v;bool ready = false;bool processed = false;void make_vector() &#123; unique_lock&lt;std::mutex&gt; lk(m); // own the mutex cv.wait(lk, []&#123;return ready;&#125;); // wait until main() sends data for (int k = 0; k &lt; 10; ++k) &#123; v.push_back(k); &#125; processed = true; lk.unlock(); // manual unlocking is done before notifying cv.notify_one(); // unblocks one of the threads currently waiting for this condition // if no threads are waiting, the function does nothing // if more than one threads are waiting, it is unspecified which will be selected&#125;int main() &#123; thread t(make_vector); ready = false; processed = false; &#123; cout &lt;&lt; \"main() signals ready for processing\\n\"; ready = true; &#125; cv.notify_one(); &#123; unique_lock&lt;std::mutex&gt; lk(m); // own the mutex cv.wait(lk, []&#123;return processed;&#125;); // wait for cv.notify_one cout &lt;&lt; \"back to main(), vector is processed\\n\"; &#125; for (auto i : v) &#123; cout &lt;&lt; i &lt;&lt; \" \"; &#125; t.join();&#125; 123main() signals ready for processingback to main(), vector is processed0 1 2 3 4 5 6 7 8 9","tags":"notes"},{"title":"&#128214; Notes on MSFM - Foreign Exchange","url":"/2019/12/finm-notes/05_foreign_exchange/","text":"img.resize { max-width:50%; max-height:50%; } Theoretical PricingFX Spot ContractThe spot price S_t is the observable market price of 1 unit of foeign currency. Let \\mathbb{F} denote foreign currency and \\mathbb{D} denote domestic currency: 1\\mathbb{F} = S_t \\mathbb{D}A FX spot contract is an agreement where the buyer purchase 1 units of foreign currency at a fixed rate R at current time t. Buyer \\; \\dfrac{\\leftarrow 1\\mathbb{F}}{R\\mathbb{D} \\rightarrow} \\; SellerThe contract value to the buyer is: 1\\mathbb{F} - R\\mathbb{D} = (S_t - R)\\mathbb{D}FX Forward ContractDenote domestic interest rate = r^{d}. The price of domestic zero-coupon bond P^d(\\tau) = e^{-r^{d}\\tau} A FX forward contract is an agreement where the buyer agree to purchase 1 units of foreign currency at a fixed rate R at future time T: Buyer \\; \\dfrac{\\leftarrow \\text{1}\\mathbb{F}}{R\\mathbb{D} \\rightarrow} \\; SellerThe time-t value of a forward contract is: \\begin{align} PV_t^{forward} &= PV_t (1\\mathbb{F} - R\\mathbb{D}) \\\\ &= P^{f} \\mathbb{F} - P^{d} R\\mathbb{D} \\\\ &= P^{f} S_t \\mathbb{D} - P^{d} R\\mathbb{D} \\\\ &= [S_t e^{-r^f(T - t)} - R e^{-r^{d}(T - t))}] \\mathbb{D} \\\\ \\end{align}We set PV_t^{forward}=0 to calculate the forward price F_t at time t. The equation is also called the covered interest parity, or CIP: F_t = S_t e^{(r^{d} - r^f)(T - t)}Non-Deliverable forwardNon-deliverable currency has restricted exchange by local regulations. CIP does not hold since covered interest arbitrage is not possible. For example: Asia CNY: China Yuan TWD: New Taiwan Dollar KRW: South Korean Won INR: India Rupee PHP: Philippine Piso IDR: Indonesia Rupiah MYR: Malaysian Ringgit Latin America: COP: Colombian Peso VEB: Venezuelan Bolívar BRL: Brazilian Real PEN: Peru Sol UYU: Uruguayan Peso CLP: Chilean Peso ARS: Argentine Peso Europe, Middle East and Africa: EGP: Egyptian Pound KZT: Kazakhstani Tenge Given CIP, we can calculate the implied yield, which is the foreign interest rate implied by the forward rate, domestic spot rate and domestic interest rate. r^f_{implied} = r^{d} - \\dfrac{\\log{F_t/S_t}}{T - t}We know that the exponential function e^x can be expressed as the sum of the Maclaurin series: e^x = \\sum_{n = 1}^{\\infty} \\dfrac{x^n}{n!} = 1 + x + \\dfrac{x^2}{2!} + \\dfrac{x^3}{3!} ...Applying this to the forward rate: \\begin{align} F(t, T) &= S_t[1 + (r^{d} - r^f)(T - t) + O([(r^{d} - r^f)(T - t)]^2)] \\\\ &\\approx S_t + S_t (r^{d} - r^f)(T - t) \\end{align}FX Swap ContractA FX swap contract contains two FX forward contracts at time T_1, T_2 with opposite directions. For example, a buy/sell swap contract: At\\; t = T_1, Buyer \\; \\dfrac{\\leftarrow 1\\mathbb{F}}{R_1\\mathbb{D} \\rightarrow} \\; Seller \\\\ At\\; t = T_2, Buyer \\; \\dfrac{\\leftarrow R_2\\mathbb{D}}{1\\mathbb{F} \\rightarrow} \\; SellerThe present value of the swap contract is the sum of the present value of the two sub-contracts: \\begin{align} PV_t^{swap} &= PV_t^1 - PV_t^2 \\\\ &= (P^{f1}S_t - P^{d1}R_1)\\mathbb{D} - (P^{f2}S_t - P^{d2}R_1)\\mathbb{D} \\\\ &= [ S_t (e^{-r^{f1}(T_1 - t)} - e^{-r^{f2}(T_2 - t)}) - R_1e^{r^{d1}(T_1 - t)} + R_2e^{r^{d2}(T_2 - t)}]\\mathbb{D} \\\\ \\end{align}Note that the value of a swap contract is fairly insensitive to spot rate changes, comparing to that of a forward contract. \\begin{align} \\dfrac{\\partial PV^{swap}}{\\partial S} &= [(e^{-r^{f1}(T_1 - t)} - e^{-r^{f2}(T_2 - t)})] \\\\ &\\approx r^f (T_2 - T_1) \\;\\;[\\text{assuming } r^{f1} \\approx r^{f2}] \\\\\\\\ \\dfrac{\\partial PV^{forward}}{\\partial S} &\\approx 1 \\\\ \\end{align}FX OptionA FX option conveys the right, but not the obligation, to exchange 1 units of foreign currency for K units of domestic currency, at a future date T. For example, the buyer of a foreign currency call strike at K, have the right at maturity to buy 1 unit of \\mathbb{F} at K even if S_T > K. This is equivalent to the the buyer of K units of domestic currency put strike at 1/K, which grants the buyer the right at maturity to sell K unit of \\mathbb{D} at a rate of 1/K, even if the exchange rate 1/S_T falls below 1/K. In formula: Call^{\\mathbb{F}}(Strike = K\\mathbb{D}) = KPut^{\\mathbb{D}}(Strike = (1/K)\\mathbb{F})Visualizing the transactions on a foreign currency call: \\begin{align} At\\;time\\;t=0 &: Buyer \\; \\xrightarrow{Price(Call^{\\mathbb{F}})} \\; Seller \\\\ At\\;time\\;t=T &: Buyer \\; \\xleftarrow[max(\\;0, (S_T - K)\\mathbb{D}\\;) ]{} \\; Seller \\\\ \\end{align}Visualizing the transactions on a domestic currency put: \\begin{align} At\\;time\\;t=0&: Buyer \\; \\xrightarrow{KPrice(Put^{ \\mathbb{D}})} \\; Seller \\\\ At\\;time\\;t=T&: Buyer \\; \\xleftarrow[K max(\\;0, (1/K - 1/S_T)\\mathbb{F}\\;) ]{} \\; Seller \\\\ \\end{align}FX options also satisfy put-call parity: \\begin{align} Call - Put & = P^{d}[F_t - K] \\\\ &= S_te^{-r^{f}(T-t)} - Ke^{-r^{d}(T-t)} \\\\ \\end{align}Garman-KohlhagenTo evaluate the price of the option: Assumptions on the stochastic nature of St Create a “risk-free” hedge portfolio, in order to find a governing PDE for the option value, which also leads to an equivalent risk-neutral probability measure Solve the PDE directly, with appropriate boundary conditions We know that if a tradable asset S_t follows the geometric Brownian motion: dS_t = rS_tdt + \\sigma S_tdW^{\\mathbb{P}}Applying Ito&#39;s formula any value of a derivative contract V(S_t, t): dV(S_t, t) = \\dfrac{\\partial V}{\\partial t}dt + \\dfrac{\\partial V}{\\partial S_t}dS_t + \\dfrac{1}{2}\\dfrac{\\partial^2 V}{\\partial S_t^2}(dS_t)^2Setting the drift term to be zero as the derivative contract is tradeable, we can derive the Black-Scholes PDE equation characterize V as such: rV = V_t + rS_tV_S + \\dfrac{1}{2}\\sigma^2S_t^2V_{SS}However, since the foreign exchange spot rate S_t is not tradable, we need to tweak the B-S formula. Let B^d and B^f denote a bank account in domestic and foreign currencies, where dB^d = r^dB^d \\;dt and dB^f = r^fB^f \\;dt. Construct replicating portfolio and set the drift term to be 0, the Garman-Kohlhagen PDE equation can be derived: r^dV = V_t + (r^d - r^f) S_tV_S + \\dfrac{1}{2}\\sigma^2S_t^2V_{SS}Solving the PDF: Call^{G-K}_t = P^d [F_t\\Phi(d_1) - K\\Phi(d_2)] \\\\ where \\; d_{1,2} = \\dfrac{log\\dfrac{F_t}{K} \\pm \\dfrac{1}{2}\\sigma^2(T - t)}{\\sigma \\sqrt{T - t}}Using the Freynman-Kac equation with additional derivation, we can conclude that \\exists \\; \\mathbb{Q} s.t. the arbitrage-free price of the contingent claim V is unequivocally determined as the expected value of the discounted final payoff under \\mathbb{Q}, and S_t obeys the stochastic differential equation: dS = (r^d - r^f)Sdt + \\sigma SdW^{\\mathbb{Q}}Practical PricingFX Spot ContractThe trade date is when the terms of the transaction are agreed, and the value date is when transaction occurs, which is trade date+2 for most currency pairs. The spot rate quote EURUSD = 1.2 means: 1\\;EUR = 1.2\\;USD, i.e. higher the EURUSD, stronger the EUR. EUR is the base currency and is set to 1 unit, whereas USD is the numeraire currency which is used as the numeraire. The bid-offer spread EURUSD = 1.199 / 1.201 means: The dealer is willing to buy 1\\;EUR for 1.199\\;USD The dealer is willing to sell 1\\;EUR for 1.201\\;USD Equivalently: The highest price YOU can sell 1\\;EUR is 1.199\\;USD The lowest price YOU can buy 1\\;EUR is 1.201\\;USD FX Forward Contract\\begin{align} \\text{Forward Point} &= Forward \\;\\text{(outright)} - Spot \\\\ &= S_t (e^{(r^d - r^f)T}-1) \\end{align}The forward point is commonly expressed in the unit pip, or point in percentage, that is worth 0.01\\%. Example 1 When selling a forward for foreign currency \\mathbb{F}, the bid side spot rate plus bid side forward points shall be equal to the bid side outright forward rate. A market-maker would construct the short \\mathbb{F} forward as follow. Note that borrowing \\mathbb{F} and lending \\mathbb{D} correspond to selling a forward and therefore the bid-side forward point. Time Transactions t = 0 borrow e^{-r^f_{offer}T}\\mathbb{F} execute a short \\mathbb{F} spot contract lend S_te^{-r^f_{offer}T}\\mathbb{D} t = T receive S_te^{(r^d_{bid}-r^f_{offer})T}\\mathbb{D} execute a long \\mathbb{F} spot contract pay 1\\mathbb{F} This is the same as selling an outright forward contract: Time Transactions t = 0 N/A t = T receive F_t\\mathbb{D} pay 1\\mathbb{F} FX Swap ContractA FX swap contract intends to adjust the timing of cash flows from T_1 to T_2 and alter the value date on an existing trade. The near rate should be consistent with the market forward rate for the near date, and the same goes for the far rate. The swap point is equal to: \\begin{align} \\text{Swap Point} &= \\text{Far Rate} - \\text{Near Rate} \\\\ &= S_te^{(r^d - r^f)(T_2-T_1)} \\end{align}A buy/sell swap on \\mathbb{F} means that it buys a forward on \\mathbb{F} at T_1 and sells a forward on mathbb{F} at T_2. This correspond to borrowing \\mathbb{F} and lending \\mathbb{D}. Example 2 A short outright forward position on \\mathbb{F} can be thought of as a buy/sell swap on \\mathbb{F} with a spot transaction at the near date and T_1=0, similar to Example 1. Here \\tau = T_2 - T_1: Time Transactions t = T_1 borrow e^{-r^f_{offer}\\tau}\\mathbb{F} execute a short \\mathbb{F} forward contract: \\;\\;-\\;\\; pay e^{-r^f_{offer}\\tau}\\mathbb{F} \\;\\;-\\;\\; receive F_{T_1}e^{-r^f_{offer}\\tau}\\mathbb{D} lend F_{T_1}e^{-r^f_{offer}\\tau}\\mathbb{D} t = T_2 receive F_{T_1}e^{(r^d_{bid}-r^f_{offer})\\tau}\\mathbb{D} execute a long \\mathbb{F} forward contract: \\;\\;-\\;\\; pay F_{T_1}e^{(r^d_{bid}-r^f_{offer})\\tau}\\mathbb{D} \\;\\;-\\;\\; receive (1/F_{T_2})F_{T_1}e^{(r^d_{bid}-r^f_{offer})\\tau}\\mathbb{F} pay 1\\mathbb{F} This is the same as a buy/sell swap: Time Transactions t = T_1 recieve e^{-r^f_{offer}\\tau}\\mathbb{F} pay F_{T_1}e^{-r^f_{offer}\\tau}\\mathbb{D} t = T_2 receive F_{T_2}\\mathbb{D} pay 1\\mathbb{F} Example 3 From a market-maker perspective: Contract Swap Point T1 T2 Buy/Sell offer-side swap point pay at bid-side points sell at offer-side points Sell/Buy bid-side swap point sell at bid-side\\ast points pay at bid-side points Note(\\ast): because a swap has less interest rate risk than an outright forward, the market-maker can easily construct a swap with bid-side points for both near and far dates. Example 4 Say the swap point is -0.01, then a party that buy/sell the foreign currency \\mathbb{F} is paying the swap point, because it is selling at a lower Far rate. Conversely, a party that sell/buy \\mathbb{F} is earning the swap point. Risk Characteristics Contract Transactions FX Risk IR Spread Risk Spot 1 Yes No Forward (Outright) 1 Yes Yes Swap 1 No Yes FX OptionThere are four ways to express an option price: Price \\rightarrow in \\mathbb{D} units in \\mathbb{F} units Notional as 1\\mathbb{F} P_{numccy} =\\text{Garman-Kohlhagen} \\rightarrow\\mathbb{D}\\text{ pips} P_{baseccy\\%} =P_{numccy}/S_t \\rightarrow\\mathbb{F}\\text{ %} Notional as 1\\mathbb{D} P_{numccy\\%} =P_{numccy}/K \\rightarrow\\mathbb{D}\\text{ %} P_{baseccy} =P_{numccy\\%}/S_t \\rightarrow\\mathbb{F}\\text{ pips} Straddle\\text{Straddle} = \\text{ATM Call} + \\text{ATM Put}\bThe meaning of ATM can be different: ATMS: at the spot rate ATMF: at the forward rate (preferred by traders) DNS: delta-neutral Risk Reversal\\text{Risk Reversal} = \\text{25-Delta Call} - \\text{25-Delta Put}Where a 25-delta option is an option with a delta of \\pm25\\%. Risk reversal can also denote the difference in implied volatility: \\text{Risk Reversal} = \\sigma_{\\text{25-Delta Call}}- \\sigma_{\\text{25-Delta Put}}Butterfly\\begin{align} \\text{Butterfly} &= \\text{25-Delta Call} + \\text{25-Delta Put} - \\text{Straddle} \\\\ &= \\text{Strangle} - \\text{Straddle} \\end{align}Note that butterfly is vega (\\partial V/\\partial \\sigma) neutral, e.e. the strangle notional is usually larger than the straddle notional to create equal and offestting vega . BF can also denote the difference in implied volatility: \\text{BF} = Avg(\\sigma_{\\text{25-Delta Call}}, \\;\\sigma_{\\text{25-Delta Put}})- \\sigma_{Straddle}Under the Black-Scholes framework, delta-netural strike (K=Se^{\\sigma^2/2}) options have the highest vega \\mathcal{V}: \\begin{align} \\mathcal{V} = \\partial V/\\partial \\sigma &= Se^{-q\\tau}\\phi(d_1)\\sqrt{\\tau} \\\\ &= Ke^{-r\\tau}\\phi(d_2)\\sqrt{\\tau} \\end{align}In addition, option gamma \\Gamma = \\partial^2 V/\\partial S^2 = \\mathcal{V}/(S^2\\sigma T)","tags":"notes"},{"title":"Optimizing No-Limit Hold'em Buy-In under Kelly's Criterion","url":"/2019/11/kelly/","text":"The Kelly&#39;s Criterion, famous for its various application in sports betting and asset management, is detailed in a paper that J. L. Kelly published in 1956 while working under the Bell lab. In a situation where a gambler places repeated bets on an event with success probability of p\\%, Kelly proves that the optimal bet size each time is (2p-1)\\% of the gambler’s total capital. This is due to the fact that as the bets continues, the logarithm of gambler’s wealth is concave with respective to the bet size. Quick ProofLet p denote the true probability of an event which the gambler bets on. V_0 and V_N denotes the initial capital and capital after N bettings, and B denotes the percentage bet size relative to the capital. Among the N bets, W denotes the number of successes. Therefore: V_N = (1+B)^W(1-B)^{(N-W)}V_0Taking the logarithm of both sides and then take derivative w.r.t. B: \\log{V_N} = W\\log{(1+B)} + (N-W)\\log{(1-B)} + \\log{V_0} \\\\ \\dfrac{\\partial}{\\partial B} \\log{V_N} = \\dfrac{W}{1+B} - \\dfrac{N-W}{1-B}Taking the second derivative and we can see that \\log{V_N} is concave w.r.t. B: \\dfrac{\\partial^2}{\\partial B^2} \\log{V_N} = - \\dfrac{W}{(1+B)^2} - \\dfrac{N-W}{(1-B)^2} < 0Setting the partial derivative to zero we can then solve for B' that maximizes \\log{V_N}: B' = 2\\dfrac{W}{N} - 1As N goes to infinity, the optimal bet size becomes 2p-1: \\lim_{N\\rightarrow\\infty} B' = 2p - 1No-Limit Hold’em ApplicationSuppose we have a bankroll of 2000 and wants to play 1/2 No-Limit Hold’em. A standard buy-in size is 100BB which amounts to 200. Suppose we have an inherent edge in this game, how can we vary[1] the buy-in to maximize our long-term profit based on the Kelly’s Criterion? Let’s say we adopt a play style where we play very tight and always all-in pre-flop. We continues until someone calls our all-in and will exit the game no matter the outcome. For now, we will ignore the blinds we are losing by waiting for a hand, since we earn some blinds when players fold to our all-ins. This game now becomes very similar to the gambler situation above, that we either double our buy-in or lose it. Since we assumed that we had an inherent edge[2] p>50\\%, we should be always betting a buy-in of (2p-1)\\% of our bankroll. But how do we know our edge? We know that sample mean is an unbiased estimator of population mean. We may use our average historical win percentage[3] as an estimate. Suppose we played 10 sessions first all with standard buy-in and made 200 in profits. Then our edge can be calculated: \\hat{p} = \\dfrac{1}{n}\\sum p_i = \\dfrac{1}{10} \\dfrac{2200}{400} = 55\\%Based on Kelly’s Criterion, in the 11th session, we want to bet 10\\% of our total bankroll of 2200, which is a buy-in of 220. Now suppose we win the 11th session, then: \\hat{p} = \\dfrac{1}{n}\\sum p_i = \\dfrac{1}{11} (\\dfrac{2200}{400}+\\dfrac{440}{440}) = 59\\%Our next optimal buy-in will become 2420 * 18\\% = 435.6. LimitationsIn the scenario above, we can observe large swings in the estimated win rate and updated optimal buy-in amount after a single session. This is because the high variance of the aggressive, all-in-only play style we adopted. In normal poker plays, the variance will be much lower and as the play history grows, the updates will become incremental. The question now becomes whether Kelly’s Criterion still applies if there are more than 2 outcomes. In fact, Kelly had made a general case for multiple outcome scenarios in his paper. I will continue this exploration in a future post. [1]: We are also making the assumption that varying buy-in will not change our inherent edge/win rate. This assumption can be supported by implementing a floor of 100BB and a cap to our buy-in, no matter what Kelly’s Criterion suggests. [2]: In reality, this play style is difficult to earn an edge, as players will only call our all-in with an even tighter range, causing our win rate to drop below 50%. [3] Note that this only works if our winning is i.i.d. However, as we sit at a table longer, players will be more familiar with our strategy and therefore negatively affect our win rate.","tags":"math"},{"title":"How to Set Up A Photo Library with Raspberry Pi","url":"/2019/10/pi/","text":"Recent I brought a Raspberry Pi 4 and started playing with it. I first moved my Bitcoin algorithmic trading strategy from a VPS to the Pi, which dropped the monthly VPS fee from my credit card bill. My second project is to create a photo library hosted through HTTP, where I can share pictures with my family on the other side of the Pacific ocean. Comparing to other personal cloud storages, this project come with several great advantages: easy to use (only requires a link and a browser) cheap (can use an idle hard drive as storage) customizable (easy to change the ascetics and layout) It is also a great project for one learn about the inner working of computer networking as well as front-end developing. So let’s get started. First we will need a Raspberry Pi 4. I installed the Raspbian GUI operating system on it which is a pretty neat Linux environment to work on. Next you will have to set up NGINX and PHP. NGINX will allow us to host web server on Pi and PHP is a back-end programming language that is useful in interacting with the operating system. For this project we will need to write a PHP script which will go through all designated folders to grab all images automatically. Next up we want to set up SSH so that we can access the Pi terminal through local networks. Then we will use the rsync tool to synchronize the pictures from my laptop to the Pi folder.1rsync -avz -e ssh desktop/image pi@xx.xx.xx.xx:server Here I have a /image folder set up on my Mac desktop, and I want to sync with the /home/pi/server/image folder on my Pi. Use cron to schedule this command if needed. Now that we have all the images sync-ed over to your Pi, we can start NGINX and host a static website. Here is my setup. We run our web service on standard port 80 for HTTP and 443 for HTTPS (HTTPS is HTTP with SSL encryption, which is far more secure)/etc/nginx/sites-enable/server12345678910111213141516171819202122232425server &#123; listen 80; server_name _; return 301 https://$host$request_uri;&#125;server &#123; listen 443; server_name _; root /home/pi/server; index index.php; location / &#123; try_files $uri $uri/ =404; &#125; location ~ \\.php$ &#123; include snippets/fastcgi-php.conf; fastcgi_pass unix:/var/run/php/php7.3-fpm.sock; &#125; location ~ /.well-known &#123; allow all; &#125;&#125; /home/pi/server/index.php12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to My Photo Library!&lt;/title&gt; &lt;style&gt; body &#123; width: auto; margin-left: 2em; margin-right: 2em; font-family: Garamond, serif; &#125; * &#123; margin: 0; padding: 0; &#125; img &#123; image-orientation: from-image; &#125; .imgbox &#123; display: grid; height: 100%; &#125; .center-fit &#123; max-width: 100%; max-height: 100vh; margin: auto; &#125; li &#123; list-style-type:none; margin-right:10px; margin-bottom:10px; float:left; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Welcome to My Photo Library!&lt;/h1&gt; &lt;div class=\"imgbox\"&gt; &lt;ul&gt; &lt;?php $handle = opendir(dirname(realpath(__FILE__)).'/image/'); while($file = readdir($handle))&#123; if($file !== '.' &amp;&amp; $file !== '..' &amp;&amp; $file !== '.DS_Store')&#123; echo '&lt;img class=\"center-fit\" src=\"image/'.$file.'\"&gt;'; &#125; &#125; ?&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Now open up &lt;local ip address of my pi&gt;:443 on my Macbook connected to the same WLAN as my Pi, I will be able to see the webpage I host. Next we need to configure our router for Port Forwarding and then set up a Dynamic DNS service. The No-IP website currently provides free DDNS service. After setting up DDNS, we can then use the hostname from your DDNS provider to access the dynamic IP[1] address of our router, which will be forwarded to the static IP of our raspberry pi with the port that NGINX used to host the website. For example, we just need to type https://&lt;my hostname from ddns provider&gt;:&lt;my router port designated to forward&gt; in the browser to view the photo library anywhere in the world:) [1] In my case my ISP uses Carrier-Grade NAT, which means my public IP is different than my WAN IP. I will need to configure the DDNS provider to access my WAN IP, in order for this to work.","tags":"tech"},{"title":"Bitcoin Quant Strategies - Perpetual Swap Funding","url":"/2019/07/algo/method-3/","text":"BackgroundIn this research, we dive into the bitcoin perpetual swap contract on the BitMEX exchange. Specifically, we are interested at the predicting power of its funding structure and the subsequent applications to algorithmic trading. Traditionally, future provides additional liquidity and leverage to market participants. With 10k USD, one may either buy 1 Bitcoin, or 100 Bitcoin futures which provide 100x more gain potentials. However, every future contract has an expiry date and can be traded at significantly spread. The first Bitcoin future in the U.S. was traded on Dec 10, 2017 on the Cboe Futures Exchange. The Bitcoin perpetual swap contract, on the contrast, does not have an expiry date thus removing the need to rollover. It trades much closer to the underlying Bitcoin price via a funding mechanism. On BitMEX, the swap holders must exchange fundings every 8 hours between the long and short counter-parties. This create price pressure for the swap price to converge to the actual Bitcoin price. For example, if swap price > Bitcoin price, then the funding would be positive and therefore the long positions will need to pay funding to its short counter-parties. This creates pressures for the swap price to decrease and move towards the Bitcoin price. StrategyThe funding creates a great monetary incentive if you are holding the contract on the right side and we would like to see if we can capture the funding gain overtime with an algorithmic trading strategy. Since the funding is announced 8 hours before the actual exchange happens, we have an 8 hour window of entry after knowing that a profitable funding will occur. After we enter the contract and collect the funding, we then have another 8 hour window for exiting (this assumes we only want to enter 1 contract at any given time). We will try to look for optimal enter/exit time combinations and evaluate performances. This is similar to the mean reversion strategy discussed by BitMEX’s founder Arthur Hayes in his blog[1][2]. We are carrying this strategy further, analyzing enter and exit options at more granular level and proposing a more optimal execution strategy. Dependency12345678910111213import pytzimport timeimport datetimeimport requestsimport numpy as npimport pandas as pdfrom random import randomimport statsmodels.api as smimport matplotlib.pyplot as pltfrom IPython.display import display, HTML, Imagefrom sklearn.linear_model import LinearRegressionfrom pandas.plotting import register_matplotlib_convertersregister_matplotlib_converters() 123456plt.rcParams['font.family'] = \"serif\"plt.rcParams['font.serif'] = \"DejaVu Serif\"plt.rcParams['figure.figsize'] = (12, 6)plt.rcParams['figure.dpi'] = 400plt.rcParams['lines.linewidth'] = 0.75pd.set_option('max_row', 6) 12def disp(df, max_rows=6): return display(HTML(df.to_html(max_rows=max_rows, header=True).replace('&lt;table border=\"1\" class=\"dataframe\"&gt;','&lt;table&gt;'))) DataWe can retrieve historical funding rates and minutely swap price data from the BitMEX api. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667def get_funding(): start_date = datetime.datetime(2016, 5, 14, 0, 0, 0, 0, tzinfo=pytz.utc) end_date = datetime.datetime.now(tz=pytz.utc) - datetime.timedelta(days=14) endpoint = 'https://www.bitmex.com/api/v1/funding' payload = &#123;'count':'500', 'reverse':'false', 'symbol':'XBTUSD', 'startTime': start_date&#125; response = requests.get(endpoint, params=payload) funding_rates_df = pd.DataFrame(response.json()) funding_rates_df['timestamp'] = pd.to_datetime(funding_rates_df['timestamp'], utc=True) funding_rates_df.set_index('timestamp', drop=True, inplace=True) start_date = funding_rates_df.index[-1] + datetime.timedelta(hours=1) while start_date &lt; end_date: time.sleep(random()) # requesting too frequently will cause error endpoint = 'https://www.bitmex.com/api/v1/funding' payload = &#123;'count':'500', 'reverse':'false', 'symbol':'XBTUSD', 'startTime': start_date&#125; response = requests.get(endpoint, params=payload) funding_rates_df_tmp = pd.DataFrame(response.json()) funding_rates_df_tmp['timestamp'] = pd.to_datetime(funding_rates_df_tmp['timestamp'], utc=True) funding_rates_df_tmp.set_index('timestamp', drop=True, inplace=True) start_date = funding_rates_df_tmp.index[-1] + datetime.timedelta(hours=1) funding_rates_df = funding_rates_df.append([funding_rates_df_tmp]) funding_rates_df.to_csv('funding_rates_df.csv') return funding_rates_dfdef get_swap(): # start_date = datetime.datetime(2016, 5, 14, 0, 0, 0, 0, tzinfo=pytz.utc) # end_date = datetime.datetime.now(tz=pytz.utc) start_date = datetime.datetime(2019, 1, 1, 0, 0, 0, 0, tzinfo=pytz.utc) end_date = datetime.datetime(2019, 11, 14, 23, 59, 59, 0, tzinfo=pytz.utc) endpoint = 'https://www.bitmex.com/api/v1/trade/bucketed' payload = &#123;'count':'1000', 'reverse':'false', 'symbol':'XBTUSD', 'startTime': start_date, 'binSize': '1m'&#125; response = requests.get(endpoint, params=payload) print(response) swap_df = pd.DataFrame(response.json()) swap_df['timestamp'] = pd.to_datetime(swap_df['timestamp'], utc=True) swap_df.set_index('timestamp', drop=True, inplace=True) start_date = swap_df.index[-1] + datetime.timedelta(hours=1) while start_date &lt; end_date: try: time.sleep(random()) endpoint = 'https://www.bitmex.com/api/v1/trade/bucketed' payload = &#123;'count':'1000', 'reverse':'false', 'symbol':'XBTUSD', 'startTime': start_date, 'binSize': '1m'&#125; response = requests.get(endpoint, params=payload) swap_df_tmp = pd.DataFrame(response.json()) swap_df_tmp['timestamp'] = pd.to_datetime(swap_df_tmp['timestamp'], utc=True) swap_df_tmp.set_index('timestamp', drop=True, inplace=True) start_date = swap_df_tmp.index[-1] + datetime.timedelta(hours=1) swap_df = swap_df.append([swap_df_tmp]) print(start_date) except Exception as e: print(e) continue swap_df.to_csv(\"swap_df_1m_2019.csv\") return swap_df_tmp 123456789101112131415161718swap = pd.read_csv(\"swap_df_1m.csv\")swap['timestamp'] = pd.to_datetime(swap['timestamp'], utc=True)swap.set_index('timestamp', inplace=True)swap.fillna(method='ffill', inplace=True)swap.dropna(inplace=True)funding = pd.read_csv(\"funding_rates_df.csv\")funding['timestamp'] = pd.to_datetime(funding['timestamp'], utc=True)funding.set_index('timestamp', inplace=True)funding = funding['fundingRate'].to_frame()funding = funding.loc[funding.index &gt;= '2016-06-05']df = swap.join([funding])# swap return by holding from funding time -30m to +1mdf['swapRet'] = df.swapPrice.shift(-300) / df.swapPrice.shift(30) - 1df.dropna(inplace=True)disp(df) swapPrice fundingRate swapRet timestamp 2016-06-05 04:00:00+00:00 585.6001 0.000242 -0.002756 2016-06-05 12:00:00+00:00 581.3784 0.000237 -0.004034 2016-06-05 20:00:00+00:00 580.9900 0.000234 -0.000978 ... ... ... ... 2019-11-06 04:00:00+00:00 9314.4560 0.000100 0.013475 2019-11-06 12:00:00+00:00 9395.8470 0.000198 -0.008921 2019-11-06 20:00:00+00:00 9301.4603 0.000374 0.002900 1234567891011121314colors = np.where(df.fundingRate &gt;= 0, 'tab:green', 'tab:red')fig, ax1 = plt.subplots()ax1.plot(df.swapPrice, c='black', linewidth=0.3)ax1.set_ylabel('swapPrice')ax1.set_ylim(-22500, 22500)ax2 = ax1.twinx()ax2.scatter(df.index, df.fundingRate, c=colors, s=0.1)ax2.set_ylabel('fundingRate')ax2.set_ylim(-0.0075, 0.025)plt.title(\"Swap Price vs Funding Rate\")plt.show() AnalysisRegress the funding rates to the swap return at different enter/exit time. Here we are trying to look for statistically significant (ideally, negative) correlation between the two. Since a negative correlation would imply additional gain from price change on top of the funding profit. We only consider entering a contract if the funding is outside twice of its 60-day historical rolling standard deviations. 12345678910111213141516171819def filter_on_rolling_std(df, window, sigma_band, t1, t2, run_reg=False, show_summary=False, show_coef=True): df_sigma = df.copy() df_sigma['sigma'] = df_sigma.fundingRate.rolling(window).std() df_sigma = df_sigma.fillna(method = 'ffill').dropna() df_sigma = df_sigma.loc[(df_sigma.fundingRate &gt; sigma_band * df_sigma.sigma) | (df_sigma.fundingRate &lt; -sigma_band * df_sigma.sigma)] if run_reg: y = np.array(df_sigma['swapRet']) X = np.array(df_sigma[['fundingRate']]) X = sm.add_constant(X) model = sm.OLS(y,X).fit() coef = model.params[1].round(4) pval = model.pvalues[0].round(4) if show_summary: print(model.summary()) if show_coef: print('enter', t1, 'exit', t2, 'coef', coef, 'pval', pval) return df_sigma, coef, pval 1234567891011121314151617181920comp_exit = pd.DataFrame(columns=['exit time', 'coef', 'pval'])t1 = -100for i in np.arange(0, 481, 10): t2=i df = swap.join([funding]) df['swapRet'] = df.swapPrice.shift(-t2) / df.swapPrice.shift(-t1) - 1 df.dropna(inplace=True) df_sigma, coef, pval = filter_on_rolling_std(df, 180, 2, t1, t2, True, show_coef=False) comp_exit = comp_exit.append(&#123;'exit time': t2, 'coef': coef, 'pval': pval&#125;, ignore_index=True)comp_exit = comp_exit.set_index('exit time')plt.plot(comp_exit)plt.axhline(y=0.05, color='grey', linestyle='dashed')plt.legend(comp_exit.columns, frameon=False)plt.xlabel('Exit Time')plt.xticks(np.arange(0, 481, step=60))plt.show() Here we observe that as exit time becomes longer, the coefficient becomes more negative and p-value of the coefficient indicates higher significance. Thus we would want to hold the swap position more than 360 minutes/6 hours. Next we look at the impact from entry time. 123456789101112131415161718192021222324comp_enter = pd.DataFrame(columns=['enter time', 'coef', 'pval'])t1 = -60t2 = 420for i in np.arange(-120, 0, 1): t1=i df = swap.join([funding]) df['swapRet'] = df.swapPrice.shift(-t2) / df.swapPrice.shift(-t1) - 1 df.dropna(inplace=True) if t1 == -60: df_sigma, coef, pval = filter_on_rolling_std(df, 180, 2, t1, t2, True, show_summary=True, show_coef=False) else: df_sigma, coef, pval = filter_on_rolling_std(df, 180, 2, t1, t2, True, show_coef=False) comp_enter = comp_enter.append(&#123;'enter time': t1, 'coef': coef, 'pval': pval&#125;, ignore_index=True)comp_enter = comp_enter.set_index('enter time')plt.plot(comp_enter)plt.axhline(y=0.05, color='grey', linestyle='dashed')plt.legend(comp_enter.columns, frameon=False)plt.xlabel('Enter Time')plt.xticks(np.arange(-120, 0, step=30))plt.show() Similar trends are observed in the entry times and that earlier the entry, the more profit it seems to imply from price changes. We show a summary of the regression at enter time=-60 minutes and exit time=420 minutes. There is a moderate R-square of 0.039 and high significance in coefficient which suggest a mean reversion in price given that specific time window. 12345678910111213141516171819202122232425 OLS Regression Results ==============================================================================Dep. Variable: y R-squared: 0.039Model: OLS Adj. R-squared: 0.036Method: Least Squares F-statistic: 10.46Date: Thu, 05 Dec 2019 Prob (F-statistic): 0.00138Time: 03:38:11 Log-Likelihood: 552.01No. Observations: 257 AIC: -1100.Df Residuals: 255 BIC: -1093.Df Model: 1 Covariance Type: nonrobust ============================================================================== coef std err t P&gt;|t| [0.025 0.975]------------------------------------------------------------------------------const 0.0035 0.002 1.809 0.072 -0.000 0.007x1 -2.2357 0.691 -3.235 0.001 -3.597 -0.875==============================================================================Omnibus: 17.788 Durbin-Watson: 2.247Prob(Omnibus): 0.000 Jarque-Bera (JB): 54.546Skew: 0.089 Prob(JB): 1.43e-12Kurtosis: 5.250 Cond. No. 391.==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. StrategyBased on the research above, this strategy will enter into a swap agreement to collect funding at t1= -1H and exit at t2= +7H. At t2, if the next funding does not fall outside of the 2-sigma band AND if we are in a position to collect the next funding, we will test two choices of holding for 1H more and exit after colllecting the funding exiting We will test the impact of a 10bps fee + slippage on each trade. 12345678910111213141516171819202122232425262728293031t1 = -60t2 = 420window = 180sigma_band = 2fee = 0.0010 # per two tradesdf = swap.join([funding])df['swapRet'] = df.swapPrice.shift(-t2) / df.swapPrice.shift(-t1) - 1df['swapRet1H'] = df.swapPrice.shift(1) / df.swapPrice.shift(-t1) - 1df.dropna(inplace=True)df['sigma'] = df.fundingRate.rolling(window).std()df.dropna(inplace=True)df['pnl'] = np.where((df.fundingRate &gt; sigma_band*df.sigma) \\ | (df.fundingRate &lt; -sigma_band*df.sigma), \\ 1 + np.abs(df.fundingRate) + \\ df.swapRet * -np.sign(df.fundingRate), 1)df['pnlOptimized'] = np.where((df.pnl != 1) &amp; (df.pnl.shift(-1) == 1) \\ &amp; (np.sign(df.fundingRate) == np.sign(df.fundingRate.shift(-1))), df.pnl + np.abs(df.fundingRate.shift(-1)) + \\ df.swapRet1H.shift(-1) * -np.sign(df.fundingRate.shift(-1)), df.pnl)df['pnlFee'] = np.where((df.pnl != 1) &amp; (df.pnl.shift(1) == 1), df.pnl - fee, df.pnl) # enter feedf['pnlFee'] = np.where((df.pnl != 1) &amp; (df.pnl.shift(-1) == 1), df.pnlFee - fee, df.pnlFee) # exit feedf['pnlFee'] = np.where((df.pnl != 1) &amp; (df.pnl.shift(1) != 1) \\ &amp; (np.sign(df.fundingRate) != np.sign(df.fundingRate.shift(1))), df.pnlFee - fee, df.pnlFee) # change position enter feedf['pnlFee'] = np.where((df.pnl != 1) &amp; (df.pnl.shift(-1) != 1) \\ &amp; (np.sign(df.fundingRate) != np.sign(df.fundingRate.shift(-1))), df.pnlFee - fee, df.pnlFee) # change position exit feedisp(df.iloc[289:293]) swapPrice fundingRate swapRet swapRet1H sigma pnl pnlOptimized pnlFee timestamp 2016-11-16 20:00:00+00:00 748.1800 0.000264 0.008467 0.014128 0.001042 1.000000 1.000000 1.000000 2016-11-17 04:00:00+00:00 744.8734 0.003750 0.008865 0.001431 0.001066 0.994885 0.994885 0.993885 2016-11-17 20:00:00+00:00 742.2400 0.003140 -0.007095 -0.001269 0.001081 1.010235 1.008677 1.009235 2016-11-18 04:00:00+00:00 740.0665 0.001242 0.012663 0.002800 0.001080 1.000000 1.000000 1.000000 12345plt.plot(df.pnl.cumprod(), c='black')plt.plot(df.pnlOptimized.cumprod(), c='tab:blue')plt.plot(df.pnlFee.cumprod(), c='grey')plt.legend(['PNL', 'PNL optimized', 'PNL with fee (not optimized)'])plt.show() 1234567def backtest_metric(df, pnl_column, mdd_interval=180): pnl = round(df[pnl_column].cumprod()[-1], 4) spr = round(np.mean(df[pnl_column]-1) / np.std(df[pnl_column]-1) * np.sqrt(365 * 3), 4) mdd = round(np.min((df[pnl_column].cumprod().rolling(mdd_interval).min() \\ - df[pnl_column].cumprod().shift(mdd_interval)) \\ / df[pnl_column].cumprod().shift(mdd_interval)), 4) return pnl, spr, mdd 12345678910result = pd.DataFrame(columns=['Strategy', 'P&amp;L', 'Sharpe Ratio', 'Maximum Drawdown'])pnl, spr, mdd = backtest_metric(df, 'pnl')result = result.append(&#123;'Strategy': 'Baseline', 'P&amp;L': pnl, 'Sharpe Ratio': spr, 'Maximum Drawdown': mdd&#125;, ignore_index=True)pnl, spr, mdd = backtest_metric(df, 'pnlOptimized')result = result.append(&#123;'Strategy': 'Optimized', 'P&amp;L': pnl, 'Sharpe Ratio': spr, 'Maximum Drawdown': mdd&#125;, ignore_index=True)disp(result) Strategy P&amp;L Sharpe Ratio Maximum Drawdown 0 Baseline 5.5625 2.2086 -0.1438 1 Optimized 6.7478 2.3101 -0.1221 We can see that this strategy does provide substantial P&amp;L from the historical periods tested with relatively limited capital exposure. Fees would impact the gains slightly, and using an optimize approach would further improve the performance. Reference: [1]: XBTUSD Funding Mean Reversion Strategy, https://blog.bitmex.com/xbtusd-funding-mean-reversion-strategy/[2]: Funding Mean Reversions 2018, https://blog.bitmex.com/funding-mean-reversions-2018/","tags":"tech"},{"title":"Bitcoin Quant Strategies - Momentum Trading","url":"/2019/07/algo/method-2/","text":"In this research I studied on the performance of simple and exponential moving average crossover strategies, with window sizes chosen by optimizing in-sample PNL, sharpe ratio and 30-day maximum drawdown. The calibrated strategy performs well, earning 500% cumulative return compared to baseline and a sharpe ratio of 1.30. The the 30-day maximum drawdown is similar to the baseline. Strategy P&amp;L Sharpe Ratio Maximum Drawdown 0 Baseline 0.28 -1.48 0.35 1 MA 1.54 1.30 0.37 2 EWMA 1.45 1.10 0.38 MotivationIt is no secret that price manipulations have always plagued the rising crypto-market. In this [paper], the auther studies large transactions behind the tether coin, and showed more evidence supporting that each large move in the crypto-market usually only come from the act of only a few. In this type of regime, I argue that technical indicator may be a better bet to profit compared to any attempt to apply fundamental analysis, because an increase in price no longer comes from the increase in a crypto’s intrinsic value, but rather speculation and manipulation. In this exercise I will mainly focus on moving average crossover techniques and its optimization. Packages123456789101112131415161718import itertoolsfrom IPython.display import display, HTML, Imageimport matplotlib.pyplot as pltimport matplotlib.ticker as tickerimport numpy as npimport pandas as pdfrom pandas.plotting import register_matplotlib_convertersimport warningsregister_matplotlib_converters()warnings.filterwarnings(\"ignore\")plt.rcParams['font.family'] = \"serif\"plt.rcParams['font.serif'] = \"DejaVu Serif\"plt.rcParams['figure.figsize'] = (12, 6)plt.rcParams['figure.dpi'] = 150plt.rcParams['lines.linewidth'] = 0.75pd.set_option('max_row', 10) Function12def disp(df): return display(HTML(df.to_html(max_rows=10, header=True).replace('&lt;table border=\"1\" class=\"dataframe\"&gt;','&lt;table&gt;'))) Data ExplorationI got the preliminary bitcoin data from bitcoincharts. Data include price and volume information recorded by Bitstamp and split by seconds. This provide great granularity that can be grouped into any desirable levels later on. 123data = pd.read_csv('bitstampUSD.csv', header=None, names=['time', 'price', 'volume'])data['time'] = pd.to_datetime(data['time'], unit='s')data.set_index('time', inplace=True) Get 3-month treasury data. 12url = 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=DTB3'tr = pd.read_csv(url, index_col=0, parse_dates=True) Data are grouped in to daily, with average applied to price and sum applied to trade volume. The backtest period is selected to be from 2018 to 2019, where the market was in continuous downturn. This ensure that our strategy performs well in adverse scenarios. 12345df1 = data.loc['2018-01-01':'2019-01-01'].resample('1D').agg(&#123;'price': np.mean, 'volume': np.sum&#125;)df2 = tr.loc['2018-01-01':'2019-01-01']df = df1.join(df2).replace('.', np.NaN).fillna(method='ffill').fillna(method='bfill').rename(&#123;'DTB3': 'tr'&#125;, axis=1)df.tr = df.tr.astype(float)/100disp(df) price volume tr time 2018-01-01 13386.429268 7688.030685 0.0142 2018-01-02 14042.643870 16299.669303 0.0142 2018-01-03 14947.898046 12275.001197 0.0139 2018-01-04 14802.363927 15004.018593 0.0139 2018-01-05 15967.972719 16248.914680 0.0137 ... ... ... ... 2018-12-28 3752.739978 13055.718407 0.0235 2018-12-29 3862.153295 6901.382332 0.0235 2018-12-30 3783.210991 5736.453708 0.0235 2018-12-31 3745.258717 6667.163737 0.0240 2019-01-01 3709.889253 5149.606277 0.0240 123plt.plot(df.price, c='tab:grey')plt.ylabel('Bitcoin Price in USD')plt.show() Simple Moving AverageA simple moving average strategy use the cross-over point of two moving averages as the trading signal. Here we use grid-search to find out the window size pair that optimizes our desired metrics, namely P&amp;L, Sharpe ratio and 30-day maximum drawdown. 123456789101112131415161718192021222324252627282930313233def moving_average(df0, ma1, ma2, transactionFee=0, runBaseline=False, returnStats=True, ewma=False): df = df0.copy() if ewma: df['ma'+str(ma1)] = df.price.ewm(span=ma1).mean() df['ma'+str(ma2)] = df.price.ewm(span=ma2).mean() else: df['ma'+str(ma1)] = df.price.rolling(ma1).mean() df['ma'+str(ma2)] = df.price.rolling(ma2).mean() df['ind'] = df['ma'+str(ma1)] &gt; df['ma'+str(ma2)] df.dropna(inplace=True) df['buy'] = (df.ind != df.ind.shift(1)) &amp; df.ind &amp; (df.index != df.index[0]) df['sell'] = (df.ind != df.ind.shift(1)) &amp; df.ind.shift(1) &amp; (df.buy.cumsum() &gt; 0) if runBaseline: df.ind = 1 df.buy = 1 df['pnl'] = df.ind * (df.buy.cumsum() &gt; 0) * df.price.shift(-1) / df.price df.pnl = df.pnl * np.where(df.ind != df.ind.shift(1), 1-transactionFee, 1) df.dropna(inplace=True) df.pnl.replace(0, 1, inplace=True) if returnStats: df['tr_daily'] = (1 + df.tr)**(1/365) - 1 pnl = round(df.pnl.cumprod()[-1], 2) sharpe_ratio = round(np.mean(df.pnl-1-df.tr_daily) / np.std(df.pnl-1) * np.sqrt(365), 2) mdd_dur = 30 max_draw_down = round(np.max(df.pnl.cumprod().rolling(mdd_dur).max() - df.pnl.cumprod().shift(mdd_dur)), 2) return pnl, sharpe_ratio, max_draw_down else: return df First let’s compute the baseline results, from a simple buy and hold strategy. 123pnl, spr, mdd = moving_average(df, 1, 1, runBaseline=True)comp = pd.DataFrame(&#123;'Strategy': 'Baseline', 'P&amp;L': pnl, 'Sharpe Ratio': spr, 'Maximum Drawdown': mdd&#125;, index=[0])disp(comp) Strategy P&amp;L Sharpe Ratio Maximum Drawdown 0 Baseline 0.28 -1.48 0.35 Performing grid-search for the optimal window size pair. Note that 25bps of transaction fee is added, this is to reflect the typical fee charged by crypto exchanges. I used coinbase pro’s fee here as an example. 12345678910111213fee = 0.0025test_range = np.arange(1, 61)result_ma = pd.DataFrame(columns=['Strategy','MA1', 'MA2', 'P&amp;L', 'Sharpe Ratio', 'Maximum Drawdown'])# grid-searchfor ma1 in test_range: for ma2 in test_range: if ma2 &gt; ma1 + 3: pnl, spr, mdd = moving_average(df, ma1, ma2, transactionFee=fee) result_ma = result_ma.append(&#123;'Strategy': 'MA', 'MA1': ma1, 'MA2': ma2, 'P&amp;L': pnl, 'Sharpe Ratio': spr, 'Maximum Drawdown': mdd&#125;, ignore_index=True) 1disp(result_ma.sort_values('P&amp;L', ascending=False).head()) Strategy MA1 MA2 P&amp;L Sharpe Ratio Maximum Drawdown 2 MA 1 7 1.54 1.30 0.37 3 MA 1 8 1.31 0.86 0.34 12 MA 1 17 1.26 0.81 0.33 11 MA 1 16 1.26 0.81 0.32 9 MA 1 14 1.25 0.78 0.32 1disp(result_ma.sort_values('Sharpe Ratio', ascending=False).head()) Strategy MA1 MA2 P&amp;L Sharpe Ratio Maximum Drawdown 2 MA 1 7 1.54 1.30 0.37 3 MA 1 8 1.31 0.86 0.34 11 MA 1 16 1.26 0.81 0.32 12 MA 1 17 1.26 0.81 0.33 9 MA 1 14 1.25 0.78 0.32 1disp(result_ma.sort_values('Maximum Drawdown', ascending=True).head()) Strategy MA1 MA2 P&amp;L Sharpe Ratio Maximum Drawdown 1129 MA 26 59 0.51 -3.38 0.04 1099 MA 25 60 0.54 -3.19 0.04 1130 MA 26 60 0.52 -3.29 0.04 1160 MA 27 60 0.52 -3.35 0.04 1128 MA 26 58 0.54 -3.01 0.06 Choosing 1-7 as our selected window pair. Plotting the PNL over the 1-year backtest period. 1234567891011bt = df.copy()bt['Baseline: Buy and Hold'] = bt.price/bt.price[0]bt['Strategy 1: MA 1-7'] = moving_average(df.copy(), 1, 7, returnStats=False).pnl.cumprod()bt['Strategy 2: MA 1-7 with Fee'] = moving_average(df.copy(), 1, 7, transactionFee=fee, returnStats=False).pnl.cumprod()plt.plot(bt.iloc[:, 3], c='tab:grey')plt.plot(bt.iloc[:, 4], c='tab:red')plt.plot(bt.iloc[:, 5], c='tab:red', alpha=0.5)plt.legend(bt.columns[3:6], frameon=False)plt.ylabel('Cumulative Asset Value Based on $1 Investment')plt.show() It seems that the trading fee does not have a material impact on the result. We plot the buy/sell signals as follow. 12345678bt = df.copy()ma = moving_average(bt, 1, 7, transactionFee=fee, returnStats=False)plt.plot(bt.price, c='black', label='Bitcoin Price')plt.plot(ma.price.loc[ma.buy], '^', markersize=3, color='g', label='Buy Signal')plt.plot(ma.price.loc[ma.sell], 'v', markersize=3, color='r', label='Sell Signal')plt.legend()plt.show() EWMAPerform the same grid-search optimization using EWMA (Exponentially Weighted Moving Averages). 123456789101112test_range = np.arange(1, 61)result_ewma = pd.DataFrame(columns=['Strategy','MA1', 'MA2', 'P&amp;L', 'Sharpe Ratio', 'Maximum Drawdown'])# grid-searchfor ma1 in test_range: for ma2 in test_range: if ma2 &gt; ma1 + 3: pnl, spr, mdd = moving_average(df, ma1, ma2, transactionFee=fee, ewma=True) result_ewma = result_ewma.append(&#123;'Strategy': 'EWMA', 'MA1': ma1, 'MA2': ma2, 'P&amp;L': pnl, 'Sharpe Ratio': spr, 'Maximum Drawdown': mdd&#125;, ignore_index=True) 1disp(result_ewma.sort_values('P&amp;L', ascending=False).head()) Strategy MA1 MA2 P&amp;L Sharpe Ratio Maximum Drawdown 0 EWMA 1 5 1.45 1.10 0.38 1 EWMA 1 6 1.39 0.98 0.39 5 EWMA 1 10 1.38 1.01 0.32 10 EWMA 1 15 1.36 0.99 0.38 6 EWMA 1 11 1.31 0.87 0.31 1disp(result_ewma.sort_values('Sharpe Ratio', ascending=False).head()) Strategy MA1 MA2 P&amp;L Sharpe Ratio Maximum Drawdown 0 EWMA 1 5 1.45 1.10 0.38 5 EWMA 1 10 1.38 1.01 0.32 10 EWMA 1 15 1.36 0.99 0.38 1 EWMA 1 6 1.39 0.98 0.39 12 EWMA 1 17 1.31 0.89 0.38 1disp(result_ewma.sort_values('Maximum Drawdown', ascending=True).head()) Strategy MA1 MA2 P&amp;L Sharpe Ratio Maximum Drawdown 797 EWMA 17 42 0.51 -2.34 0.18 1069 EWMA 25 30 0.53 -2.22 0.18 1068 EWMA 25 29 0.51 -2.29 0.18 1067 EWMA 24 60 0.67 -1.92 0.18 1066 EWMA 24 59 0.67 -1.92 0.18 Selecting 1-7 as our window pair. Plotting the cumulative strategy return and buy/sell signals. 1234567891011bt = df.copy()bt['Baseline: Buy and Hold'] = bt.price/bt.price[0]bt['Strategy 1: EMWA 1-5 (Best PNL)'] = moving_average(df.copy(), 1, 5, returnStats=False, ewma=True).pnl.cumprod()bt['Strategy 2: EMWA 1-5 (Best PNL) with Fee'] = moving_average(df.copy(), 1, 5, transactionFee=fee, returnStats=False, ewma=True).pnl.cumprod()plt.plot(bt.iloc[:, 3], c='tab:grey')plt.plot(bt.iloc[:, 4], c='tab:blue')plt.plot(bt.iloc[:, 5], c='tab:blue', alpha=0.5)plt.legend(bt.columns[3:6], frameon=False)plt.ylabel('Cumulative Asset Value Based on $1 Investment')plt.show() 12345678bt = df.copy()ma = moving_average(bt, 1, 5, transactionFee=fee, returnStats=False, ewma=True).copy()plt.plot(bt.price, c='black', label='Bitcoin Price')plt.plot(ma.price.loc[ma.buy], '^', markersize=3, color='g', label='Buy Signal')plt.plot(ma.price.loc[ma.sell], 'v', markersize=3, color='r', label='Sell Signal')plt.legend()plt.show() Comparing the MA and EWMA strategies. 1234567891011bt = df.copy()bt['Baseline: Buy and Hold'] = bt.price/bt.price[0]bt['Strategy 1: Moving Average 1-7'] = moving_average(df.copy(), 1, 7, transactionFee=fee, returnStats=False).pnl.cumprod()bt['Strategy 2: EWMA 1-5'] = moving_average(df.copy(), 1, 5, transactionFee=fee, returnStats=False, ewma=True).pnl.cumprod()plt.plot(bt.iloc[:, 3], c='tab:grey')plt.plot(bt.iloc[:, 4], c='tab:red')plt.plot(bt.iloc[:, 5], c='tab:blue')plt.legend(bt.columns[3:6], frameon=False)plt.ylabel('Cumulative Asset Value Based on $1 Investment')plt.show() As we can see, the MA strategy slightly outperforms the EWMA strategy in all three metrics. 123comp = comp.append(result_ma.iloc[2, [0, 3, 4, 5]], ignore_index=True)comp = comp.append(result_ewma.iloc[0, [0, 3, 4, 5]], ignore_index=True)disp(comp) Strategy P&amp;L Sharpe Ratio Maximum Drawdown 0 Baseline 0.28 -1.48 0.35 1 MA 1.54 1.30 0.37 2 EWMA 1.45 1.10 0.38 ImplementationStarting 08-01-2019, I have implemented the optimal MA strategy on a VPS (virtual private server), running 24/7 through the coinbase pro api. Will post update on this periodically.","tags":"tech"},{"title":"Bitcoin Quant Strategies - Classification Methods","url":"/2019/07/algo/method-1/","text":"In this research I looked at intraday Bitcoin trading based on price and volume information using classification models. Strategy Precision P&amp;L Sharpe Ratio 10 MLP Classifier 0.55 2.06 1.79 3 KNN 0.50 1.95 1.85 0 Baseline 0.00 1.69 1.14 4 Decision Tree 0.49 1.61 1.84 5 Random Forest 0.53 1.55 1.16 8 XGBoost 0.52 1.33 0.86 9 SVC 0.47 1.31 0.73 1 Logistic Regression 0.47 1.14 0.47 7 Gradient Boost 0.48 1.06 0.33 6 AdaBoost 0.50 0.86 -0.09 2 Linear Discriminant Analysis 0.47 0.85 -0.17 Packages1234567891011121314151617181920212223242526import warningsimport itertoolsimport numpy as npimport pandas as pdfrom sklearn import treefrom sklearn.svm import SVCimport matplotlib.pyplot as pltfrom xgboost import XGBClassifierimport matplotlib.ticker as tickerfrom sklearn.decomposition import PCAfrom imblearn.over_sampling import SMOTEfrom sklearn.metrics import confusion_matrixfrom multiprocessing import set_start_methodfrom sklearn.tree import DecisionTreeClassifierfrom IPython.display import display, HTML, Imagefrom sklearn.neural_network import MLPClassifierfrom sklearn.preprocessing import StandardScalerfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.linear_model import LogisticRegressionfrom sklearn.model_selection import KFold, GridSearchCVfrom pandas.plotting import register_matplotlib_convertersfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysisfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifierregister_matplotlib_converters()warnings.filterwarnings(\"ignore\") 123456plt.rcParams['font.family'] = \"serif\"plt.rcParams['font.serif'] = \"DejaVu Serif\"plt.rcParams['figure.figsize'] = (12, 6)plt.rcParams['figure.dpi'] = 100plt.rcParams['lines.linewidth'] = 0.75pd.set_option('max_row', 10) FunctionThis is a customized function used to plot confusion matrix in python. 12def disp(df, max_rows=10): return display(HTML(df.to_html(max_rows=max_rows, header=True).replace('&lt;table border=\"1\" class=\"dataframe\"&gt;','&lt;table&gt;'))) Data ExplorationI got the preliminary bitcoin data from bitcoincharts. Data include price and volume information recorded by Bitstamp and split by seconds. This provide great granularity that can be grouped into any desirable levels later on. 123data = pd.read_csv('bitstampUSD.csv', header=None, names=['time', 'price', 'volume'])data['time'] = pd.to_datetime(data['time'], unit='s')data.set_index('time', inplace=True) Get 3-month treasury bill price. 12url = 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=DTB3'tr = pd.read_csv(url, index_col=0, parse_dates=True) We first resample our data by hour. Since most Bitcoin exchanges nowadays have transaction fees, which renders retail trading at a high frequency level unattainable. Therefore I leave out the second and minute level data and combine them into hours. Note that I average the price while summing the volume within an hour. A 2 year data window from 2017 to 2019 is used, as this is when Bitcoin and other crypto has come into the attention of the larger public, and mostly importantly, started to be heavily traded. Therefore the training set will be more representative of any future trading environment. The plot below illustrates the total dollar amount traded per hours over time. 1234df0 = data.resample('H').agg(&#123;'price': np.mean, 'volume': np.sum&#125;).fillna(method='ffill')plt.plot(df0.volume * df0.price, c='black')plt.title('Bitcoin Dollar Volume in Dollar Term')plt.show() 123456df1 = data.loc['2017-07-01':'2019-06-30'].resample('H').agg(&#123;'price': np.mean, 'volume': np.sum&#125;).fillna(method='ffill')df2 = tr.loc['2017-07-01':'2019-06-30']df = df1.join(df2).replace('.', np.NaN).fillna(method='ffill').fillna(method='bfill').rename(&#123;'DTB3': 'tr'&#125;, axis=1)df.tr = df.tr.astype(float)/100disp(df) price volume tr time 2017-07-01 00:00:00 2473.427264 200.793669 0.0104 2017-07-01 01:00:00 2463.946180 228.853771 0.0104 2017-07-01 02:00:00 2441.314976 475.068038 0.0104 2017-07-01 03:00:00 2449.063866 177.876034 0.0104 2017-07-01 04:00:00 2453.192311 120.916328 0.0104 ... ... ... ... 2019-06-30 19:00:00 11173.875377 389.958860 0.0208 2019-06-30 20:00:00 11276.492157 372.471619 0.0208 2019-06-30 21:00:00 11340.807808 295.522323 0.0208 2019-06-30 22:00:00 11037.539360 963.543871 0.0208 2019-06-30 23:00:00 10838.165248 1152.810243 0.0208 123plt.plot(df.price, c='black')plt.title('Bitcoin Price 2017-07-01 to 2019-06-30')plt.show() We then created several more data fields intending to extract more information from the previous n-hour window 1234567891011interval = [6, 12, 24, 48, 120] # 0.25, 0.5, 1, 2, 5 daysfor i in interval: for c in ['price', 'volume']: df[c+'_change_'+str(i)+'H'] = df[c]/df[c].shift(i)-1 df[c+'_high_'+str(i)+'H'] = df[c].rolling(i).max().shift(1) / df[c] df[c+'_low_'+str(i)+'H'] = df[c].rolling(i).min().shift(1) / df[c] df[c+'_avg_'+str(i)+'H'] = df[c].rolling(i).mean().shift(1) / df[c] df[c+'_std_'+str(i)+'H'] = df[c].rolling(i).std().shift(1) / df[c] * np.sqrt(24/i)df.dropna(inplace=True)disp(df.head()) price volume tr price_change_6H price_high_6H price_low_6H price_avg_6H price_std_6H volume_change_6H volume_high_6H volume_low_6H volume_avg_6H volume_std_6H price_change_12H price_high_12H price_low_12H price_avg_12H price_std_12H volume_change_12H volume_high_12H volume_low_12H volume_avg_12H volume_std_12H price_change_24H price_high_24H price_low_24H price_avg_24H price_std_24H volume_change_24H volume_high_24H volume_low_24H volume_avg_24H volume_std_24H price_change_48H price_high_48H price_low_48H price_avg_48H price_std_48H volume_change_48H volume_high_48H volume_low_48H volume_avg_48H volume_std_48H price_change_120H price_high_120H price_low_120H price_avg_120H price_std_120H volume_change_120H volume_high_120H volume_low_120H volume_avg_120H volume_std_120H time 2017-07-06 00:00:00 2607.823311 233.619901 0.0102 0.005149 1.001294 0.994877 0.998116 0.005057 -0.539692 2.172459 1.271991 1.710225 0.606196 0.019447 1.001294 0.980924 0.991722 0.010182 -0.137448 2.604881 0.986408 1.724699 0.659083 0.012479 1.001294 0.973805 0.985347 0.008630 -0.708220 3.444264 0.815879 1.940980 0.748083 0.019561 1.008966 0.973805 0.990540 0.006865 0.552344 4.357035 0.644187 1.832178 0.620839 0.054336 1.008966 0.916032 0.966001 0.011353 0.163482 8.713623 0.498690 1.772706 0.491582 2017-07-06 01:00:00 2592.974565 229.561261 0.0102 -0.005044 1.007028 1.001879 1.004691 0.004088 -0.415935 1.872772 1.017680 1.541597 0.657009 0.011195 1.007028 0.988929 0.999000 0.009511 -0.622775 2.650935 1.003848 1.741677 0.698711 0.011259 1.007028 0.979381 0.991506 0.009179 -0.707043 3.505159 0.830303 1.872374 0.713401 0.009083 1.014744 0.979381 0.996615 0.006895 0.168152 4.434067 0.830303 1.872115 0.625493 0.052367 1.014744 0.921278 0.971965 0.011479 0.003091 8.867680 0.507507 1.805239 0.499861 2017-07-06 02:00:00 2595.240970 111.498601 0.0102 -0.005029 1.006148 0.999127 1.002969 0.005542 -0.624789 3.855797 2.058871 2.929583 1.561810 0.009963 1.006148 0.989687 0.999049 0.008379 -0.765640 4.551893 2.058871 3.302634 1.296594 0.016319 1.006148 0.978526 0.991104 0.009312 -0.861432 7.216670 1.709488 3.647934 1.347291 0.000808 1.013858 0.978526 0.995932 0.006872 -0.870219 9.129174 1.709488 3.860618 1.283035 0.063050 1.013858 0.920474 0.971530 0.011491 -0.765300 18.257410 1.044891 3.716808 1.029132 2017-07-06 03:00:00 2601.939179 154.465403 0.0102 0.001575 1.003558 0.996555 0.999547 0.005543 -0.640708 2.783251 0.721835 1.914348 1.612821 0.013029 1.003558 0.987139 0.997297 0.007360 -0.329707 3.285718 0.721835 2.187443 1.098140 0.017659 1.003558 0.976007 0.989220 0.009328 -0.719538 4.131480 0.721835 2.446232 0.882973 -0.004151 1.011248 0.976007 0.993385 0.006859 -0.848249 6.589761 0.721835 2.685895 0.903309 0.062422 1.011248 0.918104 0.969522 0.011449 -0.131612 13.178846 0.721835 2.663309 0.746976 2017-07-06 04:00:00 2594.198903 323.934946 0.0102 -0.006510 1.006553 0.999528 1.002792 0.005453 -0.093037 1.273228 0.344201 0.771118 0.713993 0.006701 1.006553 0.993343 1.001348 0.005868 -0.345152 1.566764 0.344201 1.023516 0.558260 0.021535 1.006553 0.978919 0.992897 0.009496 -0.492401 1.970058 0.344201 1.115490 0.427613 -0.005803 1.014265 0.978919 0.996261 0.006822 0.102404 2.598252 0.344201 1.225214 0.392388 0.057479 1.014265 0.920843 0.972906 0.011490 1.679001 6.284212 0.344201 1.269372 0.356447 PCADue to the large number of features created in the last step, we use PCA to reduce the dimensionality of the data. Aside from price, 15 other principal components are retained. Since we mostly care about predicting accuracy, therefore we are okay with losing some interpretability in the PCA process. 12345X = StandardScaler().fit_transform(df.iloc[:, 3:])comp = 15pca = PCA(n_components=comp)X_pca = pca.fit_transform(X)np.round(pca.explained_variance_ratio_, 2) array([0.29, 0.23, 0.13, 0.06, 0.05, 0.03, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01]) 1np.round(np.sum(pca.explained_variance_ratio_), 2) 0.93 123df_pca = pd.DataFrame(X_pca, index=df.index, columns = ['PC' + str(i) for i in range(1, comp+1)])df = pd.DataFrame(df.iloc[:, 0:3]).join(df_pca)disp(df.head()) price volume tr PC1 PC2 PC3 PC4 PC5 PC6 PC7 PC8 PC9 PC10 PC11 PC12 PC13 PC14 PC15 time 2017-07-06 00:00:00 2607.823311 233.619901 0.0102 1.204847 -1.442388 -0.936078 0.562964 -1.802252 -0.126177 -2.115852 0.258446 0.547159 -0.005956 -0.345683 -0.077257 -0.389290 -0.253596 0.501094 2017-07-06 01:00:00 2592.974565 229.561261 0.0102 1.072486 -0.509851 -1.208146 1.100969 -1.991122 0.106322 -1.995090 0.089313 0.690748 -0.003055 -0.152291 -0.266696 -0.403753 -0.415290 0.602009 2017-07-06 02:00:00 2595.240970 111.498601 0.0102 6.313332 0.286169 -0.274636 1.772318 -3.465762 0.816421 -5.245687 0.737407 1.652572 0.043234 0.118171 -0.658779 -0.606447 -0.557087 0.499793 2017-07-06 03:00:00 2601.939179 154.465403 0.0102 1.986983 -0.820551 -1.195466 0.697308 -1.574198 0.289253 -1.100313 0.593288 0.655685 -0.005791 -0.018679 -0.152047 -0.354950 -0.493463 0.640942 2017-07-06 04:00:00 2594.198903 323.934946 0.0102 -1.350755 -0.873287 -1.805126 0.663435 -0.972641 0.036059 -0.009574 0.000981 0.200082 0.315963 -0.225084 -0.120908 -0.308701 -0.390018 0.597231 ModelingTrain and test sets are created for modeling purpose. Since it is time series data, randomization will not be performed. Rather, both train and test sets are chosen such that they both include a market upturn and market downturn. 12train = df.loc['2017-07-01':'2018-06-30']test = df.loc['2018-07-01':'2019-06-30'] Here we specify some modeling parameters. The trading frequency is set to one day. 12345trade_interval = '1H'trade_interval_min = 60ann_factor = 24 * 365training_threshold = 0.0075transaction_fee = 0.0025 Create a model engine that fit the train data and use grid search CV to tune the parameter grid. A long trade will be executed only if the model predict a next-5-day up move in the last 24 consecutive hours. This limits the frequency of trade which reduce the impact of the relatively large transaction fee per trade. The training threshold is set to 75 bps, which means the model is train to identify a potential up move of more than 75 bps in the next 5 days. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def run_model(Model, model_name, param, param_init, param_grid, search=False): # prepare data train_copy = train.resample(trade_interval).first() test_copy = test.resample(trade_interval).first() train_copy.dropna(inplace=True) test_copy.dropna(inplace=True) indicator = 24 # hr offset = 120 # hr X_train = train_copy.iloc[:-offset, 3:] Y_train = (train_copy.price.shift(-offset)/train_copy.price)[:-offset] &gt; (1 + training_threshold) X_test = test_copy.iloc[:-offset, 3:] Y_test = (test_copy.price.shift(-offset)/test_copy.price)[:-offset] &gt; (1 + training_threshold) # run model if search: model = GridSearchCV(estimator=Model(**param_init), cv=KFold(n_splits=5, random_state=0), scoring='precision', param_grid=param_grid).fit(X_train, Y_train) print(f'cv precision: &#123;round(model.best_score_, 2)&#125;, best param: &#123;model.best_params_&#125;') else: model = Model(**param).fit(X_train, Y_train) Y_pred = model.predict(X_test) cm = confusion_matrix(Y_test, Y_pred) precision = round(cm[1][1]/(cm[1][1] + cm[0][1]), 2) # calculate pnl # test_copy['ind'] = np.append(Y_pred, False) # test_copy['pnl'] = test_copy.ind * (test_copy.price.shift(-1) / test_copy.price) test_copy['pred'] = np.append(Y_pred, [False] * offset) test_copy['ind'] = test_copy.pred.rolling(indicator).sum() == indicator test_copy['buy'] = test_copy.ind.rolling(offset).sum() &gt; 0 test_copy['pnl'] = test_copy.buy * (test_copy.price.shift(-1) / test_copy.price) test_copy.pnl.replace(0, 1, inplace=True) test_copy.dropna(inplace=True) test_copy['fee'] = np.where(test_copy.ind != test_copy.ind.shift(1), 1-transaction_fee, 1) test_copy.pnl *= test_copy.fee test_pnl = round(test_copy.pnl.cumprod()[-1], 2) test_spr = round(np.mean(test_copy.pnl - 1 - test_copy.tr/(ann_factor)) / (test_copy.pnl - 1).std() * np.sqrt(ann_factor), 2) print(f'test precision: &#123;precision&#125;; pnl: &#123;test_pnl&#125;, spr: &#123;test_spr&#125;') return test_copy.pnl, precision, test_pnl, test_spr Baseline12345678910baseline = test.resample(trade_interval).first()baseline['pnl'] = baseline.price / baseline.price.shift(1) - 1baseline_pnl = round(baseline.price.iloc[-1] / baseline.price.iloc[0], 2)baseline_spr = round(np.mean(baseline.pnl - baseline.tr/(ann_factor)) / baseline.pnl.std() * np.sqrt(ann_factor), 2)result = test[['price']].copy().rename(&#123;'price': 'Baseline'&#125;, axis=1)/test.price.iloc[0]*1000comp = pd.DataFrame(&#123;'Strategy': 'Baseline', 'Precision': 'NA', 'P&amp;L': baseline_pnl, 'Sharpe Ratio': baseline_spr&#125;, index=[0])print(f'test precision: &#123;np.NaN&#125;; pnl: &#123;baseline_pnl&#125;, spr: &#123;baseline_spr&#125;') test precision: nan; pnl: 1.69, spr: 1.14 Logistic Regression12345678910111213Model = LogisticRegressionmodel_name = 'Logistic Regression'param = &#123;'class_weight':'balanced', 'solver':'liblinear', 'random_state': 0, 'C': 0.001, 'penalty': 'l2'&#125;param_init = &#123;'random_state': 0, 'class_weight': 'balanced'&#125;param_grid = &#123;'C': [1e-2, 1e-1, 1, 10], 'penalty': ['l1', 'l2']&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.52, best param: {‘C’: 0.01, ‘penalty’: ‘l1’}test precision: 0.47; pnl: 1.14, spr: 0.47 Linear Discriminant Analysis123456789Model = LinearDiscriminantAnalysismodel_name = 'Linear Discriminant Analysis'param = &#123;'solver': 'svd', 'n_components': None&#125;param_init = &#123;&#125;param_grid = &#123;'solver': ['svd', 'lsqr'], 'n_components': [None, 5, 10, 25]&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.5, best param: {‘n_components’: None, ‘solver’: ‘svd’}test precision: 0.47; pnl: 0.85, spr: -0.17 KNN123456789Model = KNeighborsClassifiermodel_name = 'KNN'param = &#123;'p': 2, 'leaf_size': 2, 'n_neighbors': 100&#125;param_init = &#123;'p': 2&#125;param_grid = &#123;'n_neighbors': [5, 25, 100], 'leaf_size': [2, 25, 100]&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.53, best param: {‘leaf_size’: 2, ‘n_neighbors’: 100}test precision: 0.5; pnl: 1.95, spr: 1.85 Decision Tree1234567891011Model = DecisionTreeClassifiermodel_name = 'Decision Tree'param = &#123;'random_state':0, 'criterion': 'gini', 'max_depth': None, 'max_features': 10&#125;param_init = &#123;'random_state':0&#125;param_grid = &#123;'criterion': ['gini', 'entropy'], 'max_depth': [None, 5, 10, 25], 'max_features': [None, 'auto', 5, 10]&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.53, best param: {‘criterion’: ‘gini’, ‘max_depth’: 10, ‘max_features’: 5}test precision: 0.49; pnl: 1.61, spr: 1.84 Random Forest12345678910111213141516Model = RandomForestClassifiermodel_name = 'Random Forest'param = &#123;'class_weight':'balanced', 'random_state': 0, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 5, 'n_estimators': 200&#125;param_init = &#123;'class_weight':'balanced', 'random_state': 0, 'n_estimators': 200&#125;param_grid = &#123;'criterion': ['gini', 'entropy'], 'max_depth': [5, 25], 'max_features': [5, 10]&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.53, best param: {‘criterion’: ‘gini’, ‘max_depth’: 5, ‘max_features’: 10}test precision: 0.53; pnl: 1.55, spr: 1.16 AdaBoost123456789Model = AdaBoostClassifiermodel_name = 'AdaBoost'param = &#123;'random_state': 0, 'algorithm': 'SAMME.R', 'n_estimators': 200, 'learning_rate': 0.1&#125;param_init = &#123;'random_state': 0, 'algorithm': 'SAMME.R', 'n_estimators': 200&#125;param_grid = &#123;'learning_rate': [1e-2, 1e-1, 1, 10]&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.52, best param: {‘learning_rate’: 0.01}test precision: 0.5; pnl: 0.86, spr: -0.09 Gradient Boost1234567891011121314Model = GradientBoostingClassifiermodel_name = 'Gradient Boost'param = &#123;'random_state': 0, 'warm_start': True, 'n_estimators': 200, 'max_depth': 10, 'max_features': 10, 'learning_rate': 0.1&#125;param_init = &#123;'random_state': 0, 'warm_start': True, 'n_estimators': 200,&#125;param_grid = &#123;'max_depth': [5, 25], 'max_features': [5, 10], 'learning_rate': [1e-2, 1e-1, 1, 10]&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.54, best param: {‘learning_rate’: 10, ‘max_depth’: 5, ‘max_features’: 5}test precision: 0.48; pnl: 1.06, spr: 0.33 XGBoost1set_start_method('forkserver', force=True) # enabling multi-threading 12345678910111213141516Model = XGBClassifiermodel_name = 'XGBoost'param = &#123;'n_jobs':4, 'seed':0, 'n_estimators': 200, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 10, 'learning_rate': 0.01&#125;param_init = &#123;'n_jobs':4, 'seed':0, 'n_estimators': 200&#125;param_grid = &#123;'max_depth': [5, 25], 'min_child_weight': [1, 5], 'gamma': [1e-2, 1e-1, 1, 10], 'learning_rate': [1e-2, 1e-1, 1, 10]&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.52, best param: {‘gamma’: 10, ‘learning_rate’: 0.01, ‘max_depth’: 25, ‘min_child_weight’: 1}test precision: 0.52; pnl: 1.33, spr: 0.86 SVC12345678910Model = SVCmodel_name = 'SVC'param = &#123;'probability':True, 'class_weight':'balanced', 'C': 10, 'gamma': 0.01&#125;param_init = &#123;'probability':True, 'class_weight':'balanced'&#125;param_grid = &#123;'C': [1e-2, 1e-1, 1, 10], 'gamma': [1e-2, 1e-1, 1, 10]&#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.64, best param: {‘C’: 0.1, ‘gamma’: 1}test precision: 0.47; pnl: 1.31, spr: 0.73 MLP Classificer12345678910111213141516Model = MLPClassifiermodel_name = 'MLP Classifier'param = &#123;'random_state': 0, 'hidden_layer_sizes': (25, 25), 'alpha': 0.01&#125;param_init = &#123;'random_state': 0&#125;param_grid = &#123;# 'hidden_layer_sizes': [x for x in itertools.product((5, 25, 100),repeat=2)], 'alpha' : [1e-2, 1e-1, 1, 10], # 'activation' : ['identity', 'logistic', 'tanh', 'relu'], # 'solver' : ['lbfgs', 'sgd', 'adam'], # 'learning_rate' : ['constant', 'invscaling', 'adaptive'], # 'max_itr' : [100, 200, 1000] &#125;a, b, c, d = run_model(Model, model_name, param, param_init, param_grid, search=True)result = result.join(a.cumprod() * 1000).rename(&#123;'pnl': model_name&#125;, axis=1).dropna()comp = comp.append(&#123;'Strategy': model_name, 'Precision': b, 'P&amp;L': c, 'Sharpe Ratio': d&#125;, ignore_index=True) cv precision: 0.53, best param: {‘alpha’: 1}test precision: 0.55; pnl: 2.06, spr: 1.79 ResultThe results are summarized as follow. 1disp(comp.replace('NA', 0).sort_values('P&amp;L', ascending=False), 20) Strategy Precision P&amp;L Sharpe Ratio 10 MLP Classifier 0.55 2.06 1.79 3 KNN 0.50 1.95 1.85 0 Baseline 0.00 1.69 1.14 4 Decision Tree 0.49 1.61 1.84 5 Random Forest 0.53 1.55 1.16 8 XGBoost 0.52 1.33 0.86 9 SVC 0.47 1.31 0.73 1 Logistic Regression 0.47 1.14 0.47 7 Gradient Boost 0.48 1.06 0.33 6 AdaBoost 0.50 0.86 -0.09 2 Linear Discriminant Analysis 0.47 0.85 -0.17 Plotting the cumulative return for each strategy with transaction fee reflected. 123456plt.plot(result)plt.legend(result.columns, frameon=False)plt.xticks(rotation=30)plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(30))plt.ylabel('Cumulative Value Based on $1000 Investment')plt.show()","tags":"tech"},{"title":"Bitcoin Quant Strategies","url":"/2019/07/algo/","text":"01. Classification Methods02. Momemtum03. Perpectual Swap Funding","tags":"tech"},{"title":"Pricing A Variance Swap","url":"/2019/07/variance-swap/","text":"Let’s look at how risk-neutral pricing of a variance swap can be constructed with this elegant formula: \\sigma^2_{strike} = \\dfrac{2e^{rT}}{T}\\Bigg[\\int_0^{S_0e^{rT}} \\dfrac{1}{K^2} P(K) dK + \\int^{\\infty}_{S_0e^{rT}} \\dfrac{1}{K^2}C(K)dK\\Bigg]Static Portfolio Replicationproposition Let f:(0, \\infty)\\rightarrow\\mathbb{R} be twice continuous differentiable so that for any k>0 and any s>0, then, f(s) = f(k) + f'(k)(s-k) + \\int_0^kf''(K)(K-s)^+dK + \\int_k^{\\infty}f''(K)(s-K)^+dKproof We will prove the case in which s>k; similar proof can be sketched for the other case. When s>k, we have \\int_0^kf''(K)(K-s)^+dK = 0. The the second integral can be simplified as: \\int_k^{\\infty}f''(K)(s-K)^+dK = \\int_k^sf''(K)(s-K)dKUsing integration by part: du = f''(K)dK ,\\;\\; v = s-K \\\\ \\rightarrow u = f'(K) ,\\;\\; dv = -dKAnd, \\begin{align} \\int_k^s vdu &= uv |^s_k - \\int_k^s udv \\\\ &= f'(K)(s-K) |^s_k - \\int_k^s -f'(K)dK \\\\ &= -f'(K)(s-k) + f(s) - f(k) \\;\\;\\square \\end{align} The above formula shows that any twice-differentiable continuous time-T payoff f(S_T) can be replicated using a static portfolio of: f(k) \\text{ zero-coupon bond} \\\\ f'(k) \\text{ forward at } k \\\\\\ f''(K) \\text{ puts across a continuum of strike } K \\text{ from } 0 \\text{ to } k \\\\ f''(K) \\text{ calls across a continuum of strike } K \\text{ from } k \\text{ to } \\inftyIn practice, discrete set of strike can be used to approximately replicate. For example, given S_0=100 and payoff function f(S_T) = \\log S_T. Here we choose to replicate with k=100 (Though we can theoretically replicate the payoff f with any k\\in(0, \\infty), a k close to S_0 is typically chosen) and a discrete set of option strikes with increment of 5 capping at 200. In this replicating portfolio we will hold: \\log 100 \\text{ zero-coupon bond} \\\\ \\dfrac{1}{100} \\text{ forward at } 100 \\\\ -\\dfrac{5}{97.5^2} \\text{ put striked at } 97.5 \\\\ \\vdots \\\\ -\\dfrac{5}{2.5^2} \\text{ put striked at } 2.5 \\\\ \\text{and} \\\\ -\\dfrac{5}{102.5^2} \\text{ call striked at } 102.5 \\\\ \\vdots \\\\ -\\dfrac{5}{197.5^2} \\text{ put striked at } 197.5 \\\\Variance SwapA variance swap is an over-the-counter financial derivative that allows a party to trade on the future variance of a given underlying security. For example, a trader would pay the realized variance of log-price changes in exchange of a fixed payment called variance strike, normalized by the vega notional into dollar terms. The payoff of the VS is: \\text{Payoff (VS)} = N(\\sigma^2_{realized} - \\sigma^2_{strike})We can calculate the variance strike which results in a zero discounted expectation of the payoff (per unit of vega notional). \\sigma^2_{strike} = \\mathbb{E}\\sigma^2_{realized}Assuming that the underlying process follows a geometric Brownian motion with local volatility \\sigma_t: \\dfrac{dS_t}{S_t} = \\mu_t dt + \\sigma_t dW \\\\ \\rightarrow d\\log S_t = (\\mu_t - \\sigma_t^2/2)dt + \\sigma_t dW \\\\ \\rightarrow logS_T \\sim \\mathcal{N}(logS_0 + rT -\\dfrac{1}{2} \\int_0^T \\sigma^2_tdt, \\;[\\dfrac{1}{T}\\int_0^T \\sigma^2_tdt]\\;T)Therefore the realized variance of \\log S_T is: \\sigma^2_{realized} = \\dfrac{1}{T}\\int_0^T \\sigma_t^2dtFurthermore, if we combine the SDE of dS_t and d\\log S_t, \\dfrac{dS_t}{S_t} - d\\log S_t = \\dfrac{\\sigma^2_t}{2}dtTaking integral on both sides, \\int_0^T\\dfrac{dS_t}{S_t} - \\log \\dfrac{S_T}{S_0} = \\int_0^T \\dfrac{\\sigma^2_t}{2}dtCombining with the formula for the realizead variance of \\log S_t, \\sigma^2_{realized} = \\dfrac{2}{T}[\\int_0^T\\dfrac{dS_t}{S_t} - \\log \\dfrac{S_T}{S_0}]Using the proposition proven above, we can create a static replication portfolio and replicate the \\log S_T payoff. \\begin{align} \\sigma^2_{strike} &= \\mathbb{E}\\sigma^2_{realized} \\\\ &= \\mathbb{E}\\{\\dfrac{2}{T}[\\int_0^T\\dfrac{dS_t}{S_t} - \\log \\dfrac{S_T}{S_0}]\\} \\\\ &= \\dfrac{2}{T}[rT - \\log \\dfrac{S^{\\ast}}{S_0} - \\dfrac{Se^{rT} - S^{\\ast}}{S^{\\ast}} - \\int_0^{S^{\\ast}} \\dfrac{-1}{K^2} (K-S_T)^+dK - \\int^{\\infty}_{S^{\\ast}} \\dfrac{-1}{K^2}(S_T-K)^+dK] \\end{align}If we choose the cutoff as the forward price S^{\\ast} = S_0e^{rT}, we can largely simplified the formula as follow: \\sigma^2_{strike} = \\dfrac{2e^{rT}}{T}[\\int_0^{S_0e^{rT}} \\dfrac{1}{K^2} P(K) dK + \\int^{\\infty}_{S_0e^{rT}} \\dfrac{1}{K^2}C(K)dK]In conclusion, if we assume a GBM underlying process, the fair-value variance strike can be calculated as the sum of calls and puts across a continuum of strikes. Practical ConsiderationIn practice, variance swap is costly to implement, requires constant hedging and an entire array of options. The advantage of a variance swap is that it is purely exposed to volatility risk, as oppose to an option which contains directional risk. The P&amp;L of a variance swap depends directly on the difference between realized and implied volatility. Since historically the implied volatility has been above realized volatility, a.k.a. variance risk premium, volatility arbitrage (rolling short variance trade) can be carried out with variance swaps. Reference Variance and Volatility Swaps, FinancialCAD Corporation, http://docs.fincad.com/support/developerFunc/mathref/VarianceSwaps.htm","tags":"math"},{"title":"Term Structure of Volatility under Black-Scholes","url":"/2019/06/spx-vol-term-struct/","text":"In this research, we extracted a term structure from the implied volatility skewness under the Black-Scholes framework and S&amp;P 500 adjusted close prices. With the daily close prices over the period of 1970-2018, we calibrated a local volatility function by fitting the BS-implied density based on the Dupire formula (which is the aggregation of a bunch of log-normal densities at each strike, since volatility is not constant and depended on strike) to the observed S&amp;P 500 log return distribution. We started by assuming that the local volatility is a function of the log-in-the-moneyness x for a fixed maturity window of T business days. \\sigma(x) = g(x) \\\\ \\text{ where } x=log(K/S_0)Under the Black-Scholes framework with risk-free rate r=0, a call option premium for S_0=1 is: C(K, T) = \\Phi(d1) - K\\Phi(d2) \\\\ d_{\\text{1, 2}} = \\dfrac{log(1/K) \\pm (\\sigma^2/2)T}{\\sigma\\sqrt{T}}If we assume that there exists a probability density function f_{S_T}, we have: C(K, T) = \\int^{\\infty}_K(S_T-K)f_{S_T}(S_T)dS_TTaking partial derivative w.r.t. K, we get the Dupire formula: \\dfrac{\\partial C}{\\partial K} = \\int^{\\infty}_K -f_{S_T}(S_T)dS_T \\\\ \\dfrac{\\partial^2 C}{\\partial K^2} = f_{S_T}(K)We can approximate the second-order derivative numerically: f_{S_T}(K) \\approx \\dfrac{C(K + \\Delta K) - 2C(K) + C(K - \\Delta K)}{(\\Delta K)^2}We previously defined that x = log(K). Given any \\Delta K, let us define \\Delta x such that: \\Delta x = \\dfrac{\\Delta K}{K} \\\\ \\text{therefore, } \\Delta K = e^{x}\\Delta xWe defined r_T as the T period log return, and that r_T=log(S_T). Based on chain rule: f_{r_T}(x) = f_{S_T}(K) \\times KSo in conclusion we have: f_{r_T}(x) = f_{S_T}(K) \\times K \\approx \\dfrac{C(e^x + e^x\\Delta x) - 2C(e^x) + C(e^x - e^x\\Delta x)}{e^x(\\Delta x)^2} \\\\ \\text{where } C(x) = \\Phi(\\dfrac{-x + (\\sigma(x)^2/2)T}{\\sigma(x)\\sqrt{T}}) - e^x\\Phi(\\dfrac{-x - (\\sigma(x)^2/2)T}{\\sigma(x)\\sqrt{T}}) \\text{, and } \\sigma(x) = g(x)The goal was to find the optimal volatility function g(x) such that f_{r_T}(x) fits to the historical distribution of r_T. Here we use a quadratic form for g(x): g(x) = ax^2 + bx + cUsing sum of square as the objective function, we obtained a set of coefficients of a, b, and c that fit the Dupire density to the empirical density of S&amp;P 500 log returns. This following graph shows the skewness coefficient b plotted against term windows. We observed that overall as the time-window increases, the skewness decreases (in absolute values), and that the skewness reaches a local minimum (in absolute values) at T=100, or 6 month time. Coincidentally, this is observed in futures trading - potentially explained by the fact that market tends to recover from the left-skewed losses in 6 month time on average.","tags":"math"},{"title":"&#128214; Notes on ISLR","url":"/2019/04/islr/","text":"This is a study note on the book An Introduction to Statistical Learning with Applications in R, with my own experimental R-code for each topic. Cheers! Navigation00. Introduction01. Linear Model02. Tree-Based Method03. Unsupervised Learning04. PCA - A Deeper Dive05. A Side Note on Hypothesis Test and Confidence Interval Introduction &#8634;Suppose we observe a quantitative response Y and p different predicting variables X = (X_1, X_2...X_p). We assume that there is a underlying relationship f between Y and X: Y=f(X) + \\epsilonWe want to estimate f mainly for two purpose: prediction: in the case where Y is not easily obtained, we want to estimate f with \\hat{f}, and use \\hat{f} to predict Y with \\hat{Y}. Here \\hat{f} can be a black box, such as highly non-linear approaches which offers accuracy over interpretability. \\hat{Y} = \\hat{f}(X) inference: in the case where we are more interested in how Y is affected by the change in each X_n. We need to know the exact form of \\hat{f}. For example, linear model is often used which offer interpretable inference but sometimes inaccurate. FeatureThere are important and subtle differences between a feature and a variable. variable: raw data feature: data that is transformed, derived from raw data. A feature can be more predictive and have a direct relationship with the target variable, but it isn’t immediately represented by the raw variable. The need for feature engineering arises from limitations of modeling algorithms: the curse of dimensionality (leading to statistical insiginificance) the need to represent the signal in a meaningful and interpretable way the need to capture complex signals in the data accurately computational feasibility when the number of features gets large. Feature TransformationThe Occam’s Razor principle states that a simpler solutions are more likely to be corret than complex ones. Consider the following example of modeling a exponentially distributed response. After applying a log transformation, we can view the relation from a different viewpoint provided by the new feature space, in which a simpler model may achieve more predictive power than a complex model in the original input space.123456789x1 &lt;- runif(100, 1,10)x2 &lt;- exp(x1)df &lt;- data.frame(x1 = x1, x2 = x2)df$logx2 &lt;- log(df$x2)ssoptions(repr.plot.width=6, repr.plot.height=3)p1 &lt;- ggplot(data = df, aes(x = x1, y = x2)) + geom_point(size=0.3)p2 &lt;- ggplot(data = df, aes(x = x1, y = logx2)) + geom_point(size=0.3)grid.arrange(p1, p2, nrow=1) Consider another classification problem, in which we want to identify the boundary between the two classes. A complex model would draw a circle as the divider. A simpler approach would be to create a new feature with distances of each point from the origin. The divider becomes a much simpler straight line.123456789101112131415161718x1 &lt;- runif(1000,-1,1)x2 &lt;- runif(1000,-1,1)class &lt;- ifelse(sqrt(x1^2 +x2^2) &lt; 0.5, \"A\", \"B\")df &lt;- data.frame(x1 = x1, x2 = x2, class = class)p1 &lt;- ggplot(data = df, aes(x = x1, y = x2, color = class)) + geom_point(size=1)df$dist_from_0 &lt;- sqrt(df$x1^2 + df$x2^2)p2 &lt;- ggplot(data = df, aes(x = 0, y = dist_from_0, color = class)) + geom_point(position = \"jitter\", size=1) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) + annotate(\"segment\", x = -0.5, xend = 0.5, y = 0.5, yend = 0.5)options(repr.plot.width=8, repr.plot.height=3)grid.arrange(p1, p2, nrow=1) Feature SelectionFor p predictive variables, there are a total of 2^p models. We use feature selection to choose a smaller subset of the variable to model. Forward Selection We begin with the null model with no variables and an intercept. We then fit n simple linear regression to choose our first variable with the lowest RSS. Same way to choose the next variable to be added until some stoppoing rule. Backward Selection We begin with the full model and remove the variable with the largest coefficient p-value. Re-fit and remove the next. Mixed Selection We begin with the null model and the forward selection technique. Whenever the p-value for a variable exceeds a threshold we remove it. Regression ProblemsIn regression problems the variables are quantitative, we use mean squared error, or MSE, to measure the quality of estimator \\hat{f}: MSE = \\dfrac{\\sum_{i=1}^n [y_i - \\hat{f}(x_i)]^2}{n}A fundamental property of statistical learning that holds regardless of the particular dataset and statistical method is that as model flexibility increases, we can observe a monotone decrease in training MSE and an U-shape in test MSE. Bias vs VarianceThe bias-variance trade off decompose the expected test MSE of a single data point x_0: \\begin{align} \\mathbb{E}MSE^{test}(x_0) &= \\mathbb{E}[y_0 - \\hat{f}(x_0)]^2 \\\\ &= Var[\\hat{f}(x_0)] + Bias[\\hat{f}(x_0)]^2 + Var[\\epsilon] \\end{align}where: variance refers to the variance of the estimator among different datasets. A highly flexible \\hat{f} lead to a high variance, as even small variance in data induce change in the \\hat{f}‘s form. bias refers to the error due to estimator \\hat{f} inflexibility. For example, using linear \\hat{f} to estimate non-linear relationship leads to high bias. Classification ProblemsIn regression problems the variables are qualitative, we use error rate to measure the quality of estimator \\hat{f}: \\text{error rate} = \\dfrac{\\sum_{i=1}^n \\textbf{1}\\{y_i \\neq \\hat{f}(x_i)\\}}{n}The Bayes ClassifierThe Bayes classifier predict the classification based on the combination of the prior probability and its likelihood given predictor values. With categories C_1, C_2, C_3..., and predictor values \\textbf{x} = (x_1, x_2, x_3...), \\hat{y} is assigned to category C_k which has the maximum posterior probability: \\hat{y} = \\hat{f}^{Bayes}(\\textbf{x}) = C_k, \\;where\\; k = argmax_k \\;p(C_k | \\textbf{x})Where: p(C_k | \\textbf{x}) = \\dfrac{p(x_1, x_2, x_3...|C_k)p(C_k)}{p(x_1, x_2, x_3...)}The naive Bayes classifier assumes independence between the predictor X_i‘s, and the formula becomes: \\hat{y} = \\hat{f}^{naiveBayes}(\\textbf{x}) = C_k, where\\; k = argmax_k \\;p(C_k) \\times \\prod p(x_i | C_k)When x_i is continuous, the Guassian naive Bayes classifier assumes that p(x_i | C_k) \\sim \\mathcal{N}(\\mu_{i, C_k}, \\sigma^2_{i, C_k}) In R, we use the naiveBayes function from the e1071 package to predict Survival from the Titanic dataset.1234567891011121314151617181920library(e1071)library(caret)set.seed(9999)df=as.data.frame(Titanic)df &lt;- df[rep.int(seq_len(nrow(df)), df$Freq),]df$Freq &lt;- NULL# create a 75/25 train/test splitpartition &lt;- createDataPartition(df$Survived, list=FALSE, p=0.75)train &lt;- df[partition, ]test &lt;- df[-partition, ]# fit naive bayes classifierbayes &lt;- naiveBayes(Survived ~ ., data=train)# 10-fold validationbayes.cv &lt;- train(Survived ~ ., data=train, method = \"nb\", trControl = trainControl(method = \"cv\", number = 10)) Viewing the model results, the prior probabilities p(C_k) are shown in the “A-priori probabilities” section.1234567891011&gt; bayesNaive Bayes Classifier for Discrete PredictorsCall:naiveBayes.default(x = X, y = Y, laplace = laplace)A-priori probabilities:Y No Yes0.6767554 0.3232446 The likelihood p(x_i | C_k) are shown in the “Conditional probabilities” section123456789101112131415Conditional probabilities: ClassY 1st 2nd 3rd Crew No 0.09481216 0.10554562 0.34615385 0.45348837 Yes 0.28838951 0.15730337 0.24344569 0.31086142 SexY Male Female No 0.91323792 0.08676208 Yes 0.53183521 0.46816479 AgeY Child Adult No 0.03130590 0.96869410 Yes 0.06928839 0.93071161 The confusionMatrix function from the caret package returns a test Accuracy of 0.7978, which corresponds to an Bayes error rate of 0.2023. \\text{error rate}^{Bayes} = 1 - \\mathbb{E}max_k\\;p[Y=C_k|X=(x_1, x_2, x_3...)]Theoretically, the Bayes classifier produces the lowest error rate if we know the true conditional probability p(C_k | \\textbf{x}), which is not the case with real data. Therefore, the Bayes classifier serves as an unattainable gold standard against which to compare other methods.123456789&gt; confusionMatrix(predict(bayes, test), test$Survived)Confusion Matrix and Statistics ReferencePrediction No Yes No 343 82 Yes 29 95 Accuracy : 0.7978 With 10-fold cross validation, the test error rate is 0.2095.123456789&gt; confusionMatrix(predict(bayes.cv, test), test$Survived)Confusion Matrix and Statistics ReferencePrediction No Yes No 332 75 Yes 40 102 Accuracy : 0.7905 K-Nearest NeighborsThe KNN classifier estimate the conditional probability p(C_k | \\textbf{x}) based on the set of K predictors in the training data that are the most similar to \\textbf{x}, representing by \\mathcal{N}. \\hat{y} = \\hat{f}^{KNN}(\\textbf{x}) = C_k, \\;where\\; k = argmax_k \\;p(C_k | \\textbf{x}) \\\\ with\\; p(C_k | \\textbf{x}) = \\dfrac{\\sum_{i\\in\\mathcal{N}}\\textbf{1}_{y_i = C_k}}{K}Note that the p(C_k | \\textbf{x}) is one minus the \\mathcal{N}-local error rate of a C_k estimate , and therefore with KNN we are picking the C_k that minimizes the \\mathcal{N}-local error rate given \\textbf{x}. When K=1, the estimator \\hat{f}^{KNN} produces a training error rate of 0, but the test error rate might be quite high due to overfitting. The method is therefore very flexible with low bias and high variance. As K\\rightarrow\\infty, the estimator becomes more linear. In R, we use the knn function (with K=1) in the class library to predict Survival from the Titanic dataset.1234567891011121314151617181920212223242526272829303132library(e1071)library(class)set.seed(9999)df &lt;- as.data.frame(Titanic)df &lt;- df[rep.int(seq_len(nrow(df)), df$Freq),]df$Freq &lt;- NULL# The \"knn\" function in the \"class\" library only works with numeric datadf$iClass &lt;- as.integer(df$Class)df$iSex &lt;- as.integer(df$Sex)df$iAge &lt;- as.integer(df$Age)df$iSurvived &lt;- as.integer(df$Survived)# Create random 75/25 train/test splittrain_ind &lt;- sample(seq_len(nrow(df)), size = floor(0.75 * nrow(df)))df_train &lt;- df[train_ind, c(5:7)]df_test &lt;- df[-train_ind, c(5:7)]df_train_cl &lt;- df[train_ind, 4]df_test_cl &lt;- df[-train_ind, 4]# Fit KNNknn &lt;- knn(train = df_train, test = df_test, cl = df_train_cl, k=1)# 10-fold CVknn.cv &lt;- tune.knn(x = df[, c(5:7)], y = df[, 4], k = 1:20, tunecontrol=tune.control(sampling = \"cross\"), cross=10) The confusion matrix shows an error rate of 0.1942.123456789&gt; confusionMatrix(knn, df_test_cl)Confusion Matrix and Statistics ReferencePrediction No Yes No 364 101 Yes 6 80 Accuracy : 0.8058 Now run KNN with the tune wrapper to perform 10-fold cross validation. The result recommends KNN with K=1, which turns out to be the same as what we originally tested.1234567891011&gt; knn.cvParameter tuning of ‘knn.wrapper’:- sampling method: 10-fold cross validation- best parameters: k 1- best performance: 0.2157576 Summarizing the test error rate for naiveBayes and KNN.12naiveBayes (cv10): 0.2095KNN (cv10, K=1): 0.1942 Linear Model &#8634;Simple Linear RegressionA simple linear regression assumes that: Y \\sim \\beta_0 + \\beta_1XCoefficient EstimateGiven data points (x_i, y_i), let \\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}x_i. We define the residual sum of squares, or RSS, as: RSS = \\sum (y_i - \\hat{y_i})^2Minimizing RSS as an objective function, we can solve for \\hat{\\beta_0}, \\hat{\\beta_1}: \\begin{align} \\hat{\\beta_1} &= \\dfrac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i-\\bar{x})^2} \\\\ \\hat{\\beta_0} &= \\bar{y} - \\hat{\\beta_1}\\bar{x} \\end{align}Coefficient Estimate - Gaussian ResidualFurthermore, if we assume the individual error terms are i.i.d Gaussian, i.e.: Y = \\beta_0 + \\beta_1x + \\epsilon \\\\ \\text{where, } \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)We now have a conditional pdf of Y given x: p(y_i|x_i; \\beta_0, \\beta_1, \\sigma^2) = \\dfrac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\dfrac{[y_i - (\\beta_0 + \\beta_1x_i)]^2}{2\\sigma^2}}The maximum log-likelihood estimator \\hat{l}for the paramter estimate b_0, b_1, and s^2 can be computed as follow: \\begin{align} \\hat{l}(b_0, b_1, s^2| x_i, y_i) &= log \\prod p(y_i|x_i; b_0, b_1, s^2) \\\\ &= -\\dfrac{n}{2}log{2\\pi} - nlogs - \\dfrac{1}{2s^2}\\sum [y_i - (b_0+b_1x)]^2 \\end{align}Setting the partial-derivative of the estimator with respect to each of the parameter to zero, we can obtain the maximum likelihood parameters: \\begin{align} \\hat{\\beta_1} &= \\dfrac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i-\\bar{x})^2} \\\\ \\hat{\\beta_0} &= \\bar{y} - \\hat{\\beta_1}\\bar{x} \\\\ \\hat{\\sigma^2} &= \\dfrac{1}{n}\\sum [y_i - (b_0+b_1x_i)]^2 \\end{align}MLE, or maximum likelihood estimation, is a frequentist approach for estimating model parameters based on the assumed underlying model form and error distribution, by maximizing the probability of seeing what we saw in the data. MLE is a near-optimal method of estimation, and is optimal in many cases. If we assume a Gaussian error distribution and a linear model, then the conclusion above states that maximizing the MLE objective function is the SAME as minimizing the RSS objective function. More on frequentist vs Bayesian in this SOA work paper. Also see this CMU lecture note and for more detail regarding the derivation. Model FitRecall that we assume there is a underlying relationship f between Y and X: Y=f(X) + \\epsilonThe residual standard error, or RSE, estimates the standard deviation of \\epsilon. Note that RSE is an absolute measure of the lack of fit of the model and depends on units of Y. RSE = \\sqrt{RSS/(n-2)}The R^2 measures the proportion of variance explained by the regression. TSS is the total sum of squares which measures the total variance in Y R^2 = 1 - \\dfrac{RSS}{TSS}In a simple regression setting, R^2 = Corr(X, Y)^2 Residual PlotHere is a good article on how to interpret your residual plot. Summarizing the approaches for different residual issues: Y-axis Unbalanced: transform target X-axis Unbalanced: transform predictor Heteroscedasticity: transform target/predictor Non-Linearity: transform predictor; create non-linear model Outlier: transform target/predictor; remove/assess the outlier; Multiple Linear RegressionThe multiple linear regression takes the form: Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p + \\epsilonF-statisticWe use the F-statistic to test the null hypothesis that there are no relationships between the predictors and target variable. H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0 \\\\ H_a: \\text{ at least one } \\beta \\text{ is non-zero}We calculate the F-statistic as follow: F = \\dfrac{(TSS - RSS)/p}{RSS/(n-p-1)}We expect F=1 if H_0 is true. Potential ProblemsNon-Linearity Residual plots are useful to detect whether the underlying relationship f is non-linear. One of the solutions to this problem is to fit transformations of the predictors such as log{X}, \\sqrt{X}, and X^2. Collinearity This is where two or more predictors are closely correlated with each other, or “collinear”. Collinearity reduces the accuracy of the coefficient estimates by increasing its standard deviation and p-value. One way to detect collinearity is from the correlation matrix or the “pairs” plot in R. There are two solutions: dropping one of the collinear predictor, or combine the collinear predictors into a single predictor. Multi-collinearity This is where collinearity exist between three or more predictors when none of the pairwise correlations are high. The best way to assess multi-collinearity if through variance inflation factor, or VIF. VIF(\\beta_j) = \\dfrac{var(\\beta_j) \\text{ in full model}}{var(\\beta_j) \\text{ in single } \\beta_j \\text{ model}}A VIF of 1 indicates no collinearity. A VIF of 10+ indicates high collinearity. Outliers Use residual plot to detect and potentially remove outliers. Linear Model Selection and RegularizationLinear model can be improved by using alternative fitting procedures, which produce better prediction accuracy and model interpretability. Subset Selection Select a subset of the original predictors and then fit the model. Shrinkage/Regularization Fit the model by shrinking coefficient estimates towards zero, therefore reducing variances of the coefficient estimates. Dimension Reduction Project the predictors onto a M-dimensional subspace, then use the M projections as predictors to fit a linear model with least square. Subset SelectionThe beset subset selection fits a separate least square regression for each combination from the p predictors, creating 2^p models to compare. The forward stepwise selection and backward stepwise selection fits a total of 1+p(p+1)/2 models. Specifically, at each step a predictor is added/removed to the model only if it gives the greatest additional improvement (lowest RSS or highest adjusted R^2) among all the predictors. After the selection process, we need to determine the optimal model that gives the lowest potential test error, either through: Cross-validation, or Adjusted train error Example 1: \\boldsymbol{C_p} := \\dfrac{1}{n}(RSS + 2d\\hat{\\sigma}^2), where d is the number of predictors in the subset, and \\hat{\\sigma}^2 is the variance of error estimated using the full models containing all p predictors. Essentially, a penalty term 2d\\hat{\\sigma}^2 is added to the train RSS to adjust for the fact that the training error tends to underestimate the test error. Example 2: \\boldsymbol{AIC} = \\dfrac{1}{n\\hat{\\sigma}^2}(RSS + 2d\\hat{\\sigma}^2). The AIC, or Akaike information criterion, uses the maximum likelihood function to assess the relative quality of statistical models give a set of data. In linear models with Gaussian error terms, the maximum likelihood function is equivalent to RSS, and therefore C_p and AIC are proportional to each other. Example 3: \\boldsymbol{BIC} = \\dfrac{1}{n\\hat{\\sigma}^2}(RSS + log(n)d\\hat{\\sigma}^2) Example 4: \\boldsymbol{Adjusted}\\; \\boldsymbol{R^2} = 1 - \\dfrac{RSS/(n-d-1)}{TSS/(n-1)}. While RSS always decreases in the stepwise selection as the number of predictors increases, RSS/(n-d-1) may or may not decrease. ShrinkageRidge RegressionRecall that in least square regression, the coefficient \\beta are estimated by minimizing the objective function RSS. Objective\\ Function = RSS = \\sum (y_i - \\hat{y_i})^2In ridge regression, the objective function include an additional shrinkage penalty, where \\lambda>0 is a tuning parameter. Note that we do not want to shrink the intercept \\beta_0, which is simply a measure of the mean of the responses: Objective\\ Function = RSS + \\lambda\\sum_{i>0}\\beta_i^2 As \\lambda increases, the variance decreases and the bias increases. The model fit usually is improved initially as the variance decreases, but worsen at some point when bias starts to increases rapidly. Cross-validation is often used to select the optimal \\lambda. As \\lambda\\rightarrow\\infty, the coefficient approaches 0. The ridge regression works when the linear model has low bias and high variance, e.g. when the underlying relationship is close to linear. The ridge regression trades off a small increase in bias for large decrease in variance. Additionally, it is important to standardize all features when applying regularization. Imagining a feature in dollar and in thousand dollar: the model with the dollar feature will have much higher coefficient compared to the thousand dollar one, leading to larger regularization effect for the dollar feature. Lasso RegressionAlthough the ridge regression shrinks the coefficients, it does not eliminiate excess predictors. Model interpretation might be an issue for the ridge regression where the number of predictors are large. The lasso regression overcomes this issue and force some coefficients to be exactly 0. Objective\\ Function = RSS + \\lambda\\sum_{i>0}|\\beta_i|However, there are limitations of feature selections using regularization techniques such as lasso, such as model interpretability. In addition, the feature we selected are optimized in linear models, and may not necessarily translate to other model forms. Note the difference between L2 (ridge) and L1 (lasso) penalty: when the coefficients (absolute value) are greater than 1 (when the parameters are large), the L2 penalty is greater than the L1, and ridge provides more shrinkage. when the coefficients (absolute value) are smaller than 1 (when the parameters are small), the L1 penalty is greater than the L2, and lasso provides more shrinkage. In R, we use the glmnet package to compute ridge and lasso regressions to predict mpg from the mtcars built-in data set.1234567891011121314151617181920212223242526272829303132333435363738394041library(glmnet)library(caret)set.seed(9999)# datadf &lt;- as.data.frame(mtcars)x &lt;- model.matrix(mpg~., df)[, -1]y &lt;- df$mpg# 75/25 train/test splitpartition &lt;- createDataPartition(df$mpg, list = FALSE, p = .75)df_train &lt;- df[partition, ]df_test &lt;- df[-partition, ]x_train &lt;- x[partition, ]x_test &lt;- x[-partition, ]y_train &lt;- y[partition]y_test &lt;- y[-partition]# fit regressionm1 &lt;- lm(mpg ~ ., df_train)m1.pred &lt;- predict(m1, df_test)m1.mse &lt;- round(mean((y_test - m1.pred)^2), 2)# fit ridge regressionm2 &lt;- cv.glmnet(x_train, y_train, alpha=0, nfolds=6)m2.bestlambda &lt;- m2$lambda.minm2.pred &lt;- predict(m2, s=m2.bestlambda, x_test)m2.mse &lt;- round(mean((y_test - m2.pred)^2), 2)# fit lasso regressionm3 &lt;- cv.glmnet(x_train, y_train, alpha=1, nfolds=6)m3.bestlambda &lt;- m3$lambda.minm3.pred &lt;- predict(m3, s=m3.bestlambda, x_test)m3.mse &lt;- round(mean((y_test - m3.pred)^2), 2)# get coefficientsm2.best &lt;- glmnet(x_train, y_train, alpha=0, lambda=m2.bestlambda)m3.best &lt;- glmnet(x_train, y_train, alpha=1, lambda=m3.bestlambda)comp &lt;- cbind(coef(m1), coef(m2.best), coef(m3.best))colnames(comp) &lt;- c(\"original\", \"ridge\", \"lasso\") The test MSE are as follow. Note that both ridge and lasso regression perform better than the original regression.123456&gt; m1.mse[1] 16.64&gt; m2.mse[1] 3.66&gt; m3.mse[1] 6.61 We also made a comparison of the coefficients, based on the normal regression and the regularized regression with cv-optimal lambda.1234567891011121314&gt; comp11 x 3 sparse Matrix of class \"dgCMatrix\" original ridge lasso(Intercept) -19.52071389 19.420775180 14.002192375cyl 1.69431225 -0.275408324 . disp 0.01185998 -0.004705579 . hp -0.01449594 -0.011129305 -0.002545135drat 3.08676192 1.272808791 1.334526777wt -3.19280650 -1.137507747 -2.254408320qsec 1.02473436 0.117671597 0.331182874vs 0.97127211 0.677494227 . am 2.63740010 1.633418877 1.703501439gear 3.36943552 0.794847062 1.571031414carb -1.45443855 -0.588427657 -1.162118484 Resampling MethodResampling methods involve repeatedly drawing samples from a training set to re-fit the model. Cross-ValidationWe often use the test error rate to determine and compare how well a statistical learning model perform. However, in the absence of a large designated test set, the test error rate can be difficult to estimate. The train error rate is often quite different from the test error rate. Therefore, cross-validation can be used to estimate the test error rates by creating validation sets off the train data. A k-fold cross validation involves randomly dividing the observations into k-groups. The process is repeated k-times where each group is treated as a validation set while fitting the remaining k-1 groups. The k-fold CV test MSE is the average of all the MSE from each validation set: MSE_{CV} = \\dfrac{1}{k}\\sum_{i=1}^{k} MSE_iThe leave-one-out cross validation, or LOOCV, is a special case of k-fold CV with k=n. Since LOOCV requires fitting the model n times, with n being equal to number of train data points. The k-fold CV with k=5\\ or \\ 10 are more feasible computationally as it only needs to fit the model 5\\ or\\ 10 times. BootstrapBootstrap provides a measure of accruacy of either a parameter estimate or a given statistical learning method. It can be used to estimate variance of a parameter by repeatedly re-sampling the same data set with replacement (i.e. duplicate data entries allowed) while re-calculating the parameter based on each re-sample. Hyper-Parameter TuningWe specify numerious constants called hyperparameter during our modeling process, e.g. \\lambda, \\alpha, etc. To set these constant such that our model can predict accruately while avoiding over-complexity and overfitting, we tune our hyperparameter with cross validation. For more details see the auto claim notebook. Generalized Linear ModelGeneralized linear models were developed by Nelder and Wedderburn in a paper published in 1972 to provide a flexible framework which introduces a link function that transform the linear combinations of predictors. An Ordinary Linear Model has many limitations: As ordinary linear model produces a numeric response, it requires the assumptions of orderings to predict qualitative responses. Negative values may be predicted when not allowed. When the variance of the target variable depends on the mean, the homoscedasticity assumption is violated, and therefore the least square estimator is no longer the MLE estimator and various statistical test would not hold. Sensitive to outliers. Does not perform well with non-linear relationships. The Generalized Linear Models relaxes the assumptions of OLM. First, GLM relaxes the normal residual assumption of OLM, and allow the target variable Y to follow any distribution within the exponential distribution family: f(y_i|x_i) \\sim \\text{exponential distribution family}With regard to this distribution, there exists a canonical link function associated with it that simplifies the mathematics of solving GLM analytically. Normal =&gt; Identity: \\phi(a) = a Exponential/Gamma =&gt; Negative Inverse: \\phi(a) = - a^{-1} Inverse Gaussian =&gt; Inverse Square: \\phi(a) = a^{-2} Poisson =&gt; Log: \\phi(a) = ln(a) Bernoulli/Binomial/Multinomial =&gt; Logit: \\phi(a) = ln[a/(1-a)] We can either choose the canonical link function or pick another one (which may not lead to a converged GLM solution, however). With this link function, GLM assumes that the expectation of the target is the inverse linked linear combination of predictors: \\mathbb{E}(y_i|x_i) = \\phi^{-1}(\\beta x_i)With all above assumptions satisfy, the coefficient \\beta of a GLM model can then be solved: \\phi(Y) \\sim \\beta XLogistic RegressionThe logistic regression model is popular for classification problems. With two response classes, we can calculate the probability of assigning the response in each class and predict the response by choosing the class with the higher probability. or more than two response classes, multiple-class logistic regression is available but the discrimentant analysis is more popular. We define p(X) = \\mathbb{P}[Y = 1|X] as our new response variable and the link function: logit function, short for logistic function, as such: \\phi(p(X)) = logit(p(X)) = log[\\dfrac{p(X)}{1-p(X)}]Since we assume a linear relationship between our predictor X and the linked reponse logit(p(X)), we have: log[\\dfrac{p(X)}{1-p(X)}] = \\beta_0+\\beta_1X_1+\\beta_2X_2\\dotsTherefore, p(X) = \\dfrac{e^{\\beta_0+\\beta_1X_1+\\beta_2X_2\\dots}}{1+e^{\\beta_0+\\beta_1X_1+\\beta_2X_2\\dots}}Now we have a nice property of p(X) \\in (0, 1), which is exactly what we wanted to model probability responses. The quantity p(X)/(1-p(X)) is called the odds. In R, we use the glm function (with family=binomial) in the predict Survival from the Titanic dataset.12345678910111213141516171819202122232425262728293031323334353637library(e1071)library(caret)set.seed(9999)df &lt;- as.data.frame(Titanic)df &lt;- df[rep.int(seq_len(nrow(df)), df$Freq), ]df &lt;- subset(df, select = -c(Freq))# Binarize class, sex and agedf.new &lt;- predict(dummyVars(\"~Class+Sex+Age\", df, sep=\"_\", fullRank=TRUE), df)df.new &lt;- as.data.frame(df.new)df.new[\"Survived\"] &lt;- df$Surviveddf &lt;- df.new# Create random 80/20 train/test splittrain_ind &lt;- sample(seq_len(nrow(df)), size = floor(0.80 * nrow(df)))df_train &lt;- df[train_ind, ]df_test &lt;- df[-train_ind, ]# Fit Logistic Regressionmodel &lt;- glm(Survived~., df_train, family=binomial)summary(model)contrasts(df$Survived)# Predict In-Sampleprob_train &lt;- predict(model, df_train, type=\"response\")pred_train &lt;- rep(\"No\", nrow(df_train))pred_train[prob_train &gt; .5] &lt;- \"Yes\"# Predict Out-Of-Sampleprob_test &lt;- predict(model, df_test, type=\"response\")pred_test &lt;- rep(\"No\", nrow(df_test))pred_test[prob_test &gt; .5] &lt;- \"Yes\" From summary(model), note that most coeefficients are significant.123456789&gt; summary(model)Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 0.3094 0.3132 0.988 0.323 Class_2nd -1.1163 0.2187 -5.105 3.31e-07 `Class_3rd -1.7041 0.1918 -8.883 &lt; 2e-16 `Class_Crew -0.8848 0.1773 -4.991 6.01e-07 `Sex_Female 2.3691 0.1555 15.235 &lt; 2e-16 `Age_Adult -0.6289 0.2767 -2.273 0.023 * Note that probability of 1 correspond to “Yes” in the Survived variable.1234&gt; contrasts(df$Survived) YesNo 0Yes 1 From in-sample confusion matrix.123456789&gt; confusionMatrix(as.factor(pred_train), df_train$Survived)Confusion Matrix and Statistics ReferencePrediction No Yes No 1087 296 Yes 102 275 Accuracy : 0.7739 From out-of-sample confusion matrix.123456789&gt; confusionMatrix(as.factor(pred_test), df_test$Survived)Confusion Matrix and Statistics ReferencePrediction No Yes No 277 66 Yes 24 74 Accuracy : 0.7959 Comparing the test error rate between naiveBayes, KNN and logistic regression.123naiveBayes (cv10): 0.2095KNN (cv10, K=1): 0.1942logistic regression: 0.2041 Poisson RegressionThe Poisson distribution expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event. \\mathbb{P}(\\text{k events in interval}) = e^{\\lambda}\\dfrac{\\lambda^k}{k!}We can fit Posisson regression if we observe that the frequencies of response variable Y exhibits a Poisson shape. We will create a new response vector \\theta and assumes that log(\\theta) has an underlying linear relationship in X. Y \\sim poisson(\\boldsymbol {\\theta}) \\\\ \\text{and, } log(\\boldsymbol {\\theta}) = \\beta XThat is, we assume that for each X_i, Y_i \\sim poisson(e^{\\beta X_i}). The log link function ensures that \\boldsymbol{\\theta} is strictly positive. Note that we had made a strong assumption that for each X_i, the mean and variance of Y_i are the same, as dictated by the Poisson distribution. However, if the data shows larger variance than expected, or overdispersion, we can then use the quasi-Poisson regression, which is essenstially the negative binomial distribution with looser assumptions than Poisson. In the diamonds dataset from the ggplot2 package, we plotted the histogram of the price data from 50,000 observations. 123library(ggplot2)df &lt;- as.data.frame(diamonds)ggplot(df, aes(x=price)) + geom_histogram(binwidth=1) The price data shows resemblence to a Poisson distribution. We fitted four different models: linear, ridge, lasso, and Poisson regressions.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162library(e1071)library(ggplot2)library(caret)library(glmnet)set.seed(9999)df &lt;- as.data.frame(diamonds)# caret::dummyVars does not work well with ordered factor. change to unordered.df[\"cut_1\"] &lt;- factor(df$cut, order=FALSE)df[\"color_1\"] &lt;- factor(df$color, order=FALSE)df[\"clarity_1\"] &lt;- factor(df$clarity, order=FALSE)# Binarize Category Variabledummy &lt;- dummyVars(~ cut_1 + color_1 + clarity_1, df, sep=\"_\", fullRank=TRUE)df.new &lt;- as.data.frame(predict(dummy, newdata = df))df.new[\"carat\"] &lt;- df$caratdf.new[\"price\"] &lt;- df$pricedf &lt;- df.newx &lt;- model.matrix(price~., df)[, -1]y &lt;- df$price# Create random 80/20 train/test splitpartition &lt;- sample(seq_len(nrow(df)), size = floor(0.80 * nrow(df)))df_train &lt;- df[partition, ]df_test &lt;- df[-partition, ]x_train &lt;- x[partition, ]x_test &lt;- x[-partition, ]y_train &lt;- y[partition]y_test &lt;- y[-partition]# Fit Linear Regressionm1 &lt;- lm(price~., df_train)m1.pred &lt;- predict(m1, df_test)m1.mse &lt;- round(mean((y_test - m1.pred)^2), 2)# Fit Ridge Regressionm2 &lt;- cv.glmnet(x_train, y_train, alpha=0, nfolds=10)m2.bestlambda &lt;- m2$lambda.minm2.pred &lt;- predict(m2, s=m2.bestlambda, x_test)m2.mse &lt;- round(mean((y_test - m2.pred)^2), 2)# Fit Lasso Regressionm3 &lt;- cv.glmnet(x_train, y_train, alpha=1, nfolds=10)m3.bestlambda &lt;- m3$lambda.minm3.pred &lt;- predict(m3, s=m3.bestlambda, x_test)m3.mse &lt;- round(mean((y_test - m3.pred)^2), 2)# Fit Poisson Regressionm4 &lt;- glm(price~., df_train, family=poisson(link=\"log\"))m4.pred &lt;- predict(m4, df_test)m4.mse &lt;- round(mean((y_test - exp(m4.pred))^2), 2)# Fit quasiPoisson Regressionm5 &lt;- glm(price~., df_train, family=quasipoisson(link=\"log\"))m5.pred &lt;- predict(m5, df_test)m5.mse &lt;- round(mean((y_test - exp(m5.pred))^2), 2)# Compare Coefficientm2.best &lt;- glmnet(x_train, y_train, alpha=0, lambda=m2.bestlambda)m3.best &lt;- glmnet(x_train, y_train, alpha=1, lambda=m3.bestlambda)comp &lt;- cbind(coef(m1), coef(m2.best), coef(m3.best), coef(m4), coef(m5))colnames(comp) &lt;- c(\"original\", \"ridge\", \"lasso\", \"Poisson\", \"quasiPoi\") Showing the results. We can see that lasso regression improved upon ridge. However, the Poisson regression show very high MSE, and not improved by using quasi-Poisson to deal with overdispersion.1234567891011121314&gt; m1.mse[1] 1296082&gt; m2.mse[1] 1662769&gt; m3.mse[1] 1296773&gt; m4.mse[1] 5237564&gt; m5.mse[1] 5237564 Comparing coefficients:12345678910111213141516171819202122&gt; comp19 x 5 sparse Matrix of class \"dgCMatrix\" original ridge lasso Poisson quasiPoi(Intercept) -7369.2859 -2751.693983 -7083.4777 5.17185599 5.17185599cut_1_Good 686.6877 112.163397 657.1100 0.17515789 0.17515789`cut_1_Very Good` 864.3160 319.828814 838.9901 0.20528993 0.20528993cut_1_Premium 893.6342 367.364011 866.6581 0.18009057 0.18009057cut_1_Ideal 1025.5579 421.231162 999.8031 0.20406528 0.20406528color_1_E -225.3985 -23.486004 -205.5637 -0.05660526 -0.05660526color_1_F -294.1807 2.717515 -274.2126 -0.03079075 -0.03079075color_1_G -522.9599 -112.556133 -501.1661 -0.10597258 -0.10597258color_1_H -997.6266 -490.885083 -975.9837 -0.25411004 -0.25411004color_1_I -1452.1455 -749.323400 -1426.9279 -0.42200863 -0.42200863color_1_J -2343.2864 -1450.247841 -2315.1429 -0.63819087 -0.63819087clarity_1_SI2 2612.5463 -472.362109 2345.9392 1.14176901 1.14176901clarity_1_SI1 3555.6013 149.192295 3287.0687 1.38540593 1.38540593clarity_1_VS2 4210.3193 671.522828 3940.7103 1.50843614 1.50843614clarity_1_VS1 4507.7144 861.334888 4235.9431 1.58850692 1.58850692clarity_1_VVS2 4965.2210 1192.175019 4691.8855 1.66443836 1.66443836clarity_1_VVS1 5072.6388 1162.725817 4796.5710 1.61060572 1.61060572clarity_1_IF 5436.6567 1476.377453 5158.0224 1.72336616 1.72336616carat 8899.8818 7672.223943 8883.8976 1.65798106 1.65798106 We are curious as to why the Poisson regression perform much worse than a simple linear regression, when the reponse variable clearly shows Poisson patterns. 1234567891011p1 &lt;- ggplot() + geom_point(data=df_test, aes(x=as.numeric(row.names(df_test)), y=price), shape=\".\", color=\"black\") + geom_point(aes(x=as.numeric(row.names(df_test)), y=m1.pred), shape=\".\", color=\"red\")p2 &lt;- ggplot() + geom_point(data=df_test, aes(x=as.numeric(row.names(df_test)), y=price), shape=\".\", color=\"black\") + geom_point(aes(x=as.numeric(row.names(df_test)), y=exp(m4.pred)), shape=\".\", color=\"red\") We first look at the linear regression fit, where the black dots are the original data and the red dots are the fitted data: We then look at the Poisson regression fit. Unfortunately the Poisson regression create ultra-high predictions for some values, which skew the MSE matrix. This is we forget to log the numerical variable (carat) when we use log link function, which results in a exponential shape for the prediction. We change the code as follow:123456789# Fit Poisson Regressionm4 &lt;- glm(price~-carat+log(carat), df_train, family=poisson(link=\"log\"))m4.pred &lt;- predict(m4, df_test)m4.mse &lt;- round(mean((y_test - exp(m4.pred))^2), 2)# Fit quasiPoisson Regressionm5 &lt;- glm(price~-carat+log(carat)., df_train, family=quasipoisson(link=\"log\"))m5.pred &lt;- predict(m5, df_test)m5.mse &lt;- round(mean((y_test - exp(m5.pred))^2), 2) The mse are now better:1234&gt; m4.mse[1] 2544181&gt; m5.mse[1] 2544181 Plotting the prediction. We can see that other than one prediction outlier, the overall predictions are better than when we did not log the carat. Goodness of FitDeviance is a measure of the goodness of fit of a generalized linear model, similar to a RSS in the simple linear model. . The default value is called null deviance and is the deviance calculated when the response variable is predicted using its sample mean. Adding additional feature to the model would generally decrease the deviance and decrease the degree of freedoms. Tree-Based Method &#8634;The tree-based method involve segmenting the predictor space into several regions to make a prediction for a given observation. There are several advantages to the tree-based methods: Easy to explain Intuitive to human reasoning Graphic and interpretable No need to dummy variables for qualitative data On the other hand, disadvantages: Lower predictive accuracy Sensitive to change in data Several techniques can make significant improvement to compensate the disadvantages, namely bagging, random forest and boosting. Regression TreeIn a linear regression model, the underlying relationship is assumed to be: f(X) = \\beta_0 + \\sum\\beta_iX_iWhereas in a regression tree model, the underlying is assumed to be: f(X) = \\sum c_i\\textbf{1}_{X_i\\in R_i}Where each R_i represent a partition of the feature space. The goal is to solve for the partition set \\{R_i\\}_{i\\in I} which minimize the objective function: Objective\\; Function = RSS = \\sum_{i\\in I}\\sum_{X_j\\in R_i} (y_j-\\bar{y}_{R_i})^2To find \\{R_i\\}_{i\\in I} efficiently, we introduce recursive binary splitting, which is a top-down and greedy approach. It is greedy because it is short-sighted in that it always chooses the current best split, instead of the optimal split overall. Due to the greedy nature, it is preferred that we first grow a complex tree and then prune it back, so that all potential large reductions in RSS are captured. Cost Complexity PruningThe cost complexity pruning approach aim to minimize the objective function, give each value of \\alpha: Objective\\; Function = \\sum_{i\\in I_T}\\sum_{X_j\\in R_i} (y_j-\\bar{y}_{R_i})^2 + \\alpha|T|Where |T| is the number of terminal nodes of subtree T\\subset T_0 where T_0 is the original un-prune tree. The tuning parameter \\alpha controls the complexity of the subtree T, penalizing any increase in nodes. The goal is to prune the tree with various \\alpha and then use cross-validation to select the best \\alpha. This is similar to the lasso equation, which also introduce a tuning parameter \\lambda to control the complexity of a linear model. Objective\\; Function = RSS + \\lambda\\sum_{i>0}|\\beta_i|In R, we use the rpart library, which stands for recursive partitioning and regression trees, to fit a regression tree to predict mpg in our mtcars dataset.123456789101112131415library(caret)library(rpart)library(rpart.plot)set.seed(9999)df &lt;- as.data.frame(mtcars)# create a 75/25 train/test splitpartition &lt;- createDataPartition(df$mpg, list=FALSE, p=0.75)train &lt;- df[partition, ]test &lt;- df[-partition, ]# fit regression treet1 &lt;- rpart(mpg ~ ., train)t1.predict &lt;- predict(t1, test)t1.mse &lt;- round(mean((test$mpg - t1.predict)^2), 2) The test MSE, as compared to the previous linear models.1234567891011# regression tree&gt; t1.mse[1] 11.59# linear regression&gt; m1.mse[1] 16.64&gt; m2.mse[1] 3.66&gt; m3.mse[1] 6.61 Plotting the tree with rpart.plot(t1) command. Classification TreeClassification tree is very similar to regression trees expect we need an alternative method to RSS when deciding a split. There are three common approaches. Classification error rate: E = 1 - \\underset{k}{max}(\\hat{p}_{mk}) Where \\hat{p}_{mk} represents the porportion of train observations from the m-th parent node that are from the k-th child node. However, the this approach is not sufficiently sensitive to node impurity for tree-growing, compared to the next two. Gini index: G = \\sum_k \\hat{p}_{mk}(1-\\hat{p}_{mk}) Note that the Gini index decreases as all \\hat{p}_{mk} get closer to 0 or 1. Therefore it is a measure of the node purity. Entropy: D = -\\sum_k \\hat{p}_{mk} log_2(\\hat{p}_{mk}) The Entropy is also a measure of the node purity and similar to the Gini index numerically. For a two-class decision tree, the impurity measures calculated from different methods for a given \\hat{p}_{mk} are simulated below with python. 12345678910111213import matplotlib.pyplot as pltimport numpy as npx = np.arange(0, 1, 0.001)y1 = x*np.log(x)/np.log(2)*-1 + (1-x)*np.log(1-x)/np.log(2)*-1y2 = x*(1-x) + (1-x)*(1-(1-x))y3 = 1-np.maximum(x, 1-x)fig = plt.figure(figsize=(6, 6))plt.plot(x, y1)plt.plot(x, y2)plt.plot(x, y3)plt.legend(['entropy', 'gini', 'class error'], loc='upper right') We can see that all three method are similar and consistent with each other. Entropy and the Gini are more sensitive to changes in the node probabilities, therefore preferrable when growing the trees. The classification error is more often used during complexity pruning. Information GainWhen the measure of node purity is calculated, we want to maximize the information gain after each split. We use P and C to denote the parent and child node, with entropy as the measure. N is the number of observations under the parent node: IG = Entropy(P) - \\sum_{k=1}^{K}\\dfrac{N_k}{N}Entropy(C_k)In R, we use the rpart library to create a classification tree to predict Survived in the Titanic data set.12345678910111213141516171819202122library(caret)library(rpart)library(rpart.plot)set.seed(9999)df &lt;- as.data.frame(Titanic)df &lt;- df[rep.int(seq_len(nrow(df)), df$Freq), ]df &lt;- subset(df, select = -c(Freq))# create a 75/25 train/test splitpartition &lt;- createDataPartition(df$Survived, list=FALSE, p=0.75)train &lt;- df[partition, ]test &lt;- df[-partition, ]# fit classification treet2 &lt;- rpart(Survived ~ ., train)t2.prob &lt;- predict(t2, test)t2.pred &lt;- rep(\"No\", nrow(t2.prob))t2.pred[t2.prob[, 2] &gt; .5] &lt;- \"Yes\"# pruningt2.prune &lt;- prune(t2, cp = 0.05)rpart.plot(t2.prune) The confusion matrix shows:123456789&gt; confusionMatrix(as.factor(t2.pred), test$Survived)Confusion Matrix and Statistics ReferencePrediction No Yes No 368 105 Yes 4 72 Accuracy : 0.8015 Plotting the tree with rpart.plot(t2). Plotting the complexity parameter against the cross-validation relative error with plotcp(t2). Although the relative error is at the lowest at 5 nodes, comparable level of relative error was achieved at 2 nodes. Because decision tree is prone to overfitting, here we manually prune the tree back to 2 nodes. Plotting the tree with rpart.plot(t2.prune). The confusion matrix after pruning. We lose a small bit of out-of-sample accuracy due to manual pruning.123456789&gt; confusionMatrix(as.factor(t2.prune.pred), test$Survived)Confusion Matrix and Statistics ReferencePrediction No Yes No 343 83 Yes 29 94 Accuracy : 0.796 Comparing the test error rate with naiveBayes, KNN and logistic regression.1234naiveBayes (cv10): 0.2095KNN (cv10, K=1): 0.1942classification tree: 0.1985classification tree (prune): 0.2040 Confusion MatrixThe confusion matrix is a convenient summary of the model prediction. In our previous example with the un-pruned tree: 12345678910111213&gt; confusionMatrix(as.factor(t2.pred), test$Survived)Confusion Matrix and Statistics ReferencePrediction No Yes No 368 105 Yes 4 72# mapping the number to definition ReferencePrediction No Yes No TN FN Yes FP TP There are four types of prediction: True Positive (TP): 72 True Negative (TN): 368 False Positive (FP), or Type I Error: 4 False Negative (FN), or Type II Error: 105 Several metrics can be computed: Accuracy: (TP + TN) / N = (72 + 368) / 549 = 0.8015 Error Rate: (FP + FN) / N = 1 - Accuracy = 0.1985 Precision: TP / (Predicted Positive) = 72 / (72 + 4) = 0.9474 Sensitivity: TP / (Actually Positive) = 72 / (72 + 105) = 0.4068 Receiver Operator Characteristic CurveThe ROC curve can be used to evaluate the performacne of our model. The ROC curve plots the TPR (true positive rate) against FPR (false positive rate) over a range of cutoff values: TPR = TP / (Actually Positive) = 0.4068 FPR = FP / (Actually Negative) = 0.0107 In python, we can create a ROC curve from our previous prediction TPR and FPR:1234567891011121314import matplotlib.pyplot as pltimport numpy as npx = np.arange(0, 1, 0.0001)plt.plot(x, x)plt.xlabel('FPR')plt.ylabel('TPR')x2=0.0107y2=0.4680plt.scatter(x2, y2, s=20, color='red')plt.plot([0, x2], [0, y2], 'r-', color='red')plt.plot([x2, 1], [y2, 1], 'r-', color='red')plt.title('ROC Plot') The baseline line refers to a model/cutoff where all observations in the testing set are predicted to be positive (point x=1, y=1), or negative (point x=0, y=0). The area under the red lines and above the x-axis is an estimate of the model fit and is called AUC, or area under the ROC curve. An AUC of 1 means that the model has a TPR of 1 and FPR of 0. Ensemble MethodsBaggingThe decision tree method in general suffer from high model variance, compared to linear regression which shows low variance. Bootstrap aggregation, or bagging is a general-purpose procedure for reducing variance of a statistical model without affecting the bias. It is particular useful in the decision tree model context. For regression trees, construct B regression trees using B bootstrapped (repeatedly sampled) training sets. These trees grow deep and are not pruned, therefore having high variance. At the end, average the trees to reduce the variance. For classification trees, construct B classification trees. When predicting a test observation, take the majority classification resulted from the B trees. Note that the bagging results are more accruate but less visual. We can obtain the variable importances by computing the total RSS/Gini decreases by splits over each predictors, hence providing better interpretations of the results. Random ForestRandom forest improves upon bagged trees by de-correlating the trees. At each split, only m\\approx\\sqrt{p} predictors are considered, isolating effects on single feature with large influences. In R, use the randomForest package:123456789101112131415161718library(caret)library(randomForest)set.seed(9999)df &lt;- as.data.frame(Titanic)df &lt;- df[rep.int(seq_len(nrow(df)), df$Freq), ]df &lt;- subset(df, select = -c(Freq))# create a 75/25 train/test splitpartition &lt;- createDataPartition(df$Survived, list=FALSE, p=0.75)train &lt;- df[partition, ]test &lt;- df[-partition, ]# fit random forestrf &lt;- randomForest(formula = Survived ~ ., data = train, ntree = 100, importance = TRUE) In-sample confusion matrix:12345678910111213&gt; rfCall: randomForest(formula = Survived ~ ., data = train, ntree = 100, importance = TRUE) Type of random forest: classification Number of trees: 100No. of variables tried at each split: 1 OOB estimate of error rate: 23.43%Confusion matrix: No Yes class.errorNo 1063 55 0.04919499Yes 332 202 0.62172285 Out-of-sample confusino matrix:123456789&gt; confusionMatrix(as.factor(predict(rf, test)), test$Survived)Confusion Matrix and Statistics ReferencePrediction No Yes No 368 108 Yes 4 69 Accuracy : 0.796 Comparing the test error rate with naiveBayes, KNN and logistic regression.12345naiveBayes (cv10): 0.2095KNN (cv10, K=1): 0.1942classification tree: 0.1985classification tree (prune): 0.2040random forest: 0.2040 BoostingBoosting is also a general-purpose procedure for improving accuracy of the statistical model. In boosting, we repeatedly fit new trees to the residuals from the previous tree, and add the new trees to the main tree such that a loss function is minimized (subject to shrinkage parameter \\lambda, typical 0.01, to control overfitting). CV is often used to determine the total number of trees to be fitted. A gradient boosting machine is an algorithm that calculates the gradient of the loss function and update the paramters such that the model moves in the direction of the negative gradient, thus closer to a minimum point of the loss function. XGBoost is an open-source software library that provides a gradient boosting framework for R. XGBoost initially started as a research project by Tianqi Chen as part of the Distributed (Deep) Machine Learning Community (DMLC) group 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465llibrary(caret)library(xgboost)library(pROC)set.seed(9999)df &lt;- as.data.frame(Titanic)df &lt;- df[rep.int(seq_len(nrow(df)), df$Freq), ]df &lt;- subset(df, select = -c(Freq))# turn survival into 0 and 1Survived_Ind &lt;- rep(0, nrow(df))Survived_Ind[df$Survived == \"Yes\"] &lt;- 1df$Survived_Ind &lt;- Survived_Ind# create a 75/25 train/test splitpartition &lt;- createDataPartition(df$Survived_Ind, list=FALSE, p=0.75)train &lt;- df[partition, ]test &lt;- df[-partition, ]test_2 &lt;- testtrain &lt;- subset(train, select = -c(Survived))test &lt;- subset(test, select = -c(Survived))# create model frame for xgboost inputtrain.mf &lt;- model.frame(as.formula(\"Survived_Ind ~.\"), data = train)test.mf &lt;- model.frame(as.formula(\"Survived_Ind ~.\"), data = test)# create a model matrix only contains numerical values.train.mm &lt;- model.matrix(attr(train.mf, \"terms\"), data = train)test.mm &lt;- model.matrix(attr(test.mf, \"terms\"), data = test)# [optional] create A XGB dense matrix contains an R matrix and metadatatrain.dm &lt;- xgb.DMatrix(train.mm, label = train$Survived, missing = -1)test.dm &lt;- xgb.DMatrix(test.mm, label = test$Survived, missing = -1)# create xgboost parameter listparams &lt;- list(\"booster\" = \"gbtree\", # \"gblinear\" for glm \"objective\" = \"binary:logistic\", # the output here is a probability \"eval_metric\" = \"auc\", \"eta\" = 0.1, # lambda \"subsample\" = 0.6, # proportion of observations \"colsample_bytree\" = 0.6, # proportion of features \"max_depth\" = 5) # depth of the decision tree# train xgboost modelmodel.cv &lt;- xgb.cv(params = params, data = train.dm, nrounds = 1000, # the number of trees / iterations prediction = FALSE, # storage of prediction under each tree print_every_n = 25, early_stopping_rounds = 50, maximize = TRUE, # AUC metric -&gt; maximize nfold = 6) # cv# fit final modelmodel &lt;- xgb.train(params = params, data = train.dm, nrounds = model.cv$best_iteration, prediction = FALSE)# format predictionxgb.prob &lt;- predict(model, test.dm)xgb.pred &lt;- rep(\"No\", sum(lengths(xgb.prob)))xgb.pred[xgb.prob &gt; 0.5] &lt;- \"Yes\" Feature importance:1234&gt; xgb.importance(feature_names = dimnames(train.dm)[[2]], model = model) Feature Gain Cover Frequency1: Class3rd 0.8347889 0.5957944 0.52: Class2nd 0.1652111 0.4042056 0.5 AUC result:12&gt; auc(test$Survived_Ind, xgb.prob)Area under the curve: 0.6033 Confusion matrix:123456789&gt; confusionMatrix(as.factor(xgb.pred), as.factor(test_2$Survived))Confusion Matrix and Statistics ReferencePrediction No Yes No 370 180 Yes 0 0 Accuracy : 0.6727 Unfortunately xgboost predict everything to be “No” Comparing the test error rate with naiveBayes, KNN and logistic regression.123456naiveBayes (cv10): 0.2095KNN (cv10, K=1): 0.1942classification tree: 0.1985classification tree (prune): 0.2040random forest: 0.2040xgboost: 0.3273 Ensemble Model InterpretationFeature Importance ranks the contribution of each feature.Partial Dependence Plots visualizes the model’s average dependence on a specific feature (or a pair of features). Unsupervised Learning &#8634;In supervised learning, we are provided a set of n observations X, each containing p features, and a response variable Y. We are interested at predicting Y using the observations and features. In unsupervised learning, we are interested at exploring hidden relationships within the data themself without involving any response variables. It is “unsupervised” in the sense that the learning outcome is subjective, unlike supervised learning in which specific metrics such as error rates are used to evaluate learning outcomes. PCASee the PCA section below. K-Mean ClusteringClustering seek to partition data into homogeneous subgroups. The K-Mean clustering partitions data into K distinct and non-overlapping clusters C, by minimizing the objective function of total in-cluster variation W(C), which is the sum of all pair-wise squared Euclidean distances between the observations in the cluster, divided by the number of observations in the cluster. \\text{minimize } \\{\\ \\sum_{k=1}^K W(C_k)\\ \\}AlgorithmThe algorithm divides data into K initial cluster, and reassign observations to the cluster with the closest cluster centroid (mean of all previous observations in the cluster). The K-Mean clustering algorithm finds a local optimum, and therefore depend on the initial cluster. So it is important to repeat the process with different initial points, and then select the best result based on minimum total in-cluster variation. The nstart parameter in the kmean function in R specifies the number of random starting centers to try and the one ended with the optimal objective function value will be selected. It is also important to check for outliers, as the algorithm would let the outlier become its own cluster and stops improving. StandardizationIt is a must to standardize the variables before performing k-mean cluster analysis, as the objective function (Euclidean distance, etc.) is calculated from the actual value of the variable. Curse of DimensionalityThe curse of dimensionality describe the problems when performing clustering on three or more dimensional space, where: visualization becomes harder as the number of dimensions increases, the Euclidean distance between data points are the same on average. The solution is to reduce the dimensionality before using clustering technique. The Elbow MethodEach cluster replaces its data with its center. In other words, with a clustering model we try to predict which cluster a data point belongs to. A good model would explain more variance in the data with its cluster assignments. The elbow method looks at the F statistics defined as: F = \\dfrac{\\text{between-group variance}}{\\text{total variance}}As soon as the additional F statistics drops/stops increasing when adding a new cluster, we use that number of clusters. Hierarchical ClusteringThe hierarchical clustering provide flexibilities in terms of the number of clusters K. It results in a tree-based representation of the data called dendrogram, which is built either bottom-up/agglomerative or top-down/divisive. Hierarchical clustering assumes that there exists a hierarchical structure. In most feature generation cases, we prefer k-means clustering instead. AgglomerativeAn agglomerative hierarchical cluster starts off by assigning each data point in its own cluster. Each step in the clustering process two similar clusters with minimum distance among all are merged, where the distance is calculated between the elements within the cluster that are closest (single-linkage) or furthest (complete-linkage) PCA - A Deeper Dive &#8634;PCA finds low dimensional representation of a dataset that contains as much as possible of the variation. As each of the n observations lives on a p-dimensional space, and not all dimensions are equally interesting. Linear Algebra ReviewLet A be a n\\times n matrix. With n=2, \\ 3, the determinant of A can be calculated as follow. det(\\begin{bmatrix} a & b \\\\ c & d \\\\ \\end{bmatrix} ) = ad - bc\\begin{align} det ( \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\\\ \\end{bmatrix} ) &= aei + bfg + cdh - cdg - bdi - afh \\\\ &= a \\times det( \\begin{bmatrix} e & f \\\\ h & i \\\\ \\end{bmatrix} ) + b \\times det( \\begin{bmatrix} d & f \\\\ g & i \\\\ \\end{bmatrix} ) + c \\times det( \\begin{bmatrix} d & e \\\\ g & h \\\\ \\end{bmatrix} ) \\end{align}Properties of determinant: \\begin{align} det(A^T) &= det(A) \\\\ det(A^{-1}) &= det(A)^{-1} \\\\ det(AB) &= det(A)det(B) \\end{align}A real number \\lambda is an eigenvalue of A if there exists a non-zero vector x (eigenvector) in \\mathbb{R}^n such that: Ax = \\lambda xThe determinant of matrix A - \\lambda I is called the characteristic polynomial of A. The equation det(A - \\lambda I) is called the characteristic equation of A, where the eigenvalues \\lambda are the real roots of the equation. It can be shown that: \\prod_{i=1}^n \\lambda_i = det(A) \\\\ \\sum_{i=1}^n \\lambda_i = \\sum_{i=1}^n a_{i, \\ i} = trace(A)Matrix A is invertible if there exists a n\\times n matrix B such that AB = BA = I. A square matrix is invertible if and only if its determinant is non-zero. A non-square matrix do not have an inverse. Matrix A is called diagonalizable if and only if it has linearly independent eigenvectors. Let \\textbf{U} denote the eigen vectors of A and \\textbf{D} denote the diagonal \\lambda vector. Then: A = \\textbf{UDU}^{-1} \\rightarrow A^x = \\textbf{UD}^x\\textbf{U}^{-1}If matrix A is symmetric, then: all eigenvalues of A are real numbers all eigenvectors of A from distinct eigenvalues are orthogonal Matrix A is positive semi-definite if and only if any of the following: for any n\\times 1 matrix x, x^TAx \\geq 0 all eigenvalues of A are non-negative all the upper left submatrices A_K have non-negative determinants. Matrix A is positive definite if and only if any of the following: for any n\\times 1 matrix x, x^TAx > 0 all eigenvalues of A are positive all the upper left submatrices A_K have positive determinants. All covariance, correlation matrices must be symmetric and positive semi-definite. If there is no perfect linear dependence between random variables, then it must be positive definite. Let A be an invertible matrix, the LU decomposition breaks down A as the product of a lower triangle matrix L and upper triangle matrix U. Some applications are: solve Ax=b: LUx=b \\rightarrow Ly=b \\text{ ; } Ux=y solve det(A): det(A) = det(L)\\ det(U)=\\prod L_{i, \\ i}\\prod U_{j, \\ j} Let A be a symmetric positive definite matrix, the Cholesky decomponsition expand on the LU decomposition and breaks down A=U^TU, where U is a unique upper triangular matrix with positive diagonal entries. Cholesky decomposition can be used to generate correltaed random variables in Monte Carlo simulation Matrix InterpretationConsider a n\\times p matrix: \\begin{bmatrix} x_{11} & x_{12} & x_{13} & \\dots & x_{1p} \\\\ x_{21} & x_{22} & x_{23} & \\dots & x_{2p} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{n1} & x_{n2} & x_{n3} & \\dots & x_{np} \\end{bmatrix}To find the first principal component F^1, we define it as the normalized linear combination of X that has the largest variance, where its loading \\phi^1_j are normalized: \\sum^p_{j=1} (\\phi^1_j)^2 = 1 F^1 = \\phi^1_1X_1 + \\phi^1_2X_2 + \\dots + \\phi^1_pX_pOr equivalently, for each score: F^1_i = \\sum_{j=1}^{p} \\phi^1_jx_{ij} In matrix form: \\begin{bmatrix} x_{11} & x_{12} & x_{13} & \\dots & x_{1p} \\\\ x_{21} & x_{22} & x_{23} & \\dots & x_{2p} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{n1} & x_{n2} & x_{n3} & \\dots & x_{np} \\end{bmatrix}\\times \\begin{bmatrix} \\phi^1_1 \\\\ \\phi^1_2 \\\\ \\vdots \\\\ \\phi^1_p \\\\ \\end{bmatrix}= \\begin{bmatrix} f^1_1 \\\\ f^1_2 \\\\ \\vdots \\\\ f^1_n \\\\ \\end{bmatrix}Finally, the first principal component loading vector \\phi^1 solves the optimization problem that maximize the sample variance of the scores f^1. An objective function can be formulated as follow and solved via an eigen decomposition: \\text{maximize }\\{\\ \\dfrac{1}{n}\\sum_{i=1}^n(f^1_i)^2\\ \\} \\text{ subject to } \\sum^p_{j=1} (\\phi^1_j)^2 = 1To find the second principal component loading \\phi^2, use the same objective function with \\phi^2 replacement and include an additional constraint that \\phi^2 is orthogonal to \\phi^1. Geometric InterpretationThe p\\times k loading matrix L = [\\phi^1 \\dots \\phi^k] defines a linear transformation that projects the data from the feature space \\mathbb{R}^p into a subspace \\mathbb{R}^k, in which the data has the most variance. The result of the projection is the factor matrix F = [F^1 \\dots F^k], also known as the principal components. \\underbrace{ \\begin{bmatrix} x_{11} & x_{12} & x_{13} & \\dots & x_{1p} \\\\ x_{21} & x_{22} & x_{23} & \\dots & x_{2p} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{n1} & x_{n2} & x_{n3} & \\dots & x_{np} \\end{bmatrix} }_{data} \\times \\underbrace{ \\begin{bmatrix} \\phi^1_1 & \\dots & \\phi^k_1\\\\ \\phi^1_2 & \\dots & \\phi^k_2\\\\ \\vdots & \\ddots & \\vdots \\\\ \\phi^1_p & \\dots & \\phi^k_p\\\\ \\end{bmatrix} }_{loadings}= \\underbrace{ \\begin{bmatrix} f^1_1 & \\dots & f^k_1 \\\\ f^1_2 & \\dots & f^k_2 \\\\ \\vdots & \\ddots & \\vdots \\\\ f^1_n & \\dots & f^k_n \\\\ \\end{bmatrix} }_{\\text{principal components} \\\\ \\text{or, factor scores}}In other words, the principal components vectors F^1 ... F^k forms a low-dimensional linear subspace that are the closest (shortest average squared Euclidean distance) to the observations. Eigen DecompositionGiven n\\times p data matrix X, the objective of PCA is to find a lower dimension representation factor matrix F, from which a n\\times p matrix \\tilde{X} can be constructed where distance between the covariance matrices cov(X) and cov(\\tilde{X}) are minimized. The covariance matrix of X is a p\\times p symmetric positive semi-definite matrix, therefore we have the following decomposition where \\textbf{u}‘s’ are p\\times 1 eigenvectors of cov(X) and \\lambda‘s are the eigenvalues. Note that \\textbf{u} can be a zero vector if the columns of cov(X) are linearly dependent. \\begin{align} cov(X) &= \\dfrac{1}{n-1}X^TX \\\\ &=\\dfrac{1}{n-1} \\begin{bmatrix} \\textbf{u}_1 & \\dots & \\textbf{u}_p \\end{bmatrix} \\begin{bmatrix} \\lambda_1 & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & \\lambda_p \\end{bmatrix} \\begin{bmatrix} \\textbf{u}_1 & \\dots & \\textbf{u}_p \\end{bmatrix}^T \\\\ &= \\dfrac{1}{n-1}\\sum_{i=1}^p \\lambda_i\\textbf{u}_i\\textbf{u}_i^T \\end{align}If we ignore the constant 1/(n-1), and define the p\\times p loading matrix L_0=[\\textbf{u}_1, \\dots, \\textbf{u}_p] and n\\times p factor matrix F_0 where F_0^TF_0=\\Lambda. Then: X = F_0L_0^TNow comes the PCA idea: Let’s rank the \\lambda_i‘s in descending order, pick k < p such that: \\dfrac{1}{n-1}\\sum_{i=1}^{k} \\lambda_i\\textbf{u}_i\\textbf{u}_i^T \\approx \\dfrac{1}{n-1}\\sum_{i=1}^p \\lambda_i\\textbf{u}_i\\textbf{u}_i^T = cov(X) \\\\ \\text{and we denote it } cov(\\tilde{X}) \\text{, i.e. } cov(\\tilde{X}) = \\dfrac{1}{n-1}\\sum_{i=1}^{k} \\lambda_i\\textbf{u}_i\\textbf{u}_i^TNow we observe that the matrix cov(\\tilde{X}) is also a p\\times p positive semi-definite matrix. Following similar decomposition, we obtain a p\\times k matrix L and n\\times k matrix F, where: \\tilde{X} = FL^THere we have it, a dimension-reduced n\\times k factor matrix F, where its projection back to n\\times p space, \\tilde{X}, has similar covariance as the original n\\times p dataset X. Practical ConsiderationsPCA excels at identifying latent variables from the measurable variables. PCA can only be applied to numeric data, while categorical variables need to be binarized beforehand. Centering: yes. Scaling: if the range and scale of the variables are different, correlation matrix is typically used to perform PCA, i.e. each variables are scaled to have standard deviation of 1 otherwise if the variables are in the same units of measure, using the covariance matrix (not standardizing) the variables could reveal interesting properties of the data Uniqueness: each loading vector \\phi^1 is unique up to a sign flip, as the it can take on opposite direction in the same subspace. Same applies to the score vector Z^1, as var(Z^1) = var(-Z^1) Propotional of Variance Explained: we can compute the total variance in a data set in the first formula below. The variance explained by the m-th principal component is: \\dfrac{1}{n} \\sum_{i=1}^n (z^m_i)^2. Therefore, the second formula can be computed for the PVE: \\sum_{j=1}^p Var(X_j) = \\sum_{j=1}^p [ \\dfrac{1}{n} \\sum_{i=1}^n x^2_{ij} ] \\\\ PVE^m = \\dfrac{\\sum_{i=1}^n (z^m_i)^2}{\\sum_{j=1}^p\\sum_{i=1}^n x^2_{ij}} A Side Note on Hypothesis Test and Confidence Interval &#8634;A formal statistical data analysis includes: hypothesis testings: seeing whether a structure is present confidence interval: setting error limits on estimates prediction interval: setting error limits on future outcomes We will discuss a typical setting as follow: Let \\beta be the unknown parameter, and \\hat{\\beta}_n is the parameter estimator based on n observations Let \\hat{\\sigma}^2_n be the estimator of \\sigma^2_n, equal to var(\\sqrt{n}(\\hat{\\beta}_n - \\beta)) In rare circumstances where \\sqrt{n}(\\hat{\\beta}_n - \\beta)/\\hat{\\sigma} is independent of the unknown \\beta, such as in regression settings where the error terms \\epsilon_i are i.i.d. normally distributed, we can show that it follows a t-distribution with n-1 degree of freedom. \\dfrac{\\sqrt{n}(\\hat{\\beta}_n - \\beta)}{\\hat{\\sigma}} \\sim t_{n-1} However, asymptotically as n\\rightarrow\\infty, the Central Limit Theorem applies which release us from the assumption restriction above. Under a variety of regular conditions: \\lim_{n\\rightarrow\\infty} \\dfrac{\\sqrt{n}(\\hat{\\beta}_n - \\beta)}{\\hat{\\sigma}} \\sim \\mathcal{N}(0, 1) The 1-\\alpha confidence interval can then be computed as: \\beta \\in CI = \\hat{\\beta}_n \\pm t^{\\alpha}_{n-1}\\hat{\\sigma}_n/\\sqrt{n} \\\\ \\text{or asymptotically, swapping } t^{\\alpha}_{n-1} \\text{ by } z^{\\alpha} The 1-\\alpha hypothesis test of \\beta=\\beta_0 would: accept H_0 that \\beta=\\beta_0 if \\beta \\in CI reject H_0 that \\beta=\\beta_0 if \\beta \\notin CI The p-value is \\alpha such that the hypothesis test is indifference between accept or reject. In practice, t-distribution is typically used for regression data as it is more conservative (t^{\\alpha}_{n-1} > z^{\\alpha}). For non-regression data, normal distribution is often used. Some background on LLN and CLT: Given n i.i.d. random variable X_i. Let \\bar{X} = \\sum X_i/n The Law of Large Numbers states that if \\mathbb{E}|X|","tags":"math"},{"title":"About","url":"/2019/01/about/","text":"","tags":"travel"}]}